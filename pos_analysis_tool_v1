from __future__ import annotations

import sys
import traceback
from dataclasses import dataclass, field, asdict
from datetime import date, datetime, timedelta, timezone
from functools import partial
from pathlib import Path
from typing import Any, Callable, Dict, Iterable, List, Optional, Sequence, Tuple, Set
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import deque
import threading
import functools
import itertools
import json
import hashlib
import math
import os
import statistics
import uuid
import calendar
from collections import defaultdict

import duckdb
import pandas as pd
import pyodbc
import numpy as np
from PyQt6 import QtCore, QtGui, QtWidgets

import storage_duckdb
import time

try:
    from qfluentwidgets import ComboBox, CheckBox, FluentStyleSheet, LineEdit, Theme, setTheme, setThemeColor

    HAS_FLUENT = True
except ImportError:  # pragma: no cover - graceful fallback if dependency missing
    ComboBox = QtWidgets.QComboBox  # type: ignore[assignment]
    CheckBox = QtWidgets.QCheckBox  # type: ignore[assignment]
    LineEdit = QtWidgets.QLineEdit  # type: ignore[assignment]
    Theme = None  # type: ignore[assignment]

    def setTheme(_theme: object) -> None:  # type: ignore[override]
        pass

    def setThemeColor(_color: QtGui.QColor) -> None:  # type: ignore[override]
        pass

    class FluentStyleSheet:  # type: ignore[override]
        DARK = ""
        LIGHT = ""

    HAS_FLUENT = False


SERVER = "52.230.94.233"
USER = "seadmin"
PASSWORD = "$e@dmin11!"
DATABASES = [
    "sushi_gogo_pos_live",
    "sushi_express_pos_live",
    "sushi_plus_pos_live",
    "sushi_epoint_pos_live",
]
COMBINED_DATABASE = "sushi_pos_all"
MAX_SYNC_WORKERS = max(1, min(len(DATABASES), 4))

TABLE_NAMES = {
    "sales": "pos_sales_dtls",
    "payments": "pos_sales_payment_dtls",
    "cancellations": "pos_cancel_sales_item_dtls",
    "items": "item_master",
}

ACCENT_COLOR = "#4d7cfe"
SECONDARY_ACCENT = "#6ea8fe"
BACKGROUND_COLOR = "#111d3d"
PANEL_COLOR = "#1b2c59"
BUTTON_COLOR = "#3154c5"
TEXT_PRIMARY = "#e9f1ff"
TEXT_SECONDARY = "#cfd8ea"

PERIOD_OPTIONS = ("Daily", "Weekly", "Monthly", "Period")

PROMOTION_TYPES = ("Bi Monthly", "Ad-hoc Promotion")

DISCOUNT_ANALYSIS_COLUMNS: Dict[str, List[str]] = {
    "Daily": [
        "Period",
        "Outlet",
        "Discount Name",
        "Discount Sales",
        "Quantity",
        "Transaction",
        "Bill Sales",
        "Discount Ratio %",
        "Transaction Ratio %",
        "Quantity Ratio %",
    ],
    "Weekly": [
        "Period",
        "Outlet",
        "Discount Name",
        "Discount Sales",
        "Quantity",
        "Transaction",
        "Bill Sales",
        "Discount Ratio %",
        "Transaction Ratio %",
        "Quantity Ratio %",
    ],
    "Monthly": [
        "Period",
        "Outlet",
        "Discount Name",
        "Discount Sales",
        "Quantity",
        "Transaction",
        "Bill Sales",
        "Discount Ratio %",
        "Transaction Ratio %",
        "Quantity Ratio %",
    ],
    "Period": [
        "Period",
        "Outlet",
        "Discount Name",
        "Discount Sales",
        "Quantity",
        "Transaction",
        "Bill Sales",
        "Discount Ratio %",
        "Transaction Ratio %",
        "Quantity Ratio %",
    ],
}

PROMOTION_ANALYSIS_COLUMNS: Dict[str, List[str]] = {
    mode: [
        "Period",
        "Outlet",
        "Item / Discount Name",
        "Sales",
        "Transaction",
        "Quantity",
        "Sales Ratio %",
        "Transaction Ratio %",
        "Quantity Ratio %",
    ]
    for mode in PERIOD_OPTIONS
}

PRODUCT_ANALYSIS_COLUMNS: Dict[str, List[str]] = {
    "Daily": [
        "Period",
        "Outlet",
        "Item Name",
        "Category",
        "Sales",
        "Transaction",
        "Quantity",
        "Wastage",
        "Bill Sales",
        "Sales Ratio %",
        "Quantity Ratio %",
        "Wastage Ratio %",
        "Bill Sales Ratio %",
    ],
    "Weekly": [
        "Period",
        "Outlet",
        "Item Name",
        "Category",
        "Sales",
        "Transaction",
        "Quantity",
        "Wastage",
        "Bill Sales",
        "Sales Ratio %",
        "Quantity Ratio %",
        "Wastage Ratio %",
        "Bill Sales Ratio %",
    ],
    "Monthly": [
        "Period",
        "Outlet",
        "Item Name",
        "Category",
        "Sales",
        "Transaction",
        "Quantity",
        "Wastage",
        "Bill Sales",
        "Sales Ratio %",
        "Quantity Ratio %",
        "Wastage Ratio %",
        "Bill Sales Ratio %",
    ],
    "Period": [
        "Outlet",
        "Item Name",
        "Category",
        "Sales",
        "Transaction",
        "Quantity",
        "Wastage",
        "Bill Sales",
        "Sales Ratio %",
        "Quantity Ratio %",
        "Wastage Ratio %",
        "Bill Sales Ratio %",
    ],
}

APP_STYLESHEET = """
QMainWindow {
    background-color: #111d3d;
    color: #e9f1ff;
}
QWidget#CentralWidget {
    background-color: #111d3d;
}
QGroupBox {
    border: 1px solid #27437a;
    border-radius: 14px;
    margin-top: 12px;
    padding: 20px;
    background-color: #1b2c59;
    box-shadow: 0 8px 20px rgba(17, 29, 61, 0.42);
}
QGroupBox:title {
    subcontrol-origin: margin;
    subcontrol-position: top left;
    padding: 0 0 10px 0;
    color: #6ea8fe;
    font-size: 16px;
    font-weight: 600;
}
QLabel {
    color: #e9f1ff;
    font-size: 13px;
}
QToolButton, QPushButton {
    background-color: qlineargradient(x1:0, y1:0, x2:1, y2:1,
        stop:0 #4d7cfe, stop:1 #6ea8fe);
    color: #f8faff;
    border-radius: 9px;
    padding: 6px 16px;
    border: 1px solid #517dff;
}
QToolButton:hover, QPushButton:hover {
    background-color: qlineargradient(x1:0, y1:0, x2:1, y2:1,
        stop:0 #5a88ff, stop:1 #82b0ff);
    border-color: #82b0ff;
}
QToolButton:pressed, QPushButton:pressed {
    background-color: qlineargradient(x1:0, y1:0, x2:1, y2:1,
        stop:0 #385ddc, stop:1 #4c78e6);
}
QToolButton:disabled, QPushButton:disabled {
    color: #9ba7c1;
    background-color: #1b2c59;
    border: 1px solid #233968;
}
QMenuBar {
    background-color: #162650;
    color: #e9f1ff;
}
QMenuBar::item:selected {
    background-color: #4d7cfe;
}
QMenu {
    background-color: #152046;
    color: #e9f1ff;
    border: 1px solid #233968;
}
QPlainTextEdit, QTextEdit {
    background-color: #16254d;
    color: #e9f1ff;
    border-radius: 12px;
    border: 1px solid #233968;
}
QDateEdit, QComboBox, QLineEdit {
    padding: 4px 12px;
    border-radius: 10px;
    background-color: #152347;
    color: #e9f1ff;
    border: 1px solid #244170;
}
QDateEdit:focus, QComboBox:focus, QLineEdit:focus {
    border-color: #6ea8fe;
    background-color: #1d3461;
}
QTabWidget::pane {
    border: 1px solid #233968;
    border-radius: 14px;
    background-color: #152347;
}
QTabBar::tab {
    background: #142240;
    color: #a9b7d6;
    padding: 10px 24px;
    border-top-left-radius: 12px;
    border-top-right-radius: 12px;
    border: 1px solid transparent;
}
QTabBar::tab:selected {
    background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
        stop:0 #4d7cfe, stop:1 #6ea8fe);
    color: #f8faff;
    border-color: #6ea8fe;
}
QSplitter::handle {
    background-color: #1a2a4f;
    margin: 4px 0;
}
QToolBar {
    background-color: #152347;
    border: 0px;
    spacing: 6px;
}
QToolBar QToolButton {
    margin: 0 4px;
}
QWidget#HeaderFrame {
    background-color: qlineargradient(spread:pad, x1:0, y1:0, x2:1, y2:1,
        stop:0 rgba(77, 124, 254, 0.75), stop:1 rgba(110, 168, 254, 0.55));
    border-radius: 18px;
    border: 1px solid rgba(110, 168, 254, 0.6);
    padding: 20px;
}
QLabel#HeaderTitle {
    color: #f8fbff;
    font-size: 20px;
    font-weight: 700;
}
QFrame#SearchCard {
    background-color: #152347;
    border-radius: 14px;
    border: 1px solid #233968;
}
QSplitter#MainSplitter::handle {
    background-color: #1a2a4f;
}
QScrollBar:vertical {
    background: #152347;
    width: 12px;
    margin: 12px 0 12px 0;
    border-radius: 6px;
}
QScrollBar::handle:vertical {
    background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
        stop:0 #4d7cfe, stop:1 #6ea8fe);
    border-radius: 6px;
}
QScrollBar::handle:vertical:hover {
    background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
        stop:0 #5a88ff, stop:1 #82b0ff);
}
QScrollBar::handle:vertical:pressed {
    background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
        stop:0 #385ddc, stop:1 #4c78e6);
}
"""

FLUENT_BUTTON_STYLES_TEMPLATE = """
QToolButton {{
    background-color: {base};
    color: {text};
    border: 1px solid {border};
    border-radius: 8px;
    padding: 6px 14px;
}}
QToolButton::menu-indicator {{
    width: 12px;
    image: none;
}}
QToolButton::menu-indicator:subcontrol-position {{
    right: 10px;
}}
QToolButton:hover {{
    background-color: {hover};
    border-color: {accent};
    color: {accent_text};
}}
QToolButton:pressed {{
    background-color: {pressed};
    border-color: {accent};
}}
QToolBar {{
    background: transparent;
    border: none;
    spacing: 8px;
}}
QPushButton {{
    background-color: {base};
    color: {text};
    border: 1px solid {border};
    border-radius: 8px;
    padding: 6px 20px;
    font-weight: 600;
}}
QPushButton:hover {{
    background-color: {hover};
    border-color: {accent};
    color: {accent_text};
}}
QPushButton:pressed {{
    background-color: {pressed};
    border-color: {accent};
}}
"""


THEME_SCHEMES: Dict[str, Dict[str, str]] = {
    "classic_dark": {
        "name": "Classic Dark",
        "accent": "#2563eb",
        "window": "#0f172a",
        "base": "#111827",
        "text": "#e2e8f0",
        "button": "#1d4ed8",
        "button_text": "#f8fafc",
        "hover": "#2563eb",
        "pressed": "#1e3a8a",
        "accent_text": "#f8fafc",
        "border": "#1f2937",
        "panel_bg": "#172554",
        "input_bg": "#1b2742",
        "input_hover": "#20304d",
        "placeholder": "#94a3b8",
        "card_bg": "#0d1629",
        "central_stylesheet": "background: qlineargradient(x1:0,y1:0,x2:1,y2:1, stop:0 #0f172a, stop:1 #09101e); color: #e2e8f0;",
        "qtheme": "dark",
        "shadow": "rgba(8, 12, 24, 160)",
    },
    "warm_light": {
        "name": "Pure Light",
        "accent": "#60a5fa",
        "window": "#f3f6fc",
        "base": "#ffffff",
        "text": "#1e293b",
        "button": "#d9e8ff",
        "button_text": "#0f172a",
        "hover": "#c1d9ff",
        "pressed": "#8fb3ff",
        "accent_text": "#0f172a",
        "border": "#bccCDC",
        "panel_bg": "#ffffff",
        "input_bg": "#eef4ff",
        "input_hover": "#dbe9ff",
        "placeholder": "#64748b",
        "card_bg": "#f7faff",
        "central_stylesheet": "background: qlineargradient(x1:0,y1:0,x2:1,y2:1, stop:0 #f8fbff, stop:1 #edf5ff); color: #1e293b;",
        "qtheme": "light",
        "shadow": "rgba(15, 23, 42, 90)",
    },
    "neon_night": {
        "name": "Neon Purple",
        "accent": "#a855f7",
        "window": "#0a0620",
        "base": "#120b38",
        "text": "#f8f6ff",
        "button": "#2f1e8a",
        "button_text": "#f8f6ff",
        "hover": "#3d27b0",
        "pressed": "#241973",
        "accent_text": "#f1e9ff",
        "border": "#2a1d5c",
        "panel_bg": "#151046",
        "input_bg": "#1c1854",
        "input_hover": "#261f60",
        "placeholder": "#c4b8ff",
        "card_bg": "#0f0a33",
        "central_stylesheet": "background: qlineargradient(x1:0,y1:0,x2:1,y2:1, stop:0 #0b0726, stop:1 #130d3f); color: #f8f6ff;",
        "qtheme": "dark",
        "shadow": "rgba(20, 16, 70, 180)",
    },
    "azure_glow": {
        "name": "Azure Blue",
        "accent": "#4d7cfe",
        "window": "#111d3d",
        "base": "#1b2c59",
        "text": "#e9f1ff",
        "button": "#3154c5",
        "button_text": "#e9f1ff",
        "hover": "#3f63df",
        "pressed": "#2748a6",
        "accent_text": "#f5f9ff",
        "border": "#243764",
        "panel_bg": "#192c57",
        "input_bg": "#23376d",
        "input_hover": "#2b3f78",
        "placeholder": "#c7d6ff",
        "card_bg": "#132042",
        "central_stylesheet": "background: qlineargradient(x1:0,y1:0,x2:1,y2:1, stop:0 #152345, stop:1 #0f1a32); color: #e9f1ff;",
        "qtheme": "dark",
        "shadow": "rgba(13, 22, 50, 170)",
    },
    "express_deep_blue": {
        "name": "Express Deep Blue",
        "accent": "#3b74ff",
        "window": "#090f1f",
        "base": "#101a33",
        "text": "#e4ecff",
        "button": "#284b9e",
        "button_text": "#f2f6ff",
        "hover": "#3560d4",
        "pressed": "#1d3a7f",
        "accent_text": "#f2f6ff",
        "border": "#2d3e62",
        "panel_bg": "#1b253a",
        "input_bg": "#202d45",
        "input_hover": "#25334f",
        "placeholder": "#9fb6e3",
        "card_bg": "#141d30",
        "central_stylesheet": "background: qlineargradient(x1:0,y1:0,x2:1,y2:1, stop:0 #0a1326, stop:1 #101b32); color: #e4ecff;",
        "qtheme": "dark",
        "shadow": "rgba(12, 18, 38, 180)",
    },
}


def bilingual(cn: str, en: str) -> str:
    return f"{cn}\n{en}"


@dataclass
class FilterState:
    date_from: Optional[date] = None
    date_to: Optional[date] = None
    outlets: List[str] = field(default_factory=list)
    months: List[str] = field(default_factory=list)
    weeks: List[str] = field(default_factory=list)
    payments: List[str] = field(default_factory=list)
    categories: List[str] = field(default_factory=list)
    products: List[str] = field(default_factory=list)
    brands: List[str] = field(default_factory=list)
    discounts: List[str] = field(default_factory=list)
    weekdays: List[int] = field(default_factory=list)
    promotion_name: Optional[str] = None
    promotion_details: Optional[str] = None
    promotion_types: List[str] = field(default_factory=list)


@dataclass
class PaymentDisplayOptions:
    show_total: bool = False
    daily_average: bool = False
    outlet_average: bool = False
    period_mode: str = "Monthly"


@dataclass
class SalesDataFrames:
    details: pd.DataFrame
    payments: pd.DataFrame


@dataclass
class SalesReportFrames:
    details: pd.DataFrame
    payment_analysis: Dict[str, pd.DataFrame]
    discount_analysis: Dict[str, pd.DataFrame]
    product_analysis: Dict[str, pd.DataFrame]
    promotion_analysis: Dict[str, pd.DataFrame] = field(default_factory=dict)
    store_brand_map: pd.DataFrame = field(default_factory=pd.DataFrame)
    active_store_counts: Dict[str, int] = field(default_factory=dict)
    base_details: pd.DataFrame = field(default_factory=pd.DataFrame)
    base_payments: pd.DataFrame = field(default_factory=pd.DataFrame)
    base_state: FilterState = field(default_factory=FilterState)


@dataclass
class SalesRawFrames:
    detail: pd.DataFrame
    payments: pd.DataFrame


@dataclass
class ActivityRecord:
    id: str
    name: str
    details: str
    date_from: Optional[date]
    date_to: Optional[date]
    weekdays: List[int]
    outlets: List[str]
    brands: List[str]
    categories: List[str]
    products: List[str]
    discounts: List[str]
    promotion_types: List[str]
    created_at: datetime

    def to_dict(self) -> Dict[str, object]:
        return {
            "id": self.id,
            "name": self.name,
            "details": self.details,
            "date_from": self.date_from.isoformat() if self.date_from else None,
            "date_to": self.date_to.isoformat() if self.date_to else None,
            "weekdays": list(self.weekdays),
            "outlets": list(self.outlets),
            "brands": list(self.brands),
            "categories": list(self.categories),
            "products": list(self.products),
            "discounts": list(self.discounts),
            "promotion_types": list(self.promotion_types),
            "created_at": self.created_at.isoformat(),
        }

    @classmethod
    def from_dict(cls, payload: Dict[str, object]) -> "ActivityRecord":
        raw_date_from = payload.get("date_from")
        raw_date_to = payload.get("date_to")
        date_from_value = datetime.fromisoformat(str(raw_date_from)).date() if raw_date_from else None
        date_to_value = datetime.fromisoformat(str(raw_date_to)).date() if raw_date_to else None

        weekdays_payload = payload.get("weekdays") or []
        weekdays_list = [int(value) for value in weekdays_payload]

        created_at_raw = payload.get("created_at")
        created_at_value = (
            datetime.fromisoformat(str(created_at_raw))
            if created_at_raw
            else datetime.now(timezone.utc)
        )

        return cls(
            id=str(payload.get("id", uuid.uuid4())),
            name=str(payload.get("name", "")),
            details=str(payload.get("details", "")),
            date_from=date_from_value,
            date_to=date_to_value,
            weekdays=weekdays_list,
            outlets=[str(value) for value in payload.get("outlets", [])],
            brands=[str(value) for value in payload.get("brands", [])],
            categories=[str(value) for value in payload.get("categories", [])],
            products=[str(value) for value in payload.get("products", [])],
            discounts=[str(value) for value in payload.get("discounts", [])],
            promotion_types=[str(value) for value in payload.get("promotion_types", [])],
            created_at=created_at_value,
        )


@dataclass
class BrandCacheEntry:
    detail: pd.DataFrame
    payments: pd.DataFrame
    date_from: Optional[date]
    date_to: Optional[date]


@dataclass
class AggregationPeriodMeta:
    key: str
    start: date
    end: date
    files: Dict[str, str]
    updated_at: datetime

    def to_dict(self) -> Dict[str, object]:
        return {
            "key": self.key,
            "start": self.start.isoformat(),
            "end": self.end.isoformat(),
            "files": dict(self.files),
            "updated_at": self.updated_at.isoformat(),
        }

    @classmethod
    def from_dict(cls, payload: Dict[str, object]) -> "AggregationPeriodMeta":
        key = str(payload.get("key", ""))
        start = datetime.fromisoformat(str(payload["start"])) if payload.get("start") else datetime.min
        end = datetime.fromisoformat(str(payload["end"])) if payload.get("end") else datetime.min
        updated_at_raw = payload.get("updated_at")
        updated_at = (
            datetime.fromisoformat(str(updated_at_raw))
            if updated_at_raw
            else datetime.now(timezone.utc)
        )
        files = {str(k): str(v) for k, v in dict(payload.get("files", {})).items()}
        return cls(key=key, start=start.date(), end=end.date(), files=files, updated_at=updated_at)


@dataclass
class AggregationCacheMetadata:
    brand: str
    periods: Dict[str, AggregationPeriodMeta] = field(default_factory=dict)
    version: int = 1

    def to_dict(self) -> Dict[str, object]:
        return {
            "brand": self.brand,
            "version": self.version,
            "periods": {key: meta.to_dict() for key, meta in self.periods.items()},
        }

    @classmethod
    def from_dict(cls, payload: Dict[str, object]) -> "AggregationCacheMetadata":
        brand = str(payload.get("brand", ""))
        version = int(payload.get("version", 1))
        raw_periods = payload.get("periods", {}) or {}
        periods: Dict[str, AggregationPeriodMeta] = {}
        for key, meta_payload in dict(raw_periods).items():
            try:
                periods[str(key)] = AggregationPeriodMeta.from_dict(meta_payload)
            except Exception:
                continue
        return cls(brand=brand, periods=periods, version=version)


class DataCachePaths:
    """Helper to describe on-disk cache assets for a database."""

    def __init__(self, db_name: str) -> None:
        self.db_name = db_name
        storage_duckdb.ensure_layout(db_name)

    @property
    def duckdb_path(self) -> Path:
        if self.db_name == "sushi_epoint_pos_live":
            print(f"[DEBUG] ===== STARTING EPOINT DB FILE SEARCH =====")
            print(f"[DEBUG] Current working directory: {Path.cwd()}")
            
            # For Epoint, find the most recent date file
            cache_dir = Path(".pos_cache") / self.db_name
            print(f"[DEBUG] Looking for Epoint database files in: {cache_dir.absolute()}")
            print(f"[DEBUG] Directory exists: {cache_dir.exists()}")
            
            date_files = self.get_epoint_date_files()
            print(f"[DEBUG] Found {len(date_files)} Epoint database files")
            
            if date_files:
                # Return the path from the most recent (should already be sorted by get_epoint_date_files)
                most_recent = date_files[-1][0]  # Get the path from the (path, date) tuple
                print(f"[DEBUG] Using most recent Epoint database file: {most_recent}")
                print(f"[DEBUG] File exists: {most_recent.exists()}")
                print(f"[DEBUG] ===== END EPOINT DB FILE SEARCH =====")
                return most_recent
            else:
                print("[WARNING] No Epoint database files found. Falling back to default location.")
                
        # Default path for non-Epoint databases or if no date files found
        default_path = Path(".pos_cache") / self.db_name / "pos.duckdb"
        print(f"[DEBUG] Using default database path: {default_path.absolute()}")
        print(f"[DEBUG] Default path exists: {default_path.exists()}")
        print(f"[DEBUG] ===== END EPOINT DB FILE SEARCH =====")
        return default_path
        
    def get_epoint_date_files(self) -> List[Tuple[Path, date, List[str]]]:
        """Get all date-based Epoint database files, sorted by date.
        
        Looks for files in the format: .pos_cache/sushi_epoint_pos_live/pos_YYYYMMDD.duckdb
        
        Returns:
            List of tuples containing (file_path, date, table_names) for each database file
        """
        if self.db_name != "sushi_epoint_pos_live":
            print(f"[DEBUG] Not an Epoint database: {self.db_name}")
            return []
            
        epoint_dir = Path(".pos_cache") / self.db_name
        date_files = []
        
        print(f"[DEBUG] Searching for Epoint database files in: {epoint_dir.absolute()}")
        
        # Check if the directory exists
        if not epoint_dir.exists():
            print(f"[ERROR] Epoint directory does not exist: {epoint_dir.absolute()}")
            return []
            
        # List all files in the directory for debugging
        print("[DEBUG] Directory contents:")
        for item in epoint_dir.glob("*"):
            print(f"  - {item.name} (dir: {item.is_dir()})")
        
        def check_db_file(db_path: Path) -> Tuple[Path, date, List[str]]:
            """Check a database file and return its path, date, and table list."""
            try:
                # Extract date from filename (pos_YYYYMMDD.duckdb)
                date_str = db_path.stem.split('_')[-1]
                file_date = datetime.strptime(date_str, "%Y%m%d").date()
                
                # Check what tables exist in the database
                try:
                    conn = duckdb.connect(str(db_path), read_only=True)
                    tables = [row[0] for row in conn.execute("SHOW TABLES").fetchall()]
                    conn.close()
                    print(f"[DEBUG] Found {len(tables)} tables in {db_path}: {', '.join(tables) or 'None'}")
                    return (db_path, file_date, tables)
                except Exception as e:
                    print(f"[WARNING] Error checking tables in {db_path}: {str(e)}")
                    return (db_path, file_date, [])
                    
            except (ValueError, IndexError) as e:
                print(f"[WARNING] Error processing file {db_path}: {str(e)}")
                return (db_path, date.today(), [])
        
        # Look for database files directly in the epoint directory
        print("[DEBUG] Looking for direct database files...")
        for db_file in epoint_dir.glob("pos_*.duckdb"):
            result = check_db_file(db_file)
            if result[2]:  # Only add if we found tables
                date_files.append(result)
        
        # Also check for date-based subdirectories (format: YYYYMMDD/pos_YYYYMMDD.duckdb)
        print("[DEBUG] Checking for date-based subdirectories...")
        for date_dir in epoint_dir.glob("*"):
            if not date_dir.is_dir() or not date_dir.name.isdigit() or len(date_dir.name) != 8:
                continue
                
            db_file = date_dir / f"pos_{date_dir.name}.duckdb"
            if db_file.exists():
                result = check_db_file(db_file)
                if result[2]:  # Only add if we found tables
                    date_files.append(result)
        
        # Sort by date
        date_files.sort(key=lambda x: x[1])
        
        # Filter out files that don't have the required tables
        filtered_files = []
        for db_file, file_date, tables in date_files:
            tables_lower = [t.lower() for t in tables]
            if 'raw_details' in tables_lower and 'raw_payments' in tables_lower:
                filtered_files.append((db_file, file_date))
                print(f"[DEBUG] Valid database file: {db_file} (tables: {', '.join(tables)})")
            else:
                print(f"[WARNING] Skipping {db_file}: missing required tables (found: {', '.join(tables) or 'none'})")
        
        print(f"[DEBUG] Found {len(filtered_files)} valid Epoint database files")
        return filtered_files

    @property
    def parquet_root(self) -> Path:
        return Path(".pos_cache") / self.db_name / "parquet"

    def parquet_dir(self, table: str) -> Path:
        return self.parquet_root / table

    # ------------------------------------------------------------------
    # Aggregation cache helpers
    # ------------------------------------------------------------------
    def aggregates_root(self) -> Path:
        path = Path(".pos_cache") / self.db_name / "aggregates"
        path.mkdir(parents=True, exist_ok=True)
        return path

    def aggregates_dir(self, kind: str) -> Path:
        path = self.aggregates_root() / kind
        path.mkdir(parents=True, exist_ok=True)
        return path

    def aggregates_metadata_path(self) -> Path:
        return self.aggregates_root() / "metadata.json"


class DataRepository(QtCore.QObject):
    """Coordinates local DuckDB cache and remote SQL Server fetching."""

    log_message = QtCore.pyqtSignal(str)
    filters_ready = QtCore.pyqtSignal(object, object)
    filters_failed = QtCore.pyqtSignal(object, object)
    repair_completed = QtCore.pyqtSignal(str)

    def __init__(self, parent: Optional[QtCore.QObject] = None) -> None:
        super().__init__(parent)
        self.cache_paths: Dict[str, DataCachePaths] = {
            name: DataCachePaths(name) for name in [*DATABASES, COMBINED_DATABASE]
        }
        self._tasks: Set[BackgroundTask] = set()
        self._brand_raw_cache: Dict[str, BrandCacheEntry] = {}
        self._brand_cache_lock = threading.Lock()
        self._filter_cache: Dict[Tuple[str, ...], Dict[str, List[str]]] = {}
        self._connections: Dict[str, duckdb.DuckDBPyConnection] = {}
        self._repair_queue: "deque[Tuple[str, Path]]" = deque()
        self._repair_active = False
        self._aggregation_metadata_cache: Dict[str, AggregationCacheMetadata] = {}
        self._activity_records: List[ActivityRecord] = []

    def invalidate_caches(
        self,
        *,
        filters: bool = True,
        brands: bool = True,
        aggregates: bool = True,
    ) -> None:
        if filters:
            self._filter_cache.clear()
        if aggregates:
            self._aggregation_metadata_cache.clear()
        if brands:
            with self._brand_cache_lock:
                self._brand_raw_cache.clear()

    def _invalidate_brand_cache(self, db_name: str) -> None:
        with self._brand_cache_lock:
            self._brand_raw_cache.pop(db_name, None)

    def _invalidate_aggregates_for_range(
        self,
        db_name: str,
        start_date: Optional[date],
        end_date: Optional[date],
    ) -> None:
        metadata = self._load_aggregation_metadata(db_name)
        cache_paths = self.cache_paths[db_name]

        if start_date and end_date and start_date > end_date:
            start_date, end_date = end_date, start_date

        if start_date is None or end_date is None:
            keys = list(metadata.periods.keys())
        else:
            months: List[date] = []
            current = date(start_date.year, start_date.month, 1)
            last = date(end_date.year, end_date.month, 1)
            while current <= last:
                months.append(current)
                current = (current.replace(day=28) + timedelta(days=4)).replace(day=1)
            keys = [self._aggregation_period_key(month) for month in months]

        removed = False
        for key in keys:
            meta = metadata.periods.pop(key, None)
            if meta is None:
                continue
            for label, filename in meta.files.items():
                if not filename:
                    continue
                directory = "details" if label == "detail" else "payments"
                target = cache_paths.aggregates_dir(directory) / filename
                if target.exists():
                    try:
                        target.unlink()
                    except OSError:
                        pass
            removed = True

        if removed:
            self._save_aggregation_metadata(db_name, metadata)
        self._aggregation_metadata_cache.pop(db_name, None)

    def _invalidate_post_sync_caches(
        self,
        db_name: str,
        range_start: Optional[datetime],
        range_end: Optional[datetime],
    ) -> None:
        start_date = range_start.date() if range_start is not None else None
        end_date = range_end.date() if range_end is not None else None
        self._invalidate_brand_cache(db_name)
        self._invalidate_aggregates_for_range(db_name, start_date, end_date)

    # ------------------------------------------------------------------
    # DuckDB helpers
    # ------------------------------------------------------------------
    def duckdb_connection(self, db_name: str) -> duckdb.DuckDBPyConnection:
        if db_name not in self._connections:
            self._connections[db_name] = storage_duckdb.open_conn(db_name)
        return self._connections[db_name]

    def close(self) -> None:
        for conn in self._connections.values():
            conn.close()
        self._connections.clear()
        try:
            self._save_activity_records()
        except Exception:
            pass

    # ------------------------------------------------------------------
    # Aggregation metadata helpers
    # ------------------------------------------------------------------
    @staticmethod
    def _brand_label(source: Optional[str]) -> str:
        source_lower = (source or "").lower()
        if "gogo" in source_lower:
            return "GOGO"
        if "express" in source_lower:
            return "SE"
        if "plus" in source_lower:
            return "PLUS"
        return "Other"

    def _load_aggregation_metadata(self, db_name: str) -> AggregationCacheMetadata:
        if db_name in self._aggregation_metadata_cache:
            return self._aggregation_metadata_cache[db_name]

        path = self.cache_paths[db_name].aggregates_metadata_path()
        if not path.exists():
            meta = AggregationCacheMetadata(brand=db_name)
            self._aggregation_metadata_cache[db_name] = meta
            return meta

        try:
            payload = json.loads(path.read_text(encoding="utf-8"))
        except Exception:
            meta = AggregationCacheMetadata(brand=db_name)
        else:
            meta = AggregationCacheMetadata.from_dict(payload)
            if not meta.brand:
                meta.brand = db_name
        self._aggregation_metadata_cache[db_name] = meta
        return meta

    def _save_aggregation_metadata(self, db_name: str, metadata: AggregationCacheMetadata) -> None:
        path = self.cache_paths[db_name].aggregates_metadata_path()
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(json.dumps(metadata.to_dict(), indent=2, ensure_ascii=False), encoding="utf-8")
        self._aggregation_metadata_cache[db_name] = metadata

    def _aggregation_period_key(self, period_start: date) -> str:
        return period_start.strftime("%Y-%m")

    # ------------------------------------------------------------------
    # Activity record persistence
    # ------------------------------------------------------------------
    def _activity_records_path(self) -> Path:
        return self.cache_paths[COMBINED_DATABASE].aggregates_root() / "activity_records.json"

    def _load_activity_records(self) -> None:
        path = self._activity_records_path()
        if not path.exists():
            self._activity_records = []
            return
        try:
            payload = json.loads(path.read_text(encoding="utf-8"))
        except Exception:
            self._activity_records = []
            return
        records_payload = payload.get("records", []) if isinstance(payload, dict) else []
        self._activity_records = []
        for record_payload in records_payload:
            try:
                record = ActivityRecord.from_dict(record_payload)
            except Exception:
                continue
            self._activity_records.append(record)

    def _save_activity_records(self) -> None:
        path = self._activity_records_path()
        path.parent.mkdir(parents=True, exist_ok=True)
        payload = {"records": [record.to_dict() for record in self._activity_records]}
        path.write_text(json.dumps(payload, indent=2, ensure_ascii=False), encoding="utf-8")

    def list_activity_records(self) -> List[ActivityRecord]:
        if not self._activity_records:
            self._load_activity_records()
        return list(self._activity_records)

    def add_activity_record(self, record: ActivityRecord) -> ActivityRecord:
        if not self._activity_records:
            self._load_activity_records()
        record_id = record.id or str(uuid.uuid4())
        record.id = record_id
        self._activity_records = [existing for existing in self._activity_records if existing.id != record_id]
        self._activity_records.append(record)
        self._activity_records.sort(key=lambda r: r.created_at, reverse=True)
        self._save_activity_records()
        return record

    def delete_activity_record(self, record_id: str) -> bool:
        if not self._activity_records:
            self._load_activity_records()
        before = len(self._activity_records)
        self._activity_records = [record for record in self._activity_records if record.id != record_id]
        removed = len(self._activity_records) != before
        if removed:
            self._save_activity_records()
        return removed

    def _load_cached_raw_frames(
        self, db_name: str, period_keys: Optional[Iterable[str]] = None
    ) -> SalesRawFrames:
        metadata = self._load_aggregation_metadata(db_name)
        if not metadata.periods:
            return SalesRawFrames(pd.DataFrame(), pd.DataFrame())

        selected_keys = set(period_keys) if period_keys is not None else set(metadata.periods.keys())
        detail_frames: List[pd.DataFrame] = []
        payment_frames: List[pd.DataFrame] = []

        cache_path = self.cache_paths[db_name]

        for key in selected_keys:
            meta = metadata.periods.get(key)
            if not meta:
                continue

            detail_filename = meta.files.get("detail")
            if detail_filename:
                detail_path = cache_path.aggregates_dir("details") / detail_filename
                if detail_path.exists():
                    try:
                        detail_frames.append(pd.read_parquet(detail_path))
                    except Exception:
                        pass

            payments_filename = meta.files.get("payments")
            if payments_filename:
                payments_path = cache_path.aggregates_dir("payments") / payments_filename
                if payments_path.exists():
                    try:
                        payment_frames.append(pd.read_parquet(payments_path))
                    except Exception:
                        pass

        detail_df = pd.concat(detail_frames, ignore_index=True) if detail_frames else pd.DataFrame()
        payment_df = pd.concat(payment_frames, ignore_index=True) if payment_frames else pd.DataFrame()
        return SalesRawFrames(detail_df, payment_df)

    def _save_cached_raw_frames(
        self,
        db_name: str,
        period_start: date,
        period_end: date,
        detail_frame: pd.DataFrame,
        payments_frame: pd.DataFrame,
    ) -> None:
        key = self._aggregation_period_key(period_start)
        metadata = self._load_aggregation_metadata(db_name)

        cache_paths = self.cache_paths[db_name]
        timestamp = datetime.now(timezone.utc).strftime("%Y%m%d%H%M%S")

        # clean previous files for this key
        previous = metadata.periods.get(key)
        if previous:
            for label, filename in previous.files.items():
                if not filename:
                    continue
                directory = "details" if label == "detail" else "payments"
                target = cache_paths.aggregates_dir(directory) / filename
                if target.exists():
                    try:
                        target.unlink()
                    except OSError:
                        pass

        files: Dict[str, str] = {}

        if not detail_frame.empty:
            detail_filename = f"{key}_detail_{timestamp}.parquet"
            detail_path = cache_paths.aggregates_dir("details") / detail_filename
            detail_frame.to_parquet(detail_path, index=False)
            files["detail"] = detail_filename

        if not payments_frame.empty:
            payments_filename = f"{key}_payments_{timestamp}.parquet"
            payments_path = cache_paths.aggregates_dir("payments") / payments_filename
            payments_frame.to_parquet(payments_path, index=False)
            files["payments"] = payments_filename

        metadata.periods[key] = AggregationPeriodMeta(
            key=key,
            start=period_start,
            end=period_end,
            files=files,
            updated_at=datetime.now(timezone.utc),
        )
        self._save_aggregation_metadata(db_name, metadata)

    def _ensure_monthly_raw_frames(self, db_name: str, month_starts: Sequence[date]) -> None:
        if not month_starts:
            return

        metadata = self._load_aggregation_metadata(db_name)
        missing = []
        for month_start in month_starts:
            key = self._aggregation_period_key(month_start)
            if key not in metadata.periods:
                missing.append(month_start)

        for month_start in missing:
            month_end = self._month_end(month_start)
            raw_frames = self._load_brand_raw_frames(db_name, month_start, month_end)
            self._save_cached_raw_frames(db_name, month_start, month_end, raw_frames.detail, raw_frames.payments)

    def _persist_raw_frames_by_month(
        self,
        db_name: str,
        detail_frame: pd.DataFrame,
        payments_frame: pd.DataFrame,
    ) -> None:
        if detail_frame.empty and payments_frame.empty:
            return

        detail_copy = detail_frame.copy() if not detail_frame.empty else pd.DataFrame()
        payments_copy = payments_frame.copy() if not payments_frame.empty else pd.DataFrame()

        detail_copy["_dt"] = pd.to_datetime(detail_copy.get("c_date"), errors="coerce")
        payments_copy["_dt"] = pd.to_datetime(payments_copy.get("c_date"), errors="coerce")

        timestamps = []
        if not detail_copy.empty:
            timestamps.append(detail_copy["_dt"].dropna())
        if not payments_copy.empty:
            timestamps.append(payments_copy["_dt"].dropna())

        if not timestamps:
            return

        min_ts = min(series.min() for series in timestamps if not series.empty)
        max_ts = max(series.max() for series in timestamps if not series.empty)
        if pd.isna(min_ts) or pd.isna(max_ts):
            return

        start_month = date(min_ts.year, min_ts.month, 1)
        end_month = date(max_ts.year, max_ts.month, 1)

        current = start_month
        while current <= end_month:
            month_end = self._month_end(current)
            start_ts = pd.Timestamp(current)
            end_ts = pd.Timestamp(month_end) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)

            detail_month = detail_copy.loc[(detail_copy["_dt"] >= start_ts) & (detail_copy["_dt"] <= end_ts)].drop(columns=["_dt"], errors="ignore")
            payments_month = payments_copy.loc[(payments_copy["_dt"] >= start_ts) & (payments_copy["_dt"] <= end_ts)].drop(columns=["_dt"], errors="ignore")

            self._save_cached_raw_frames(db_name, current, month_end, detail_month, payments_month)

            next_month = (current.replace(day=28) + timedelta(days=4)).replace(day=1)
            current = next_month

    def _month_end(self, month_start: date) -> date:
        return (month_start.replace(day=28) + timedelta(days=4)).replace(day=1) - timedelta(days=1)

    def _month_range(
        self,
        date_from: Optional[date],
        date_to: Optional[date],
        metadata: AggregationCacheMetadata,
    ) -> List[date]:
        if date_from and date_to and date_from > date_to:
            date_from, date_to = date_to, date_from

        if date_from is not None and date_to is not None:
            start = date(date_from.year, date_from.month, 1)
            end = date(date_to.year, date_to.month, 1)
        elif date_from is not None:
            start = end = date(date_from.year, date_from.month, 1)
        elif date_to is not None:
            start = end = date(date_to.year, date_to.month, 1)
        else:
            if not metadata.periods:
                return []
            keys = sorted(metadata.periods.keys())
            months: List[date] = []
            for key in keys:
                try:
                    month_start = datetime.strptime(key, "%Y-%m").date().replace(day=1)
                except ValueError:
                    continue
                months.append(month_start)
            return months

        months: List[date] = []
        current = start
        while current <= end:
            months.append(current)
            next_month = (current.replace(day=28) + timedelta(days=4)).replace(day=1)
            current = next_month
        return months

    # ------------------------------------------------------------------
    # Parquet repair utilities
    # ------------------------------------------------------------------
    @staticmethod
    def _server_config(db_name: str) -> Optional[Dict[str, str]]:
        # Return None for Epoint data to indicate it's not a SQL Server database
        if db_name == "sushi_epoint_pos_live":
            return None
            
        return {
            "server": f"{SERVER},1433",
            "database": db_name,
            "user": USER,
            "password": PASSWORD,
            "driver": "ODBC Driver 18 for SQL Server",
            "encrypt": "yes",
            "trust_server_certificate": "yes",
            "timeout": 30,
        }

    def _repair_quarantined_parquet(self, db_name: str, quarantined: Path) -> None:
        self._repair_queue.append((db_name, quarantined))
        if not self._repair_active:
            self._repair_active = True
            worker = BackgroundTask(self._process_repair_queue, parent=self)
            self._start_background_task(worker)

    def _process_repair_queue(self) -> None:
        while self._repair_queue:
            db_name, quarantined = self._repair_queue[0]
            repaired = self._perform_partition_repair(db_name, quarantined)
            if repaired:
                self.repair_completed.emit(db_name)
            self._repair_queue.popleft()
        self._repair_active = False

    def _perform_partition_repair(self, db_name: str, quarantined: Path) -> bool:
        table_name = quarantined.parent.name
        filename = quarantined.name

        original_name = filename[:-len(".corrupt")] if filename.endswith(".corrupt") else filename
        if original_name.endswith(".parquet"):
            original_name = original_name[:-len(".parquet")]

        partition_date: Optional[date]
        try:
            partition_date = datetime.strptime(original_name, "%Y-%m-%d").date()
        except ValueError:
            partition_date = None

        since_map: Optional[Dict[str, Optional[datetime]]] = None
        if partition_date is not None:
            since_map = {table_name: datetime.combine(partition_date, datetime.min.time())}

        cfg = self._server_config(db_name)
        try:
            self.log_message.emit(
                f"[REPAIR] {db_name}: rebuilding data for {table_name} ({original_name})."
            )
            storage_duckdb.sync_from_sqlserver(db_name, cfg, since_map)
        except Exception as exc:  # pragma: no cover - defensive log
            self.log_message.emit(
                f"[REPAIR] {db_name}: failed to repair parquet {quarantined.name} ({exc})."
            )
            return False
        return True

    # ------------------------------------------------------------------
    # Remote fetching skeleton
    # ------------------------------------------------------------------
    def sync_remote_tables(
        self,
        target_databases: Optional[Iterable[str]] = None,
        *,
        single_date: Optional[date] = None,
        start_date: Optional[date] = None,
        end_date: Optional[date] = None,
    ) -> None:
        """
        Pull fresh data from SQL Server and store into parquet+DuckDB caches.
        For Epoint data, this just validates that the local DuckDB files exist.

        When ``single_date`` is provided, only that day's data is synchronized.
        """
        target_dbs = list(target_databases or DATABASES)
        if single_date and (start_date or end_date):
            raise ValueError("Cannot specify both single_date and start/end range.")

        if single_date is not None:
            start_date = single_date
            end_date = single_date

        range_start_dt = datetime.combine(start_date, datetime.min.time()) if start_date else None
        range_end_dt = datetime.combine(end_date, datetime.max.time()) if end_date else None

        successes: List[str] = []
        failures: List[str] = []

        def _sync_database(db_name: str) -> bool:
            # Handle Epoint data (local DuckDB files)
            if db_name == "sushi_epoint_pos_live":
                # Just check if we have any Epoint data files
                epoint_files = list(Path(".pos_cache").glob("sushi_epoint_pos_live/pos_*.duckdb"))
                if not epoint_files:
                    self.log_message.emit(
                        "[SYNC] sushi_epoint_pos_live: No Epoint data files found. "
                        "Please run the Epoint data processing script first."
                    )
                    return False
                self.log_message.emit(
                    f"[SYNC] sushi_epoint_pos_live: Found {len(epoint_files)} data files"
                )
                return True
                
            # Handle SQL Server databases
            cfg = {
                "server": f"{SERVER},1433",
                "database": db_name,
                "user": USER,
                "password": PASSWORD,
                "driver": "ODBC Driver 18 for SQL Server",
                "encrypt": "yes",
                "trust_server_certificate": "yes",
                "timeout": 30,
            }

            attempt = 0
            last_exc: Optional[Exception] = None
            while attempt < 3:
                attempt += 1
                try:
                    if range_start_dt or range_end_dt:
                        range_label_start = start_date.isoformat() if start_date else "-∞"
                        range_label_end = end_date.isoformat() if end_date else "+∞"
                        self.log_message.emit(
                            f"[SYNC] {db_name}: downloading data for {range_label_start} ~ {range_label_end} (attempt {attempt}/3)"
                        )
                        since_map = {
                            table: range_start_dt
                            for table in storage_duckdb.TABLE_DATE_COLUMN
                        }
                        until_map = {
                            table: range_end_dt
                            for table in storage_duckdb.TABLE_DATE_COLUMN
                        }
                        storage_duckdb.sync_from_sqlserver(
                            db_name,
                            cfg,
                            since=since_map,
                            until=until_map,
                        )
                    else:
                        self.log_message.emit(
                            f"[SYNC] {db_name}: incremental refresh (attempt {attempt}/3)"
                        )
                        storage_duckdb.init_and_sync(db_name, cfg)
                    self._invalidate_post_sync_caches(db_name, range_start_dt, range_end_dt)
                    return True
                except Exception as exc:  # pragma: no cover - defensive log
                    last_exc = exc
                    self.log_message.emit(
                        f"[SYNC] {db_name}: attempt {attempt} failed ({exc})."
                    )
                    if attempt < 3:
                        time.sleep(min(5, attempt * 2))
            if last_exc is not None:
                self.log_message.emit(
                    f"[SYNC] {db_name}: giving up after 3 attempts ({last_exc})."
                )
            return False

        worker_count = min(MAX_SYNC_WORKERS, len(target_dbs))
        if worker_count <= 1:
            for db in target_dbs:
                (successes if _sync_database(db) else failures).append(db)
        else:
            with ThreadPoolExecutor(max_workers=worker_count) as executor:
                futures = {executor.submit(_sync_database, db): db for db in target_dbs}
                for future in as_completed(futures):
                    db_name = futures[future]
                    try:
                        result = future.result()
                    except Exception as exc:  # pragma: no cover - defensive log
                        self.log_message.emit(f"[SYNC] {db_name}: unexpected failure ({exc}).")
                        failures.append(db_name)
                    else:
                        (successes if result else failures).append(db_name)

        if successes:
            self.log_message.emit(
                "[SYNC] Completed for: " + ", ".join(successes)
            )
        if failures:
            self.log_message.emit(
                "[SYNC] Failed databases: " + ", ".join(failures)
            )

        if successes and not failures:
            try:
                self._rebuild_combined_database(successes)
                self.log_message.emit(
                    f"[SYNC] {COMBINED_DATABASE}: refreshed with {len(successes)} sources."
                )
            except Exception as exc:  # pragma: no cover - defensive log
                self.log_message.emit(
                    f"[SYNC] {COMBINED_DATABASE}: refresh failed ({exc})."
                )
        elif failures:
            self.log_message.emit(
                f"[SYNC] {COMBINED_DATABASE}: skipped refresh because some databases failed."
            )

        self.log_message.emit("[SYNC] Synchronization complete.")

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------
    def _rebuild_combined_database(self, source_databases: Iterable[str]) -> None:
        sources = [db for db in dict.fromkeys(source_databases) if db in DATABASES]
        if not sources:
            return

        storage_duckdb.ensure_layout(COMBINED_DATABASE)
        existing = self._connections.pop(COMBINED_DATABASE, None)
        if existing is not None:
            existing.close()

        conn = duckdb.connect(str(self.cache_paths[COMBINED_DATABASE].duckdb_path))

        for table_name in TABLE_NAMES.values():
            file_paths: List[Path] = []
            for db in sources:
                parquet_dir = self.cache_paths[db].parquet_dir(table_name)
                file_paths.extend(sorted(parquet_dir.glob("*.parquet")))

            if not file_paths:
                continue

            literals = ", ".join(
                f"'{path.as_posix().replace("'", "''")}'" for path in file_paths
            )
            relation_sql = f"read_parquet([{literals}], union_by_name = TRUE)"
            conn.execute(
                f"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM {relation_sql}"
            )

        conn.execute("CHECKPOINT")
        conn.close()
        self._invalidate_brand_cache(COMBINED_DATABASE)
        self._aggregation_metadata_cache.pop(COMBINED_DATABASE, None)

    def load_filter_options(self, state: Optional[FilterState] = None) -> Dict[str, List[str]]:
        state = state or FilterState()
        selected_brands = [db for db in state.brands if db in DATABASES]
        cache_key = tuple(sorted(selected_brands))
        if (
            not state.outlets
            and not state.months
            and not state.weeks
            and not state.products
            and not state.categories
            and not state.payments
            and not state.discounts
        ):
            cached = self._filter_cache.get(cache_key)
            if cached is not None:
                cache_counts = {key: len(values) for key, values in cached.items()}
                self.log_message.emit(
                    f"[FILTER] Cache hit for brands {cache_key or '(all)'}: counts={cache_counts}"
                )
                return cached

        self.log_message.emit(
            f"[FILTER] Loading filter options for {len(selected_brands) if selected_brands else 'all'} brands"
        )

        brand_options = list(dict.fromkeys([*state.brands, *DATABASES])) if state.brands else list(DATABASES)
        options: Dict[str, List[str]] = {
            "outlets": [],
            "months": [],
            "weeks": [],
            "payments": [],
            "categories": [],
            "products": [],
            "discounts": [],
            "brands": brand_options,
        }
        
        # Special handling for Epoint data
        is_epoint = 'sushi_epoint_pos_live' in (selected_brands or DATABASES)
        if is_epoint and (not selected_brands or 'sushi_epoint_pos_live' in selected_brands):
            self.log_message.emit("[FILTER] Loading Epoint-specific filter options")

        targets: List[str] = selected_brands[:] if selected_brands else list(DATABASES)
        if not targets:
            return options

        aggregated: Dict[str, Set[str]] = {
            "outlets": set(),
            "months": set(),
            "weeks": set(),
            "payments": set(),
            "categories": set(),
            "products": set(),
            "discounts": set(),
        }

        def _build_sales_conditions(exclude: Optional[str] = None) -> Tuple[List[str], List[Any]]:
            clauses: List[str] = []
            params: List[Any] = []
            if state.date_from:
                clauses.append("DATE(s.c_date) >= ?")
                params.append(state.date_from)
            if state.date_to:
                clauses.append("DATE(s.c_date) <= ?")
                params.append(state.date_to)
            if exclude != "outlets" and state.outlets:
                placeholders = ",".join("?" for _ in state.outlets)
                clauses.append(f"s.store_name IN ({placeholders})")
                params.extend(state.outlets)
            if exclude != "months" and state.months:
                placeholders = ",".join("?" for _ in state.months)
                clauses.append(f"strftime('%Y-%m', s.c_date) IN ({placeholders})")
                params.extend(state.months)
            if exclude != "weeks" and state.weeks:
                placeholders = ",".join("?" for _ in state.weeks)
                clauses.append(f"strftime('%Y-W%V', s.c_date) IN ({placeholders})")
                params.extend(state.weeks)
            if exclude != "products" and state.products:
                placeholders = ",".join("?" for _ in state.products)
                clauses.append(f"s.item_name IN ({placeholders})")
                params.extend(state.products)
            if exclude != "categories" and state.categories:
                placeholders = ",".join("?" for _ in state.categories)
                clauses.append(f"im.category_code IN ({placeholders})")
                params.extend(state.categories)
            if exclude != "discounts" and state.discounts:
                placeholders = ",".join("?" for _ in state.discounts)
                clauses.append(f"s.disc_name IN ({placeholders})")
                params.extend(state.discounts)
            if exclude != "payments" and state.payments:
                placeholders = ",".join("?" for _ in state.payments)
                clauses.append(
                    "EXISTS ("
                    "SELECT 1 FROM pos_sales_payment_dtls pay "
                    "WHERE pay.store_name = s.store_name "
                    "  AND pay.sales_no = s.sales_no "
                    "  AND DATE(pay.c_date) = DATE(s.c_date) "
                    f"  AND pay.payment_name IN ({placeholders})"
                    ")"
                )
                params.extend(state.payments)
            return clauses, params

        for db_name in targets:
            start_ts = time.perf_counter()
            try:
                conn = self.duckdb_connection(db_name)
            except duckdb.Error as exc:
                self.log_message.emit(f"[FILTER] {db_name}: cannot open DuckDB ({exc}).")
                continue
                
            self.log_message.emit(f"[FILTER] {db_name}: connected; gathering option buckets.")
            
            # Skip regular processing for Epoint data, we'll handle it specially
            if db_name == 'sushi_epoint_pos_live':
                self.log_message.emit("[FILTER] Processing Epoint data with special handling")
                try:
                    # Get outlets (store names)
                    outlets_query = """
                    SELECT DISTINCT store_name 
                    FROM raw_details 
                    WHERE store_name IS NOT NULL
                    """
                    outlets = [str(row[0]) for row in conn.execute(outlets_query).fetchall()]
                    aggregated["outlets"].update(outlets)
                    
                    # Get payment methods - map to specific payment types
                    payments_query = """
                    SELECT DISTINCT 
                        CASE 
                            -- Map specific payment types
                            WHEN UPPER(TRIM(payment_name)) = 'AMEX' THEN 'AMEX'
                            WHEN UPPER(TRIM(payment_name)) IN ('MASTER', 'MC') THEN 'MASTER CARD'
                            WHEN UPPER(TRIM(payment_name)) = 'VISA' THEN 'VISA'
                            WHEN UPPER(TRIM(payment_name)) = 'VOUCHER' THEN 'VOUCHER'
                            WHEN UPPER(TRIM(payment_name)) = 'DBSMAX' THEN 'DBS MAX'
                            WHEN UPPER(TRIM(payment_name)) = 'NETS' THEN 'NETS'
                            -- Fallback mappings for other cases
                            WHEN UPPER(payment_name) LIKE '%CASH%' THEN 'CASH'
                            WHEN UPPER(payment_name) LIKE '%AMEX%' THEN 'AMEX'
                            WHEN UPPER(payment_name) LIKE '%MASTER%' OR UPPER(payment_name) LIKE '%MC%' THEN 'MASTER CARD'
                            WHEN UPPER(payment_name) LIKE '%VISA%' THEN 'VISA'
                            WHEN UPPER(payment_name) LIKE '%VOUCHER%' THEN 'VOUCHER'
                            WHEN UPPER(payment_name) LIKE '%DBS%' OR UPPER(payment_name) LIKE '%MAX%' THEN 'DBS MAX'
                            WHEN UPPER(payment_name) LIKE '%NETS%' THEN 'NETS'
                            WHEN UPPER(payment_name) LIKE '%GRAB%' THEN 'GRABPAY'
                            WHEN UPPER(payment_name) LIKE '%TOUCH%' OR UPPER(payment_name) LIKE '%TOUCHNGO%' THEN 'TOUCH N GO'
                            WHEN UPPER(payment_name) LIKE '%BANK%' OR UPPER(payment_name) LIKE '%TRANSFER%' THEN 'BANK TRANSFER'
                            WHEN UPPER(payment_name) LIKE '%EWALLET%' THEN 'EWALLET'
                            ELSE UPPER(COALESCE(TRIM(payment_name), 'UNKNOWN'))
                        END as payment_method
                    FROM raw_payments 
                    WHERE payment_name IS NOT NULL 
                    AND payment_name != ''
                    """
                    payments = [str(row[0]) for row in conn.execute(payments_query).fetchall() if row[0] and str(row[0]).strip()]
                    aggregated["payments"].update(payments)
                    
                    # Log the payment methods found
                    self.log_message.emit(f"[FILTER] Found payment methods: {', '.join(payments) if payments else 'None'}")
                    
                    # Get categories
                    categories_query = """
                    SELECT DISTINCT category_name 
                    FROM raw_details 
                    WHERE category_name IS NOT NULL 
                    AND category_name != ''
                    """
                    categories = [str(row[0]) for row in conn.execute(categories_query).fetchall()]
                    aggregated["categories"].update(categories)
                    
                    # Get products
                    products_query = """
                    SELECT DISTINCT item_name 
                    FROM raw_details 
                    WHERE item_name IS NOT NULL 
                    AND item_name != ''
                    """
                    products = [str(row[0]) for row in conn.execute(products_query).fetchall()]
                    aggregated["products"].update(products)
                    
                    # Get discounts
                    discounts_query = """
                    SELECT DISTINCT discount_name 
                    FROM raw_details 
                    WHERE discount_name IS NOT NULL 
                    AND discount_name != ''
                    """
                    discounts = [str(row[0]) for row in conn.execute(discounts_query).fetchall()]
                    aggregated["discounts"].update(discounts)
                    
                    # Get dates for months and weeks
                    dates_query = """
                    SELECT DISTINCT c_date 
                    FROM raw_details 
                    WHERE c_date IS NOT NULL
                    """
                    dates = [row[0] for row in conn.execute(dates_query).fetchall() if row[0]]
                    
                    # Process months
                    months = set()
                    for date_val in dates:
                        if isinstance(date_val, str):
                            try:
                                dt = datetime.strptime(date_val, '%Y-%m-%d')
                                months.add(dt.strftime('%Y-%m'))
                            except (ValueError, TypeError):
                                continue
                        elif hasattr(date_val, 'strftime'):
                            months.add(date_val.strftime('%Y-%m'))
                    aggregated["months"].update(months)
                    
                    # Process weeks
                    weeks = set()
                    for date_val in dates:
                        if isinstance(date_val, str):
                            try:
                                dt = datetime.strptime(date_val, '%Y-%m-%d')
                                weeks.add(dt.strftime('%Y-W%V'))
                            except (ValueError, TypeError):
                                continue
                        elif hasattr(date_val, 'strftime'):
                            weeks.add(date_val.strftime('%Y-W%V'))
                    aggregated["weeks"].update(weeks)
                    
                    self.log_message.emit(
                        f"[FILTER] {db_name}: loaded {len(outlets)} outlets, {len(payments)} payments, "
                        f"{len(categories)} categories, {len(products)} products, {len(discounts)} discounts, "
                        f"{len(months)} months, {len(weeks)} weeks"
                    )
                    
                except Exception as e:
                    self.log_message.emit(f"[FILTER] Error processing Epoint data: {str(e)}")
                    import traceback
                    self.log_message.emit(f"[FILTER] {traceback.format_exc()}")
                
                # Skip the regular processing for Epoint data
                continue

            def _run_with_quarantine(query: str, parameters: Sequence[object]) -> Optional[List[tuple]]:
                nonlocal conn
                attempts = 0
                while attempts < 2:
                    try:
                        return conn.execute(query, parameters).fetchall()
                    except duckdb.Error as err:
                        quarantined = storage_duckdb.quarantine_parquet_from_exception(err)
                        if quarantined is None:
                            self.log_message.emit(f"[FILTER] {db_name}: query failed ({err}).")
                            return None
                        self.log_message.emit(
                            f"[FILTER] {db_name}: quarantined corrupted parquet '{quarantined.name}'; retrying."
                        )
                        self._repair_quarantined_parquet(db_name, quarantined)
                        cached_conn = self._connections.pop(db_name, None)
                        if cached_conn is not None:
                            cached_conn.close()
                        try:
                            conn = self.duckdb_connection(db_name)
                        except duckdb.Error as reopen_exc:
                            self.log_message.emit(
                                f"[FILTER] {db_name}: unable to reopen DuckDB after quarantine ({reopen_exc})."
                            )
                            return None
                        attempts += 1
                return None

            for key in ("outlets", "months", "weeks", "categories", "products", "discounts"):
                q_start = time.perf_counter()
                clauses, params = _build_sales_conditions(exclude=key)
                where_sql = " AND ".join(clauses) if clauses else "1=1"

                if key == "outlets":
                    sql = (
                        "SELECT DISTINCT CAST(s.store_name AS VARCHAR) AS value "
                        "FROM v_sales_clean s "
                        "LEFT JOIN item_master im USING (item_name) "
                        "WHERE s.store_name IS NOT NULL "
                        f"AND {where_sql}"
                    )
                elif key == "months":
                    sql = (
                        "SELECT DISTINCT strftime('%Y-%m', s.c_date) AS value "
                        "FROM v_sales_clean s "
                        "LEFT JOIN item_master im USING (item_name) "
                        "WHERE s.c_date IS NOT NULL "
                        f"AND {where_sql}"
                    )
                elif key == "weeks":
                    sql = (
                        "SELECT DISTINCT strftime('%Y-W%V', s.c_date) AS value "
                        "FROM v_sales_clean s "
                        "LEFT JOIN item_master im USING (item_name) "
                        "WHERE s.c_date IS NOT NULL "
                        f"AND {where_sql}"
                    )
                elif key == "categories":
                    sql = (
                        "SELECT DISTINCT CAST(im.category_code AS VARCHAR) AS value "
                        "FROM v_sales_clean s "
                        "LEFT JOIN item_master im USING (item_name) "
                        "WHERE im.category_code IS NOT NULL "
                        f"AND {where_sql}"
                    )
                elif key == "discounts":
                    sql = (
                        "SELECT DISTINCT CAST(s.disc_name AS VARCHAR) AS value "
                        "FROM v_sales_clean s "
                        "LEFT JOIN item_master im USING (item_name) "
                        "WHERE s.disc_name IS NOT NULL "
                        f"AND {where_sql}"
                    )
                else:
                    sql = (
                        "SELECT DISTINCT CAST(s.item_name AS VARCHAR) AS value "
                        "FROM v_sales_clean s "
                        "LEFT JOIN item_master im USING (item_name) "
                        "WHERE s.item_name IS NOT NULL "
                        f"AND {where_sql}"
                    )

                rows = _run_with_quarantine(sql, params)
                if rows is None:
                    self.log_message.emit(
                        f"[FILTER] {db_name}: query for {key} aborted after {time.perf_counter() - q_start:.2f}s."
                    )
                    continue
                aggregated[key].update(str(value) for (value,) in rows if value)
                self.log_message.emit(
                    f"[FILTER] {db_name}: loaded {len(rows)} raw {key} values in {time.perf_counter() - q_start:.2f}s."
                )

            clauses, params = _build_sales_conditions(exclude="payments")
            where_sql = " AND ".join(clauses) if clauses else "1=1"
            payment_sql = (
                "SELECT DISTINCT CAST(p.payment_name AS VARCHAR) AS value "
                "FROM pos_sales_payment_dtls p "
                "WHERE p.payment_name IS NOT NULL "
                "AND EXISTS ("
                "    SELECT 1 "
                "    FROM v_sales_clean s "
                "    LEFT JOIN item_master im USING (item_name) "
                "    WHERE s.store_name = p.store_name "
                "      AND s.sales_no = p.sales_no "
                "      AND DATE(s.c_date) = DATE(p.c_date) "
                f"      AND {where_sql}"
                ")"
            )

            rows = _run_with_quarantine(payment_sql, params)
            if rows is None:
                self.log_message.emit(
                    f"[FILTER] {db_name}: payment query aborted after {time.perf_counter() - start_ts:.2f}s."
                )
                continue
            aggregated["payments"].update(str(value) for (value,) in rows if value)
            self.log_message.emit(
                f"[FILTER] {db_name}: payment query returned {len(rows)} rows. Total elapsed {time.perf_counter() - start_ts:.2f}s."
            )

        self.log_message.emit(
            "[FILTER] Aggregated option sizes: "
            + ", ".join(f"{key}={len(values)}" for key, values in aggregated.items())
        )

        for key, values in aggregated.items():
            options[key] = sorted(values)

        if (
            not state.outlets
            and not state.months
            and not state.weeks
            and not state.products
            and not state.categories
            and not state.payments
            and not state.discounts
        ):
            self._filter_cache[cache_key] = options
            cache_counts = {key: len(val) for key, val in options.items()}
            self.log_message.emit(
                f"[FILTER] Cache populated for brands {cache_key or '(all)'}: counts={cache_counts}"
            )

        self.log_message.emit(
            f"[FILTER] Completed loading options for brands {selected_brands or '(all)'}"
        )

        return options

    def _load_filter_worker(self, state: FilterState) -> Dict[str, List[str]]:
        self.log_message.emit("[FILTER] Worker starting for state load.")
        try:
            result = self.load_filter_options(state)
        finally:
            self.log_message.emit("[FILTER] Worker finished for state load.")
        return result

    def load_filter_options_async(self, state: FilterState) -> None:
        task = BackgroundTask(self._load_filter_worker, state, parent=self)

        def _handle_success(result: Dict[str, List[str]]) -> None:
            self.filters_ready.emit(state, result)

        def _handle_failure(exc: Exception) -> None:
            self.filters_failed.emit(state, exc)

        task.signals.finished.connect(_handle_success)
        task.signals.failed.connect(_handle_failure)
        self._start_background_task(task)

    def get_cached_filter_options(self, state: FilterState) -> Optional[Dict[str, List[str]]]:
        if any(
            (
                state.outlets,
                state.months,
                state.weeks,
                state.products,
                state.categories,
                state.payments,
                state.discounts,
            )
        ):
            return None

        selected_brands = [db for db in state.brands if db in DATABASES]
        cache_key = tuple(sorted(selected_brands))
        cached = self._filter_cache.get(cache_key)
        if cached is None:
            return None
        self.log_message.emit(
            f"[FILTER] Using cached options for brands {cache_key or '(all)'}"
        )
        return {key: list(values) for key, values in cached.items()}

    def _start_background_task(self, task: BackgroundTask) -> None:
        self._tasks.add(task)

        def _release(_: object) -> None:
            self._tasks.discard(task)

        def _release_exc(_: Exception) -> None:
            self._tasks.discard(task)

        task.signals.finished.connect(_release)
        task.signals.failed.connect(_release_exc)
        QtCore.QThreadPool.globalInstance().start(task)

    # ------------------------------------------------------------------
    # Data retrieval helpers
    # ------------------------------------------------------------------
    def _brand_cache_covers(self, entry: BrandCacheEntry, date_from: Optional[date], date_to: Optional[date]) -> bool:
        if date_from is not None:
            if entry.date_from is None or entry.date_from > date_from:
                return False
        if date_to is not None:
            if entry.date_to is None or entry.date_to < date_to:
                return False
        return True

    def _load_brand_raw_frames(
        self,
        db_name: str,
        date_from: Optional[date],
        date_to: Optional[date],
    ) -> SalesRawFrames:
        start_ts = time.perf_counter()
        
        # Check if this is Epoint data
        is_epoint = db_name == 'sushi_epoint_pos_live'
        
        conn = storage_duckdb.open_conn(db_name)

        conditions = ["1=1"]
        params: List[object] = []
        if date_from is not None:
            conditions.append("DATE(s.c_date) >= ?")
            params.append(date_from)
        if date_to is not None:
            conditions.append("DATE(s.c_date) <= ?")
            params.append(date_to)

        where_clause = " AND ".join(conditions)

        if is_epoint:
            # For Epoint data, we need to handle date-based database files
            cache_paths = self.cache_paths[db_name]
            date_files = cache_paths.get_epoint_date_files()
            
            if not date_files:
                self.log_message.emit(f"[EPOINT] No valid date-based database files found for {db_name}")
                return SalesRawFrames(detail=pd.DataFrame(), payments=pd.DataFrame())
                
            # Get the most recent database file that matches our date range
            date_files_sorted = sorted(date_files, key=lambda x: x[1], reverse=True)
            selected_file = date_files_sorted[0][0]  # Get the path from the first (most recent) file
            
            self.log_message.emit(f"[EPOINT] Loading data from: {selected_file}")
            try:
                conn = duckdb.connect(str(selected_file), read_only=True)
                # Double-check that tables exist (should be true since get_epoint_date_files already checked)
                tables = conn.execute("SHOW TABLES").fetchall()
                table_names = {t[0].lower() for t in tables}
                
                if 'raw_details' in table_names and 'raw_payments' in table_names:
                    # Tables exist, use them
                    try:
                        details_query = """
                            SELECT
                                c_date,
                                store_name,
                                sales_no,
                                item_name AS item_no,
                                item_name,
                                '' AS category_code,
                                qty,
                                sub_total,
                                disc_name,
                                disc_amt,
                                pro_disc_amt,
                                svc_amt,
                                tax_amt,
                                '' AS take_away_item,
                                item_sub_total,
                                payment_methods,
                                ? AS source_database
                            FROM raw_details
                        """
                        details = conn.execute(details_query, [db_name]).fetchdf()
                        
                        payments_query = """
                            SELECT DISTINCT
                                c_date,
                                store_name,
                                sales_no,
                                ? AS source_database,
                                payment_name,
                                tender_amt AS tender_amount
                            FROM raw_payments
                        """
                        payments = conn.execute(payments_query, [db_name]).fetchdf()
                        
                        conn.close()
                        
                        # Apply date filtering
                        if date_from:
                            details = details[details['c_date'] >= pd.Timestamp(date_from)]
                            payments = payments[payments['c_date'] >= pd.Timestamp(date_from)]
                            
                        if date_to:
                            details = details[details['c_date'] <= pd.Timestamp(date_to)]
                            payments = payments[payments['c_date'] <= pd.Timestamp(date_to)]
                        
                        # Ensure proper column ordering and types
                        if not details.empty:
                            details = details.astype({
                                'c_date': 'datetime64[ns]',
                                'store_name': 'string',
                                'sales_no': 'string',
                                'item_no': 'string',
                                'item_name': 'string',
                                'category_code': 'string',
                                'disc_name': 'string',
                                'payment_methods': 'string'
                            })
                            
                        if not payments.empty:
                            payments = payments.astype({
                                'c_date': 'datetime64[ns]',
                                'store_name': 'string',
                                'sales_no': 'string',
                                'source_database': 'string',
                                'payment_name': 'string'
                            })
                        
                        self.log_message.emit(f"[EPOINT] Loaded {len(details)} details and {len(payments)} payments from {selected_file}")
                        return SalesRawFrames(detail=details, payments=payments)
                        
                    except Exception as e:
                        self.log_message.emit(f"[EPOINT] Error querying database: {str(e)}")
                        import traceback
                        self.log_message.emit(traceback.format_exc())
                        if 'conn' in locals():
                            try:
                                conn.close()
                            except:
                                pass
                        return SalesRawFrames(detail=pd.DataFrame(), payments=pd.DataFrame())
                
                # If we get here, there was an error with the selected file
                if 'conn' in locals():
                    try:
                        conn.close()
                    except:
                        pass
                return SalesRawFrames(detail=pd.DataFrame(), payments=pd.DataFrame())
                
            except Exception as e:
                self.log_message.emit(f"[EPOINT] Unexpected error: {str(e)}")
                import traceback
                self.log_message.emit(traceback.format_exc())
                if 'conn' in locals():
                    try:
                        conn.close()
                    except:
                        pass
                return SalesRawFrames(detail=pd.DataFrame(), payments=pd.DataFrame())
        
        # This code is for non-Epoint data or if Epoint processing is skipped
        all_details = []
        all_payments = []
        
        # Get the list of database files to process
        try:
            date_files = self.cache_paths[db_name].get_epoint_date_files()
            filtered_files = [f[0] for f in date_files]  # Extract just the file paths
            
            for db_file in filtered_files:
                try:
                    # Connect to the date-specific database file
                    conn = duckdb.connect(str(db_file), read_only=True)
                    
                    # Check if tables exist
                    tables = conn.execute("SHOW TABLES").fetchall()
                    table_names = {t[0].lower() for t in tables}
                    
                    if 'raw_details' not in table_names or 'raw_payments' not in table_names:
                        self.log_message.emit(f"[EPOINT] Missing required tables in {db_file}")
                        continue
                    
                    # Query for details
                    details_query = """
                        SELECT
                            c_date,
                            store_name,
                            sales_no,
                            item_name AS item_no,
                            item_name,
                            '' AS category_code,
                            qty,
                            sub_total,
                            disc_name,
                            disc_amt,
                            pro_disc_amt,
                            svc_amt,
                            tax_amt,
                            '' AS take_away_item,
                            item_sub_total,
                            payment_methods,
                            ? AS source_database
                        FROM raw_details
                    """
                    details = conn.execute(details_query, [db_name]).fetchdf()
                    if not details.empty:
                        all_details.append(details)
                    
                    # Query for payments
                    payments_query = """
                        SELECT DISTINCT
                            c_date,
                            store_name,
                            sales_no,
                            ? AS source_database,
                            payment_name,
                            tender_amt AS tender_amount
                        FROM raw_payments
                    """
                    payments = conn.execute(payments_query, [db_name]).fetchdf()
                    if not payments.empty:
                        all_payments.append(payments)
                        
                    conn.close()
                    
                except Exception as e:
                    self.log_message.emit(f"[EPOINT] Error processing {db_file}: {str(e)}")
                    if 'conn' in locals():
                        conn.close()
                
                # Combine all results
                details_df = pd.concat(all_details, ignore_index=True) if all_details else pd.DataFrame()
                payments_df = pd.concat(all_payments, ignore_index=True) if all_payments else pd.DataFrame()
                
                # Apply date filtering in memory (since we already filtered by file dates)
                if not details_df.empty and date_from:
                    details_df = details_df[details_df['c_date'] >= pd.Timestamp(date_from)]
                if not payments_df.empty and date_from:
                    payments_df = payments_df[payments_df['c_date'] >= pd.Timestamp(date_from)]
                    
                if not details_df.empty and date_to:
                    details_df = details_df[details_df['c_date'] <= pd.Timestamp(date_to)]
                if not payments_df.empty and date_to:
                    payments_df = payments_df[payments_df['c_date'] <= pd.Timestamp(date_to)]
                
                # Ensure proper column ordering and types
                if not details_df.empty:
                    details_df = details_df.astype({
                        'c_date': 'datetime64[ns]',
                        'store_name': 'string',
                        'sales_no': 'string',
                        'item_no': 'string',
                        'item_name': 'string',
                        'category_code': 'string',
                        'disc_name': 'string',
                        'payment_methods': 'string'
                    })
                    
                if not payments_df.empty:
                    payments_df = payments_df.astype({
                        'c_date': 'datetime64[ns]',
                        'store_name': 'string',
                        'sales_no': 'string',
                        'source_database': 'string',
                        'payment_name': 'string'
                    })
                
                return SalesRawFrames(detail=details_df, payments=payments_df)
                
        except Exception as e:
            self.log_message.emit(f"[EPOINT] Error in Epoint data loading: {str(e)}")
            import traceback
            self.log_message.emit(traceback.format_exc())
            return SalesRawFrames(detail=pd.DataFrame(), payments=pd.DataFrame())
    
        # Standard SQL for non-Epoint data
        sales_sql = f"""
            WITH item_lookup AS (
                SELECT item_name, MAX(category_code) AS category_code
                FROM item_master
                GROUP BY item_name
            )
            SELECT
                DATE(s.c_date) AS c_date,
                CAST(s.store_name AS VARCHAR) AS store_name,
                CAST(s.sales_no AS VARCHAR) AS sales_no,
                CAST(s.item_no AS VARCHAR) AS item_no,
                CAST(s.item_name AS VARCHAR) AS item_name,
                COALESCE(CAST(im.category_code AS VARCHAR), '') AS category_code,
                CAST(s.qty AS DOUBLE) AS qty,
                CAST(s.sub_total AS DOUBLE) AS sub_total,
                CAST(s.disc_name AS VARCHAR) AS disc_name,
                CAST(s.disc_amt AS DOUBLE) AS disc_amt,
                CAST(s.pro_disc_amt AS DOUBLE) AS pro_disc_amt,
                CAST(s.svc_amt AS DOUBLE) AS svc_amt,
                CAST(s.tax_amt AS DOUBLE) AS tax_amt,
                CAST(s.take_away_item AS VARCHAR) AS take_away_item,
                CAST(s.item_sub_total AS DOUBLE) AS item_sub_total,
                COALESCE(
                    (
                        SELECT string_agg(DISTINCT CAST(payment_name AS VARCHAR), ', ')
                        FROM pos_sales_payment_dtls pay
                        WHERE pay.store_name = s.store_name
                          AND pay.sales_no = s.sales_no
                          AND DATE(pay.c_date) = DATE(s.c_date)
                    ),
                    ''
                ) AS payment_methods,
                COALESCE(CAST(s.source_database AS VARCHAR), '{db_name}') AS source_database
            FROM v_sales_clean s
            LEFT JOIN item_lookup im USING (item_name)
            WHERE {where_clause}
              AND NOT EXISTS (
                  SELECT 1
                  FROM pos_cancel_sales_item_dtls canc
                  WHERE canc.store_name = s.store_name
                    AND canc.sales_no = s.sales_no
                    AND canc.item_name = s.item_name
                    AND DATE(canc.c_date) = DATE(s.c_date)
              )
                ORDER BY c_date, store_name, sales_no, item_name
            """

        payment_sql = f"""
            WITH base AS (
                SELECT DISTINCT
                    DATE(s.c_date) AS c_date,
                    CAST(s.store_name AS VARCHAR) AS store_name,
                    CAST(s.sales_no AS VARCHAR) AS sales_no,
                    CAST('{db_name}' AS VARCHAR) AS source_database
                FROM v_sales_clean s
                WHERE {where_clause}
                  AND NOT EXISTS (
                      SELECT 1
                      FROM pos_cancel_sales_item_dtls canc
                      WHERE canc.store_name = s.store_name
                        AND canc.sales_no = s.sales_no
                        AND canc.item_name = s.item_name
                        AND DATE(canc.c_date) = DATE(s.c_date)
                  )
            )
            SELECT
                base.c_date,
                base.store_name,
                base.sales_no,
                base.source_database,
                CAST(pay.payment_name AS VARCHAR) AS payment_name,
                CAST(pay.tender_amt AS DOUBLE) AS tender_amount
            FROM base
            JOIN pos_sales_payment_dtls pay
                  ON pay.store_name = base.store_name
                 AND pay.sales_no = base.sales_no
                 AND DATE(pay.c_date) = base.c_date
            """

        try:
            detail_df = conn.execute(sales_sql, params).df()
            payment_df = conn.execute(payment_sql, params).df()
        except duckdb.Error as exc:
            raise RuntimeError(f"{db_name}: DuckDB query failed ({exc})") from exc
        finally:
            try:
                conn.close()
            except Exception:
                pass

        elapsed = time.perf_counter() - start_ts
        self.log_message.emit(
            f"[FETCH] {db_name}: loaded raw detail {len(detail_df):,} rows, payments {len(payment_df):,} rows in {elapsed:.2f}s"
        )
        return SalesRawFrames(detail_df, payment_df)

    def _ensure_brand_raw_frames(self, db_name: str, state: FilterState) -> BrandCacheEntry:
        date_from = state.date_from
        date_to = state.date_to

        with self._brand_cache_lock:
            entry = self._brand_raw_cache.get(db_name)

        if entry and self._brand_cache_covers(entry, date_from, date_to):
            return entry

        raw_frames = self._load_brand_raw_frames(db_name, date_from, date_to)
        new_entry = BrandCacheEntry(raw_frames.detail, raw_frames.payments, date_from, date_to)

        with self._brand_cache_lock:
            self._brand_raw_cache[db_name] = new_entry

        return new_entry

    @staticmethod
    def _filter_sales_frames(
        detail_frame: pd.DataFrame,
        payment_frame: pd.DataFrame,
        state: FilterState,
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """Apply in-memory filters to detail and payment dataframes.
        
        Handles both SQL and Epoint data by normalizing column names and values.
        """
        if detail_frame.empty or payment_frame.empty:
            return detail_frame, payment_frame

        # Make copies to avoid SettingWithCopyWarning
        detail = detail_frame.copy()
        payment = payment_frame.copy()

        # Ensure date is datetime
        if 'c_date' in detail.columns and not pd.api.types.is_datetime64_any_dtype(detail['c_date']):
            detail['c_date'] = pd.to_datetime(detail['c_date'])
            
        # Apply date filter
        if state.date_from:
            detail = detail[detail["c_date"] >= pd.to_datetime(state.date_from)]
        if state.date_to:
            detail = detail[detail["c_date"] <= pd.to_datetime(state.date_to)]

        # Apply brand filter - handle both 'brand' and 'store_code3' for compatibility
        if state.brands:
            if 'brand' in detail.columns:
                detail = detail[detail["brand"].isin(state.brands)]
            elif 'store_code3' in detail.columns:
                # Map store codes to brands for Epoint data
                def get_brand(store_code):
                    if not store_code or pd.isna(store_code):
                        return "SE"
                    if str(store_code).startswith('3'):
                        return "GOGO"
                    if str(store_code).startswith('4'):
                        return "PLUS"
                    return "SE"
                
                detail['_brand'] = detail['store_code3'].apply(get_brand)
                detail = detail[detail["_brand"].isin(state.brands)]
                detail = detail.drop(columns=['_brand'])

        # Apply store filter if store_code3 is present
        if state.outlets and 'store_code3' in detail.columns:
            detail = detail[detail["store_code3"].isin(state.outlets)]

        # Apply weekday filter
        if state.weekdays and 'c_date' in detail.columns:
            detail = detail[detail["c_date"].dt.weekday.isin(state.weekdays)]

        # Apply payment filter
        if state.payments and 'payment_name' in payment.columns:
            payment = payment[payment["payment_name"].str.upper().isin([p.upper() for p in state.payments])]
            detail = detail[detail["sales_no"].isin(payment["sales_no"])]

        # Apply product filter
        if state.products and 'item_name' in detail.columns:
            detail = detail[detail["item_name"].str.upper().isin([p.upper() for p in state.products])]

        # Apply category filter
        if state.categories and 'category_name' in detail.columns:
            detail = detail[detail["category_name"].str.upper().isin([c.upper() for c in state.categories])]

        # Apply discount filter
        if state.discounts and 'discount_name' in detail.columns:
            detail = detail[detail["discount_name"].str.upper().isin([d.upper() for d in state.discounts])]

        # Filter payments to only include sales that match the filtered details
        if not detail.empty and 'sales_no' in payment.columns:
            payment = payment[payment["sales_no"].isin(detail["sales_no"])]

        return detail.reset_index(drop=True), payment.reset_index(drop=True)

    def fetch_sales_transactions(self, state: FilterState) -> SalesReportFrames:
        targets: List[str] = []

        if state.brands:
            targets.extend([db for db in state.brands if db in DATABASES])
        else:
            targets.extend(DATABASES)

        empty_promotion = {mode: pd.DataFrame(columns=PROMOTION_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}

        if not targets:
            empty = pd.DataFrame()
            empty_map = {mode: pd.DataFrame(columns=DISCOUNT_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}
            empty_product = {mode: pd.DataFrame(columns=PRODUCT_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}
            return SalesReportFrames(
                empty,
                empty_map,
                empty_map.copy(),
                empty_product,
                empty_promotion,
            )

        total_start = time.perf_counter()

        raw_detail_frames: List[pd.DataFrame] = []
        raw_payment_frames: List[pd.DataFrame] = []

        for db_name in targets:
            metadata = self._load_aggregation_metadata(db_name)
            month_starts = self._month_range(state.date_from, state.date_to, metadata)
            if month_starts:
                self._ensure_monthly_raw_frames(db_name, month_starts)
                period_keys = [self._aggregation_period_key(month) for month in month_starts]
                cached_raw = self._load_cached_raw_frames(db_name, period_keys)
            else:
                cached_raw = SalesRawFrames(pd.DataFrame(), pd.DataFrame())

            detail_frame = cached_raw.detail
            payments_frame = cached_raw.payments

            if detail_frame.empty and payments_frame.empty:
                self.log_message.emit(
                    f"[FETCH] {db_name}: cached raw frames missing; loading from DuckDB."
                )
                raw_frames = self._load_brand_raw_frames(db_name, state.date_from, state.date_to)
                detail_frame = raw_frames.detail
                payments_frame = raw_frames.payments
                self._persist_raw_frames_by_month(db_name, detail_frame, payments_frame)
            else:
                self.log_message.emit(
                    f"[FETCH] {db_name}: loaded cached raw frames ({len(detail_frame):,} rows)."
                )

            if not detail_frame.empty:
                raw_detail_frames.append(detail_frame)
            if not payments_frame.empty:
                raw_payment_frames.append(payments_frame)

        if not raw_detail_frames:
            empty_payment = {mode: pd.DataFrame(columns=self._payment_columns_for_mode(mode)) for mode in PERIOD_OPTIONS}
            empty_discount = {mode: pd.DataFrame(columns=DISCOUNT_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}
            empty_product = {mode: pd.DataFrame(columns=PRODUCT_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}
            return SalesReportFrames(
                pd.DataFrame(),
                empty_payment,
                empty_discount,
                empty_product,
                empty_promotion,
            )

        combined_detail = pd.concat(raw_detail_frames, ignore_index=True)
        combined_payments = (
            pd.concat(raw_payment_frames, ignore_index=True) if raw_payment_frames else pd.DataFrame()
        )

        base_state = FilterState(
            date_from=state.date_from,
            date_to=state.date_to,
            brands=list(state.brands),
        )

        base_detail, base_payments = self._filter_sales_frames(combined_detail, combined_payments, base_state)

        filter_start = time.perf_counter()
        filtered_detail, filtered_payments = self._filter_sales_frames(base_detail, base_payments, state)
        filter_elapsed = time.perf_counter() - filter_start
        self.log_message.emit(
            f"[FILTER] Applied in-memory filters: details {len(filtered_detail):,} rows, payments {len(filtered_payments):,} rows in {filter_elapsed:.2f}s"
        )

        if filtered_detail.empty or filtered_payments.empty:
            empty_payment = {mode: pd.DataFrame(columns=self._payment_columns_for_mode(mode)) for mode in PERIOD_OPTIONS}
            empty_discount = {mode: pd.DataFrame(columns=DISCOUNT_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}
            empty_product = {mode: pd.DataFrame(columns=PRODUCT_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}
            return SalesReportFrames(
                filtered_detail,
                empty_payment,
                empty_discount,
                empty_product,
                empty_promotion,
                base_details=base_detail.copy(),
                base_payments=base_payments.copy(),
                base_state=base_state,
            )

        result = self._assemble_sales_report(
            filtered_detail,
            filtered_payments,
            base_details=base_detail.copy(),
            base_payments=base_payments.copy(),
            base_state=base_state,
            state=state,
        )

        total_elapsed = time.perf_counter() - total_start
        self.log_message.emit(
            f"[FETCH] Completed aggregation: details {len(result.details):,} rows, payments {sum(len(df.index) for df in result.payment_analysis.values()):,} rows in {total_elapsed:.2f}s"
        )
        return result

    def _assemble_sales_report(
        self,
        detail_frame: pd.DataFrame,
        payments_frame: pd.DataFrame,
        *,
        base_details: pd.DataFrame,
        base_payments: pd.DataFrame,
        base_state: FilterState,
        state: FilterState,
    ) -> SalesReportFrames:
        detail_frame = detail_frame.reset_index(drop=True).copy()
        payments_frame = payments_frame.reset_index(drop=True).copy()

        sub_total = pd.to_numeric(detail_frame.get("sub_total"), errors="coerce").fillna(0.0)
        disc_amt = pd.to_numeric(detail_frame.get("disc_amt"), errors="coerce").fillna(0.0)
        pro_disc_amt = pd.to_numeric(detail_frame.get("pro_disc_amt"), errors="coerce").fillna(0.0)
        tax_amt = pd.to_numeric(detail_frame.get("tax_amt"), errors="coerce").fillna(0.0)
        svc_amt = pd.to_numeric(detail_frame.get("svc_amt"), errors="coerce").fillna(0.0)

        if "source_database" in detail_frame:
            source_db = detail_frame["source_database"].astype(str)
        else:
            source_db = pd.Series("", index=detail_frame.index, dtype="object")

        if "take_away_item" in detail_frame:
            takeaway_flag = detail_frame["take_away_item"].astype(str).str.upper()
        else:
            takeaway_flag = pd.Series("", index=detail_frame.index, dtype="object")

        express_mask = source_db.eq("sushi_express_pos_live")
        takeaway_mask = takeaway_flag.eq("Y")
        tax_deduction = np.where(express_mask & ~takeaway_mask, 0.0, tax_amt)

        detail_frame["net_item"] = sub_total - disc_amt - pro_disc_amt - tax_deduction + svc_amt

        receipt_totals = (
            detail_frame.groupby(["c_date", "store_name", "sales_no"], as_index=False)
            .agg(
                net_total=("net_item", "sum"),
                tax_total=("tax_amt", "sum"),
            )
        )
        receipt_totals["Month"] = pd.to_datetime(receipt_totals["c_date"], errors="coerce").dt.to_period("M").astype(str)

        payments_frame["Month"] = pd.to_datetime(payments_frame["c_date"], errors="coerce").dt.to_period("M").astype(str)

        store_brand_map = (
            detail_frame[["store_name", "source_database"]]
            .dropna(subset=["store_name"])
            .drop_duplicates()
        )
        store_brand_map["BrandGroup"] = store_brand_map["source_database"].map(self._brand_label)
        store_brand_map = store_brand_map[["store_name", "BrandGroup"]]

        active_store_counts_df = (
            detail_frame[["store_name"]]
            .dropna(subset=["store_name"])
            .drop_duplicates()
            .merge(store_brand_map, on="store_name", how="left")
        )
        if active_store_counts_df.empty:
            active_store_counts: Dict[str, int] = {}
        else:
            active_store_counts_df["BrandGroup"] = active_store_counts_df["BrandGroup"].fillna("Other")
            grouped_counts = (
                active_store_counts_df.groupby("BrandGroup")["store_name"].nunique().astype(int)
            )
            active_store_counts = {str(key): int(value) for key, value in grouped_counts.items()}
            overall_count = int(active_store_counts_df["store_name"].nunique())
            active_store_counts["__overall__"] = overall_count

        payment_receipt = payments_frame.merge(
            receipt_totals[["c_date", "store_name", "sales_no", "net_total", "tax_total", "Month"]],
            on=["c_date", "store_name", "sales_no"],
            how="left",
            suffixes=("_payment", "_receipt"),
        )

        if "Month_payment" in payment_receipt.columns or "Month_receipt" in payment_receipt.columns:
            payment_receipt["Month"] = payment_receipt.get("Month_payment")
            if "Month_receipt" in payment_receipt.columns:
                payment_receipt["Month"] = payment_receipt["Month"].fillna(payment_receipt["Month_receipt"])
            drop_cols = [col for col in ("Month_payment", "Month_receipt") if col in payment_receipt.columns]
            if drop_cols:
                payment_receipt.drop(columns=drop_cols, inplace=True)

        if payment_receipt.empty:
            payment_analysis = {mode: pd.DataFrame(columns=self._payment_columns_for_mode(mode)) for mode in PERIOD_OPTIONS}
        else:
            base_summary = self._build_payment_summary(payment_receipt, receipt_totals, store_brand_map)
            payment_analysis = {
                mode: self._format_payment_period(base_summary, mode)
                for mode in PERIOD_OPTIONS
            }

        discount_frame_source = detail_frame.drop(columns=["net_item"], errors="ignore").copy()
        discount_summary = self._build_discount_summary(discount_frame_source, store_brand_map, receipt_totals)
        discount_analysis = {
            mode: self._format_discount_period(discount_summary, mode)
            for mode in PERIOD_OPTIONS
        }

        promotion_analysis = self._build_promotion_analysis(detail_frame, store_brand_map, state)

        if "net_item" in detail_frame.columns:
            detail_frame.drop(columns=["net_item"], inplace=True)

        product_analysis = self._build_product_analysis(detail_frame, payments_frame, receipt_totals, store_brand_map)

        return SalesReportFrames(
            detail_frame,
            payment_analysis,
            discount_analysis,
            product_analysis,
            promotion_analysis,
            store_brand_map,
            active_store_counts,
            base_details=base_details,
            base_payments=base_payments,
            base_state=base_state,
        )
    def _build_product_analysis(
        self,
        detail_frame: pd.DataFrame,
        payment_frame: pd.DataFrame,
        receipt_totals: pd.DataFrame,
        store_brand_map: pd.DataFrame,
    ) -> Dict[str, pd.DataFrame]:
        product_frames: Dict[str, pd.DataFrame] = {}

        if detail_frame.empty:
            return {mode: pd.DataFrame(columns=PRODUCT_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}

        frame = detail_frame.copy()

        exclude_mask = frame.get("exclude_from_transactions")
        if exclude_mask is not None:
            if exclude_mask.dtype != bool:
                exclude_mask = exclude_mask.astype(bool)
            frame = frame.loc[~exclude_mask].copy()

        brand_lookup_source = store_brand_map.drop_duplicates(subset=["store_name"]).copy()
        frame = frame.merge(brand_lookup_source, on="store_name", how="left")
        brand_lookup = brand_lookup_source.rename(columns={"store_name": "Outlet"})

        receipt_lookup = (
            receipt_totals[["c_date", "store_name", "sales_no", "net_total"]]
            .drop_duplicates()
            .rename(columns={"net_total": "ReceiptNet"})
        )
        frame = frame.merge(receipt_lookup, on=["c_date", "store_name", "sales_no"], how="left")
        frame["ReceiptNet"] = pd.to_numeric(frame.get("ReceiptNet"), errors="coerce").fillna(0.0)

        wastage_receipts = (
            payment_frame.assign(payment_name=payment_frame.get("payment_name", "").astype(str).str.upper())
            .loc[lambda df: df["payment_name"].eq("WASTAGE"), ["c_date", "store_name", "sales_no"]]
            .drop_duplicates()
        )
        wastage_receipts["_is_wastage_receipt"] = True

        frame["Outlet"] = frame.get("store_name", "").astype(str)
        frame["Item Name"] = frame.get("item_name", "").astype(str)
        frame["Category"] = frame.get("category_code", "").astype(str)
        frame["sales_no"] = frame.get("sales_no", "").astype(str)

        # Base numeric fields
        frame["Sales"] = pd.to_numeric(frame.get("sub_total"), errors="coerce").fillna(0.0)
        frame["Quantity"] = pd.to_numeric(frame.get("qty"), errors="coerce").fillna(0.0)

        # Nett sales per item (align with payment logic)
        disc_amt = pd.to_numeric(frame.get("disc_amt"), errors="coerce").fillna(0.0)
        promo_disc = pd.to_numeric(frame.get("pro_disc_amt"), errors="coerce").fillna(0.0)
        svc_amt = pd.to_numeric(frame.get("svc_amt"), errors="coerce").fillna(0.0)
        tax_amt = pd.to_numeric(frame.get("tax_amt"), errors="coerce").fillna(0.0)

        frame = frame.merge(wastage_receipts, on=["c_date", "store_name", "sales_no"], how="left")
        wastage_flag = frame.get("_is_wastage_receipt")
        if wastage_flag is None:
            is_wastage = pd.Series(False, index=frame.index, dtype=bool)
        else:
            is_wastage = wastage_flag.astype("boolean").fillna(False)
        frame["Wastage"] = np.where(is_wastage.to_numpy(dtype=bool, na_value=False), frame["Quantity"], 0.0)
        if "_is_wastage_receipt" in frame.columns:
            frame.drop(columns=["_is_wastage_receipt"], inplace=True)

        frame["Date"] = pd.to_datetime(frame["c_date"], errors="coerce")
        frame["WeekLabel"] = frame["Date"].dt.strftime("%Y-W%V")
        frame["YearMonth"] = frame["Date"].dt.to_period("M").astype(str)

        duck_columns = [
            "Date",
            "WeekLabel",
            "YearMonth",
            "Outlet",
            "Item Name",
            "Category",
            "sales_no",
            "store_name",
            "c_date",
            "Sales",
            "Quantity",
            "Wastage",
            "ReceiptNet",
            "BrandGroup",
        ]

        duck_conn = duckdb.connect(database=":memory:")
        duck_table = "product_items"
        try:
            duck_conn.register(duck_table, frame[duck_columns])
            for mode in PERIOD_OPTIONS:
                product_frames[mode] = self._format_product_period(
                    frame,
                    mode,
                    duck_conn=duck_conn,
                    duck_table=duck_table,
                )
        finally:
            duck_conn.close()

        return product_frames

    def _build_promotion_analysis(
        self,
        detail_frame: pd.DataFrame,
        store_brand_map: pd.DataFrame,
        state: FilterState,
    ) -> Dict[str, pd.DataFrame]:
        if detail_frame.empty:
            return {mode: pd.DataFrame(columns=PROMOTION_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}

        frame = detail_frame.copy()
        frame["Date"] = pd.to_datetime(frame["c_date"], errors="coerce")
        frame["YearMonth"] = frame["Date"].dt.to_period("M").astype(str)
        frame["WeekLabel"] = frame["Date"].dt.strftime("%Y-W%V")
        frame["Outlet"] = frame.get("store_name", "").astype(str)

        brand_lookup = store_brand_map.drop_duplicates(subset=["store_name"]).rename(columns={"store_name": "Outlet"})
        frame = frame.merge(brand_lookup, on="Outlet", how="left")

        base_columns = {
            "Sales": pd.to_numeric(frame.get("sub_total"), errors="coerce").fillna(0.0),
            "Quantity": pd.to_numeric(frame.get("qty"), errors="coerce").fillna(0.0),
            "Transaction": frame.get("sales_no", "").astype(str),
        }
        frame["Sales"] = base_columns["Sales"]
        frame["Quantity"] = base_columns["Quantity"]
        frame["Transaction"] = base_columns["Transaction"]

        if state.products:
            name_column = frame.get("item_name", "").astype(str)
        elif state.discounts:
            name_column = frame.get("disc_name", "").astype(str)
        else:
            item_sales = frame.groupby("item_name", dropna=False)["Sales"].sum()
            discount_sales = frame.groupby("disc_name", dropna=False)["Sales"].sum()
            if item_sales.sum() >= discount_sales.sum():
                name_column = frame.get("item_name", "").astype(str)
            else:
                name_column = frame.get("disc_name", "").astype(str)

        frame["Item / Discount Name"] = name_column.fillna("")
        frame = frame[frame["Item / Discount Name"].str.strip().ne("")]
        if frame.empty:
            return {mode: pd.DataFrame(columns=PROMOTION_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}

        group_keys = [
            ("Date", "Daily"),
            ("WeekLabel", "Weekly"),
            ("YearMonth", "Monthly"),
        ]

        period_frames: Dict[str, pd.DataFrame] = {}

        def _aggregate(df: pd.DataFrame, period_label: Optional[str], columns: List[str]) -> pd.DataFrame:
            working = df.copy()
            if period_label is None:
                working["Period"] = "Selected Period"
                grouping = ["Period", "Outlet", "Item / Discount Name"]
            else:
                if period_label not in working.columns:
                    self.log_message.emit(
                        f"[PROMOTION] Missing period label '{period_label}' column. Defaulting to selected period."
                    )
                    working["Period"] = "Selected Period"
                else:
                    working["Period"] = working[period_label]
                grouping = ["Period", "Outlet", "Item / Discount Name"]

            for column in grouping:
                if column not in working.columns:
                    default = "Selected Period" if column == "Period" else ""
                    working[column] = default

            aggregated = (
                working.groupby(grouping, as_index=False)
                .agg(
                    Sales=("Sales", "sum"),
                    Transaction=("Transaction", "nunique"),
                    Quantity=("Quantity", "sum"),
                )
            )

            outlet_totals = (
                aggregated.groupby(grouping[:-1], as_index=False)
                .agg(
                    OutletSales=("Sales", "sum"),
                    OutletTx=("Transaction", "sum"),
                    OutletQty=("Quantity", "sum"),
                )
            )

            merged = aggregated.merge(outlet_totals, on=grouping[:-1], how="left")

            def _ratio(numerator: pd.Series, denominator: pd.Series) -> pd.Series:
                return np.where(denominator.gt(0), (numerator / denominator) * 100.0, 0.0)

            merged["Sales Ratio %"] = _ratio(merged["Sales"], merged["OutletSales"])
            merged["Transaction Ratio %"] = _ratio(merged["Transaction"], merged["OutletTx"])
            merged["Quantity Ratio %"] = _ratio(merged["Quantity"], merged["OutletQty"])

            merged["Sales"] = merged["Sales"].round(1)
            merged["Quantity"] = merged["Quantity"].round(1)
            merged["Transaction"] = merged["Transaction"].astype(int)
            for column in ("Sales Ratio %", "Transaction Ratio %", "Quantity Ratio %"):
                merged[column] = merged[column].round(2).map(lambda x: f"{x:.2f}%")

            merged.drop(columns=["OutletSales", "OutletTx", "OutletQty"], inplace=True)

            if "Period" not in merged.columns:
                merged.insert(0, "Period", "Selected Period")

            for column in columns:
                if column not in merged.columns:
                    merged[column] = {
                        "Period": "Selected Period",
                        "Outlet": "",
                        "Item / Discount Name": "",
                        "Sales": 0.0,
                        "Transaction": 0,
                        "Quantity": 0.0,
                        "Sales Ratio %": "0.00%",
                        "Transaction Ratio %": "0.00%",
                        "Quantity Ratio %": "0.00%",
                    }.get(column, "")

            sort_fields = [field for field in PROMOTION_ANALYSIS_COLUMNS["Daily"] if field in merged.columns]
            merged.sort_values(sort_fields, inplace=True)

            try:
                return merged.reindex(columns=columns)
            except KeyError as exc:
                available = list(merged.columns)
                missing = [column for column in columns if column not in available]
                self.log_message.emit(
                    "[PROMOTION] Reindex failed. Missing columns: "
                    f"{missing}. Available columns: {available}."
                )
                raise exc

        for period_key, mode in group_keys:
            period_df = _aggregate(frame, period_key, PROMOTION_ANALYSIS_COLUMNS[mode])
            period_frames[mode] = period_df

        period_frames["Period"] = _aggregate(frame, None, PROMOTION_ANALYSIS_COLUMNS["Period"])

        enriched: Dict[str, pd.DataFrame] = {}
        ratio_columns = [
            "Sales Ratio %",
            "Transaction Ratio %",
            "Quantity Ratio %",
        ]

        for mode, df in period_frames.items():
            if df.empty:
                enriched[mode] = df
                continue

            working = df.copy()
            value_columns = [col for col in ("Sales", "Transaction", "Quantity") if col in working.columns]
            base_group = [col for col in ("Period",) if col in working.columns]

            if value_columns and "Outlet" in working.columns:
                if base_group:
                    grouped = (
                        df.groupby(base_group, as_index=False)[value_columns].sum()
                    )
                else:
                    grouped = pd.DataFrame([{col: df[col].sum() for col in value_columns}])
                if not base_group:
                    grouped.index = pd.RangeIndex(len(grouped))
                totals = grouped.copy()
                totals["Outlet"] = "All"
                if "Item / Discount Name" in working.columns:
                    totals["Item / Discount Name"] = "All"
                for column in ratio_columns:
                    if column in working.columns:
                        totals[column] = "100.00%"
                working = pd.concat([working, totals], ignore_index=True, sort=False)

            if value_columns:
                summary_row: Dict[str, object] = {column: "" for column in working.columns}
                for column in value_columns:
                    summary_row[column] = float(df[column].sum())
                if "Period" in working.columns:
                    summary_row["Period"] = "SUMMARY"
                if "Outlet" in working.columns:
                    summary_row["Outlet"] = "All"
                if "Item / Discount Name" in working.columns:
                    summary_row["Item / Discount Name"] = "Total"
                for column in ratio_columns:
                    if column in working.columns:
                        summary_row[column] = "100.00%"
                overall_totals = pd.DataFrame([summary_row])
                working = pd.concat([working, overall_totals], ignore_index=True, sort=False)

            required = PROMOTION_ANALYSIS_COLUMNS.get(mode, list(working.columns))
            for column in required:
                if column not in working.columns:
                    working[column] = "" if column not in {"Sales", "Transaction", "Quantity"} else 0

            # Ensure numeric totals remain numeric
            for column in value_columns:
                working[column] = pd.to_numeric(working[column], errors="coerce").fillna(0.0)

            enriched[mode] = working.reindex(columns=required)

        return {
            mode: enriched.get(mode, pd.DataFrame(columns=PROMOTION_ANALYSIS_COLUMNS[mode]))
            for mode in PERIOD_OPTIONS
        }

    def _format_product_period(
        self,
        frame: pd.DataFrame,
        mode: str,
        *,
        duck_conn: Optional[duckdb.DuckDBPyConnection] = None,
        duck_table: str = "product_items",
    ) -> pd.DataFrame:
        columns = PRODUCT_ANALYSIS_COLUMNS[mode]
        if frame.empty:
            return pd.DataFrame(columns=columns)

        brand_lookup = (
            frame[["Outlet", "BrandGroup"]]
            .dropna(subset=["Outlet"])
            .drop_duplicates()
        )

        close_conn = False
        if duck_conn is None:
            duck_conn = duckdb.connect(database=":memory:")
            close_conn = True
            duck_conn.register(duck_table, frame)

        period_sql = {
            "Daily": "strftime('%Y-%m-%d', Date)",
            "Weekly": "WeekLabel",
            "Monthly": "YearMonth",
        }

        select_period = period_sql.get(mode)
        select_fields = []
        group_fields = []
        if select_period:
            select_fields.append(f"{select_period} AS Period")
            group_fields.append(select_period)
        select_fields.extend(
            [
                "Outlet",
                '"Item Name"',
                "Category",
                "SUM(Sales) AS Sales",
                "COUNT(DISTINCT sales_no) AS Transaction",
                "SUM(Quantity) AS Quantity",
                "SUM(Wastage) AS Wastage",
                "SUM(ReceiptNet) AS BillSales",
            ]
        )
        group_fields.extend(["Outlet", '"Item Name"', "Category"])

        query = (
            "SELECT "
            + ", ".join(select_fields)
            + f" FROM {duck_table} GROUP BY "
            + ", ".join(group_fields)
        )

        try:
            aggregated = duck_conn.execute(query).df()
        finally:
            if close_conn:
                duck_conn.close()

        if aggregated.empty:
            return pd.DataFrame(columns=columns)

        aggregated.rename(columns={"""Item Name""": "Item Name"}, inplace=True)
        if "Period" in aggregated.columns:
            aggregated["Period"] = aggregated["Period"].astype(str)

        for col in ("Sales", "Quantity", "Wastage", "BillSales"):
            aggregated[col] = pd.to_numeric(aggregated[col], errors="coerce").fillna(0.0)
        aggregated["Transaction"] = pd.to_numeric(aggregated["Transaction"], errors="coerce").fillna(0).astype(int)

        aggregated = aggregated.merge(brand_lookup, on="Outlet", how="left")

        ratio_group = ["Outlet", "Item Name", "Category"]
        if mode != "Period":
            ratio_group = ["Period"] + ratio_group

        value_columns = {
            "Sales": "sum",
            "Transaction": "sum",
            "Quantity": "sum",
            "Wastage": "sum",
            "BillSales": "sum",
        }
        base_group = [field for field in ratio_group if field != "Outlet"]
        if base_group:
            brand_rows = (
                aggregated.dropna(subset=["BrandGroup"])
                .groupby(base_group + ["BrandGroup"], as_index=False)
                .agg(value_columns)
            )
            brand_rows["Outlet"] = brand_rows["BrandGroup"].map(lambda g: f"{g} All")
            aggregated = pd.concat([aggregated, brand_rows], ignore_index=True, sort=False)

        outlet_fields = [field for field in ratio_group if field not in {"Item Name", "Category"}]
        outlet_totals = (
            aggregated.groupby(outlet_fields, as_index=False)
            .agg(
                OutletSales=("Sales", "sum"),
                OutletTx=("Transaction", "sum"),
                OutletQty=("Quantity", "sum"),
                OutletWastage=("Wastage", "sum"),
                OutletBillSales=("BillSales", "sum"),
            )
        )

        merged = aggregated.merge(outlet_totals, on=outlet_fields, how="left")

        def _ratio(numerator: pd.Series, denominator: pd.Series) -> pd.Series:
            return np.where(denominator.gt(0), (numerator / denominator) * 100.0, 0.0)

        merged["Sales Ratio %"] = _ratio(merged["Sales"], merged["OutletSales"])
        merged["Quantity Ratio %"] = _ratio(merged["Quantity"], merged["OutletQty"])
        wastage_denominator = merged["OutletQty"] + merged["OutletWastage"]
        merged["Wastage Ratio %"] = np.where(
            wastage_denominator.gt(0),
            (merged["Wastage"] / wastage_denominator) * 100.0,
            0.0,
        )
        merged["Bill Sales Ratio %"] = _ratio(merged["BillSales"], merged["OutletBillSales"])

        # Formatting
        merged["Sales"] = merged["Sales"].round(1)
        merged["Transaction"] = merged["Transaction"].fillna(0).astype(int)
        merged["Quantity"] = merged["Quantity"].round(1)
        merged["Wastage"] = merged["Wastage"].round(1)
        merged["Bill Sales"] = merged["BillSales"].round(1)

        for col in ("Sales Ratio %", "Quantity Ratio %", "Wastage Ratio %", "Bill Sales Ratio %"):
            merged[col] = merged[col].round(2).map(lambda x: f"{x:.2f}%")

        # Clean up helper columns
        merged.drop(columns=["BillSales", "OutletSales", "OutletTx", "OutletQty", "OutletWastage", "OutletBillSales"], inplace=True)
        merged.drop(columns=["BrandGroup"], inplace=True, errors="ignore")

        if mode == "Weekly" and "Period" in merged.columns:
            merged["Period"] = merged["Period"].astype(str).map(self._format_week_period_label)

        sort_fields = [field for field in columns if field in merged.columns]
        merged.sort_values(sort_fields, inplace=True)

        # Ensure column order
        return merged.reindex(columns=columns)

    def _build_payment_summary(
        self,
        payment_receipt: pd.DataFrame,
        receipt_totals: pd.DataFrame,
        store_brand_map: pd.DataFrame,
    ) -> pd.DataFrame:
        payment_receipt = payment_receipt.copy()
        payment_receipt["Date"] = pd.to_datetime(payment_receipt["c_date"], errors="coerce")
        payment_receipt["YearMonth"] = payment_receipt["Date"].dt.to_period("M").astype(str)
        payment_receipt["WeekLabel"] = payment_receipt["Date"].dt.strftime("%Y-W%V")

        group_cols = ["Date", "store_name", "sales_no"]
        total_tender = payment_receipt.groupby(group_cols)["tender_amount"].transform("sum").fillna(0.0)
        tax_total = payment_receipt.groupby(group_cols)["tax_total"].transform("max").fillna(0.0)
        net_total = payment_receipt.groupby(group_cols)["net_total"].transform("max").fillna(0.0)

        tender_ratio = np.divide(
            payment_receipt["tender_amount"],
            total_tender,
            out=np.zeros_like(payment_receipt["tender_amount"], dtype=float),
            where=total_tender.ne(0.0),
        )
        base_alloc = payment_receipt["tender_amount"] - tender_ratio * tax_total
        base_alloc = np.maximum(base_alloc, 0.0)

        is_cash = payment_receipt["payment_name"].astype(str).str.contains("CASH", case=False, na=False)
        payment_receipt["_base_non_cash"] = np.where(is_cash, 0.0, base_alloc)

        non_cash_sum = payment_receipt.groupby(group_cols)["_base_non_cash"].transform("sum")
        scale_reduce = np.where(
            (non_cash_sum > 0) & (net_total < non_cash_sum),
            np.maximum(net_total / non_cash_sum, 0.0),
            1.0,
        )
        payment_receipt["_base_non_cash"] *= scale_reduce

        non_cash_sum = payment_receipt.groupby(group_cols)["_base_non_cash"].transform("sum")
        payment_receipt["_cash_tender"] = np.where(is_cash, payment_receipt["tender_amount"], 0.0)
        cash_tender_total = payment_receipt.groupby(group_cols)["_cash_tender"].transform("sum")

        no_cash_scale = np.where(
            (cash_tender_total == 0) & (non_cash_sum > 0),
            np.maximum(net_total / non_cash_sum, 0.0),
            1.0,
        )
        payment_receipt["_base_non_cash"] *= no_cash_scale

        non_cash_sum = payment_receipt.groupby(group_cols)["_base_non_cash"].transform("sum")
        remainder = np.maximum(net_total - non_cash_sum, 0.0)

        cash_share = np.where(
            is_cash & cash_tender_total.gt(0),
            payment_receipt["tender_amount"] / cash_tender_total,
            0.0,
        )
        cash_alloc = cash_share * remainder

        payment_receipt["allocated_sales"] = np.where(is_cash, cash_alloc, payment_receipt["_base_non_cash"])

        brand_lookup = store_brand_map.drop_duplicates(subset=["store_name"])
        payment_receipt = payment_receipt.merge(brand_lookup, on="store_name", how="left")

        payment_receipt_group = (
            payment_receipt.groupby(
                ["Date", "WeekLabel", "YearMonth", "store_name", "sales_no", "payment_name", "BrandGroup"], as_index=False
            )
            .agg(
                payment_sales=("allocated_sales", "sum"),
                bill_total=("net_total", "max"),
            )
        )

        payment_receipt.drop(
            columns=["_base_non_cash", "_cash_tender", "allocated_sales", "total_tender"],
            inplace=True,
            errors="ignore",
        )

        outlet_totals = receipt_totals.copy()
        outlet_totals["Date"] = pd.to_datetime(outlet_totals["c_date"], errors="coerce")
        outlet_totals["YearMonth"] = outlet_totals["Date"].dt.to_period("M").astype(str)
        outlet_totals["WeekLabel"] = outlet_totals["Date"].dt.strftime("%Y-W%V")

        outlet_rollups = (
            outlet_totals.groupby(["Date", "WeekLabel", "YearMonth", "store_name"], as_index=False)
            .agg(
                outlet_bill_sales=("net_total", "sum"),
                outlet_receipts=("sales_no", "nunique"),
            )
        )

        outlet_payment_totals = (
            payment_receipt_group.groupby(["Date", "WeekLabel", "YearMonth", "store_name"], as_index=False)["payment_sales"].sum()
            .rename(columns={"payment_sales": "outlet_payment_sales"})
        )

        payment_summary = (
            payment_receipt_group.groupby(["Date", "WeekLabel", "YearMonth", "store_name", "payment_name"], as_index=False)
            .agg(
                payment_sales=("payment_sales", "sum"),
                receipts=("sales_no", "nunique"),
                bill_sales=("bill_total", "sum"),
            )
        )

        payment_summary = payment_summary.merge(
            outlet_rollups, on=["Date", "WeekLabel", "YearMonth", "store_name"], how="left"
        ).merge(
            outlet_payment_totals, on=["Date", "WeekLabel", "YearMonth", "store_name"], how="left"
        )

        payment_summary["Sales Ratio %"] = np.where(
            payment_summary["outlet_payment_sales"].gt(0),
            (payment_summary["payment_sales"] / payment_summary["outlet_payment_sales"]) * 100.0,
            0.0,
        )
        payment_summary["TC Ratio %"] = np.where(
            payment_summary["outlet_receipts"].gt(0),
            (payment_summary["receipts"] / payment_summary["outlet_receipts"]) * 100.0,
            0.0,
        )

        totals_rows = outlet_rollups.merge(
            outlet_payment_totals, on=["Date", "WeekLabel", "YearMonth", "store_name"], how="left"
        )
        totals_rows["payment_name"] = "TOTAL"
        totals_rows.rename(
            columns={
                "outlet_payment_sales": "payment_sales",
                "outlet_bill_sales": "bill_sales",
            },
            inplace=True,
        )
        totals_rows["receipts"] = totals_rows["outlet_receipts"].astype(int)
        totals_rows["Sales Ratio %"] = 100.0
        totals_rows["TC Ratio %"] = 100.0

        payment_summary = pd.concat([payment_summary, totals_rows], ignore_index=True, sort=False)
        payment_summary["IsTotal"] = payment_summary["payment_name"].eq("TOTAL").astype(int)

        detailed_rows = payment_summary[payment_summary["IsTotal"] == 0].copy()
        if not detailed_rows.empty:
            brand_grouped = detailed_rows.merge(brand_lookup, on="store_name", how="left")
            brand_grouped = brand_grouped.dropna(subset=["BrandGroup"])

            brand_outlet = (
                brand_grouped.groupby(["Date", "WeekLabel", "YearMonth", "BrandGroup", "payment_name"], as_index=False)
                .agg(
                    payment_sales=("payment_sales", "sum"),
                    receipts=("receipts", "sum"),
                    bill_sales=("bill_sales", "sum"),
                )
            )

            brand_totals = (
                brand_grouped.groupby(["Date", "WeekLabel", "YearMonth", "BrandGroup"], as_index=False)
                .agg(
                    period_payment_sales=("payment_sales", "sum"),
                    period_bill_sales=("bill_sales", "sum"),
                )
            )

            brand_receipt_totals = (
                outlet_rollups.merge(brand_lookup, on="store_name", how="left")
                .dropna(subset=["BrandGroup"])
                .groupby(["Date", "WeekLabel", "YearMonth", "BrandGroup"], as_index=False)
                .agg(period_receipts=("outlet_receipts", "sum"))
            )

            brand_outlet = brand_outlet.merge(brand_totals, on=["Date", "WeekLabel", "YearMonth", "BrandGroup"], how="left")
            brand_outlet = brand_outlet.merge(brand_receipt_totals, on=["Date", "WeekLabel", "YearMonth", "BrandGroup"], how="left")
            brand_outlet["Sales Ratio %"] = np.where(
                brand_outlet["period_payment_sales"].gt(0),
                (brand_outlet["payment_sales"] / brand_outlet["period_payment_sales"]) * 100.0,
                0.0,
            )
            brand_outlet["TC Ratio %"] = np.where(
                brand_outlet["period_receipts"].gt(0),
                (brand_outlet["receipts"] / brand_outlet["period_receipts"]) * 100.0,
                0.0,
            )
            brand_outlet["store_name"] = brand_outlet["BrandGroup"].map(lambda g: f"{g} All")
            brand_outlet["IsTotal"] = 0
            brand_outlet.drop(
                columns=["period_payment_sales", "period_bill_sales", "period_receipts", "BrandGroup"],
                inplace=True,
            )

            brand_totals = brand_totals.merge(brand_receipt_totals, on=["Date", "WeekLabel", "YearMonth", "BrandGroup"], how="left")
            brand_totals = brand_totals.rename(
                columns={
                    "period_payment_sales": "payment_sales",
                    "period_bill_sales": "bill_sales",
                    "period_receipts": "receipts",
                }
            )
            brand_totals["payment_name"] = "TOTAL"
            brand_totals["Sales Ratio %"] = 100.0
            brand_totals["TC Ratio %"] = 100.0
            brand_totals["store_name"] = brand_totals["BrandGroup"].map(lambda g: f"{g} All")
            brand_totals["IsTotal"] = 1
            brand_totals.drop(columns=["BrandGroup"], inplace=True)

            payment_summary = pd.concat([payment_summary, brand_outlet, brand_totals], ignore_index=True, sort=False)

        payment_summary["IsTotal"] = payment_summary["payment_name"].eq("TOTAL").astype(int)

        payment_summary.drop(
            columns=["outlet_bill_sales", "outlet_receipts", "outlet_payment_sales"],
            inplace=True,
            errors="ignore",
        )

        return payment_summary

    def _format_payment_period(self, summary: pd.DataFrame, mode: str) -> pd.DataFrame:
        columns = self._payment_columns_for_mode(mode)
        if summary.empty:
            return pd.DataFrame(columns=columns)

        frame = summary.copy()
        frame["Payment Sales"] = frame["payment_sales"].round(1)
        frame["Receipt"] = frame["receipts"].astype(int)
        frame["Bill Sales"] = frame["bill_sales"].round(1)
        frame["Sales Ratio %"] = frame["Sales Ratio %"].round(2)
        frame["TC Ratio %"] = frame["TC Ratio %"].round(2)

        if mode == "Daily":
            frame["Period"] = frame["Date"].dt.strftime("%Y-%m-%d")
        elif mode == "Weekly":
            frame["Period"] = frame["WeekLabel"]
        elif mode == "Monthly":
            frame["Period"] = frame["YearMonth"]
        else:
            frame["Period"] = "Selected Period"

        frame.rename(
            columns={
                "store_name": "Outlet",
                "payment_name": "Payment Type",
            },
            inplace=True,
        )

        grouping = ["Period", "Outlet", "Payment Type"] if mode != "Period" else ["Outlet", "Payment Type"]
        aggregated = (
            frame.groupby(grouping, as_index=False)
            .agg(
                PaymentSales=("Payment Sales", "sum"),
                Receipt=("Receipt", "sum"),
                BillSales=("Bill Sales", "sum"),
                SalesRatio=("Sales Ratio %", "mean"),
                TCRatio=("TC Ratio %", "mean"),
                IsTotal=("IsTotal", "max"),
            )
        )

        aggregated["Payment Sales"] = aggregated["PaymentSales"].round(1)
        aggregated["Bill Sales"] = aggregated["BillSales"].round(1)
        aggregated["Receipt"] = aggregated["Receipt"].astype(int)
        aggregated["Sales Ratio %"] = aggregated["SalesRatio"].round(2).map(lambda x: f"{x:.2f}%")
        aggregated["TC Ratio %"] = aggregated["TCRatio"].round(2).map(lambda x: f"{x:.2f}%")

        aggregated.drop(columns=["PaymentSales", "BillSales", "SalesRatio", "TCRatio"], inplace=True)

        sort_fields = (["Period"] if "Period" in aggregated.columns else []) + ["Outlet", "IsTotal", "Payment Type"]
        aggregated.sort_values(sort_fields, inplace=True)
        aggregated.drop(columns=["IsTotal"], inplace=True)

        if mode == "Weekly" and "Period" in aggregated.columns:
            aggregated["Period"] = aggregated["Period"].astype(str).map(self._format_week_period_label)

        return aggregated[columns]

    def _build_discount_summary(
        self,
        detail_frame: pd.DataFrame,
        store_brand_map: pd.DataFrame,
        receipt_totals: pd.DataFrame,
    ) -> pd.DataFrame:
        columns = [
            "Date",
            "WeekLabel",
            "YearMonth",
            "Outlet",
            "Discount Name",
            "Discount_Sales",
            "Quantity",
            "Transaction",
            "Bill Sales",
            "Discount Ratio",
            "Transaction Ratio",
            "Quantity Ratio",
        ]

        if detail_frame.empty or "disc_amt" not in detail_frame.columns:
            return pd.DataFrame(columns=columns)

        discounts = detail_frame.copy()
        discounts["Discount_Sales"] = pd.to_numeric(discounts.get("disc_amt"), errors="coerce").fillna(0.0)
        discounts["Quantity"] = pd.to_numeric(discounts.get("qty"), errors="coerce").fillna(0.0)
        discounts["Transaction"] = discounts.get("sales_no", "").astype(str)

        discounts = discounts[discounts["Discount_Sales"].gt(0)]
        if discounts.empty:
            return pd.DataFrame(columns=columns)

        discounts["Date"] = pd.to_datetime(discounts["c_date"], errors="coerce")
        discounts["YearMonth"] = discounts["Date"].dt.to_period("M").astype(str)
        discounts["WeekLabel"] = discounts["Date"].dt.strftime("%Y-W%V")
        discounts["Outlet"] = discounts.get("store_name", "").astype(str)
        discounts["Discount Name"] = discounts.get("disc_name", "").fillna("").astype(str)

        if not receipt_totals.empty:
            receipt_lookup = (
                receipt_totals[["c_date", "store_name", "sales_no", "net_total"]]
                .drop_duplicates()
                .rename(columns={"net_total": "ReceiptNet"})
            )
            discounts = discounts.merge(
                receipt_lookup,
                left_on=["c_date", "store_name", "Transaction"],
                right_on=["c_date", "store_name", "sales_no"],
                how="left",
            )
            discounts.drop(columns=["sales_no"], inplace=True, errors="ignore")
            discounts["Bill Sales"] = pd.to_numeric(discounts.get("ReceiptNet"), errors="coerce").fillna(0.0)
            discounts.drop(columns=["ReceiptNet"], inplace=True, errors="ignore")
        else:
            discounts["Bill Sales"] = 0.0

        if not discounts.empty:
            duplicate_mask = discounts.duplicated(
                subset=["Date", "WeekLabel", "YearMonth", "Outlet", "Discount Name", "Transaction"]
            )
            if duplicate_mask.any():
                discounts.loc[duplicate_mask, "Bill Sales"] = 0.0

        express_mask = discounts.get("source_database", "").astype(str).eq("sushi_express_pos_live")
        discounts.loc[express_mask, "Quantity"] = 1.0

        summary = (
            discounts.groupby(["Date", "WeekLabel", "YearMonth", "Outlet", "Discount Name"], as_index=False)
            .agg(
                Discount_Sales=("Discount_Sales", "sum"),
                Quantity=("Quantity", "sum"),
                Transaction=("Transaction", "nunique"),
                Bill_Sales=("Bill Sales", "sum"),
            )
        )

        brand_lookup = (
            store_brand_map.drop_duplicates(subset=["store_name"]).rename(columns={"store_name": "Outlet"})
        )
        summary = summary.merge(brand_lookup, on="Outlet", how="left")

        outlet_totals = summary.groupby(["Date", "WeekLabel", "YearMonth", "Outlet"], as_index=False).agg(
            total_sales=("Discount_Sales", "sum"),
            total_tx=("Transaction", "sum"),
            total_qty=("Quantity", "sum"),
        )
        summary = summary.merge(outlet_totals, on=["Date", "WeekLabel", "YearMonth", "Outlet"], how="left")
        summary["Discount Ratio"] = np.where(
            summary["total_sales"].gt(0),
            (summary["Discount_Sales"] / summary["total_sales"]) * 100.0,
            0.0,
        )
        summary["Transaction Ratio"] = np.where(
            summary["total_tx"].gt(0),
            (summary["Transaction"] / summary["total_tx"]) * 100.0,
            0.0,
        )
        summary["Quantity Ratio"] = np.where(
            summary["total_qty"].gt(0),
            (summary["Quantity"] / summary["total_qty"]) * 100.0,
            0.0,
        )
        summary.drop(columns=["total_sales", "total_tx", "total_qty"], inplace=True)

        brand_summary = (
            summary.dropna(subset=["BrandGroup"])
            .groupby(["Date", "WeekLabel", "YearMonth", "BrandGroup", "Discount Name"], as_index=False)
            .agg(
                Discount_Sales=("Discount_Sales", "sum"),
                Quantity=("Quantity", "sum"),
                Transaction=("Transaction", "sum"),
                Bill_Sales=("Bill_Sales", "sum"),
            )
        )

        brand_period_totals = (
            summary.dropna(subset=["BrandGroup"])
            .groupby(["Date", "WeekLabel", "YearMonth", "BrandGroup"], as_index=False)
            .agg(
                period_sales=("Discount_Sales", "sum"),
                period_tx=("Transaction", "sum"),
                period_qty=("Quantity", "sum"),
                period_bill_sales=("Bill_Sales", "sum"),
            )
        )

        brand_summary = brand_summary.merge(
            brand_period_totals,
            on=["Date", "WeekLabel", "YearMonth", "BrandGroup"],
            how="left",
        )
        brand_summary["Outlet"] = brand_summary["BrandGroup"].map(lambda group: f"{group} All")
        brand_summary["Discount Ratio"] = np.where(
            brand_summary["period_sales"].gt(0),
            (brand_summary["Discount_Sales"] / brand_summary["period_sales"]) * 100.0,
            0.0,
        )
        brand_summary["Transaction Ratio"] = np.where(
            brand_summary["period_tx"].gt(0),
            (brand_summary["Transaction"] / brand_summary["period_tx"]) * 100.0,
            0.0,
        )
        brand_summary["Quantity Ratio"] = np.where(
            brand_summary["period_qty"].gt(0),
            (brand_summary["Quantity"] / brand_summary["period_qty"]) * 100.0,
            0.0,
        )
        brand_summary.drop(
            columns=["period_sales", "period_tx", "period_qty", "period_bill_sales"],
            inplace=True,
        )
        brand_summary = brand_summary[
            [
                "Date",
                "WeekLabel",
                "YearMonth",
                "Outlet",
                "Discount Name",
                "Discount_Sales",
                "Quantity",
                "Transaction",
                "Bill_Sales",
                "Discount Ratio",
                "Transaction Ratio",
                "Quantity Ratio",
            ]
        ]

        combined = pd.concat([summary, brand_summary], ignore_index=True, sort=False)
        combined.sort_values(by=["Date", "Outlet", "Discount_Sales"], ascending=[False, True, False], inplace=True)
        combined.drop(columns=["BrandGroup"], inplace=True, errors="ignore")
        combined.rename(columns={"Bill_Sales": "Bill Sales"}, inplace=True)

        return combined

    def _format_discount_period(self, summary: pd.DataFrame, mode: str) -> pd.DataFrame:
        columns = DISCOUNT_ANALYSIS_COLUMNS.get(mode, [])
        if summary.empty:
            return pd.DataFrame(columns=columns)

        frame = summary.copy()
        if mode == "Daily":
            frame["Period"] = frame["Date"].dt.strftime("%Y-%m-%d")
        elif mode == "Weekly":
            frame["Period"] = frame["WeekLabel"]
        elif mode == "Monthly":
            frame["Period"] = frame["YearMonth"]
        else:
            frame["Period"] = "Selected Period"

        grouping = ["Period", "Outlet", "Discount Name"] if mode != "Period" else ["Outlet", "Discount Name"]
        aggregated = (
            frame.groupby(grouping, as_index=False)
            .agg(
                Discount_Sales=("Discount_Sales", "sum"),
                Quantity=("Quantity", "sum"),
                Transaction=("Transaction", "sum"),
                Bill_Sales=("Bill Sales", "sum"),
                DiscountRatio=("Discount Ratio", "mean"),
                TransactionRatio=("Transaction Ratio", "mean"),
                QuantityRatio=("Quantity Ratio", "mean"),
            )
        )

        aggregated["Discount Sales"] = aggregated["Discount_Sales"].round(1)
        aggregated["Quantity"] = aggregated["Quantity"].round(1)
        aggregated["Transaction"] = aggregated["Transaction"].astype(int)
        aggregated["Bill Sales"] = aggregated["Bill_Sales"].round(1)
        aggregated["Discount Ratio %"] = aggregated["DiscountRatio"].round(2).map(lambda value: f"{value:.2f}%")
        aggregated["Transaction Ratio %"] = aggregated["TransactionRatio"].round(2).map(lambda value: f"{value:.2f}%")
        aggregated["Quantity Ratio %"] = aggregated["QuantityRatio"].round(2).map(lambda value: f"{value:.2f}%")

        aggregated.drop(
            columns=["Discount_Sales", "Bill_Sales", "DiscountRatio", "TransactionRatio", "QuantityRatio"],
            inplace=True,
        )

        if "Period" not in aggregated.columns:
            aggregated.insert(0, "Period", "Selected Period")

        sort_fields = (["Period"] if "Period" in aggregated.columns else []) + ["Outlet", "Discount Sales"]
        aggregated.sort_values(sort_fields, ascending=[True] * len(sort_fields), inplace=True)

        if mode == "Weekly" and "Period" in aggregated.columns:
            aggregated["Period"] = aggregated["Period"].astype(str).map(self._format_week_period_label)

        return aggregated[columns]

    def _payment_columns_for_mode(self, mode: str) -> List[str]:
        if mode == "Period":
            return [
                "Outlet",
                "Payment Type",
                "Payment Sales",
                "Receipt",
                "Bill Sales",
                "Sales Ratio %",
                "TC Ratio %",
            ]
        return [
            "Period",
            "Outlet",
            "Payment Type",
            "Payment Sales",
            "Receipt",
            "Bill Sales",
            "Sales Ratio %",
            "TC Ratio %",
        ]

    @staticmethod
    def _format_week_period_label(week_label: str) -> str:
        try:
            year_part, week_part = week_label.split("-W")
            year = int(year_part)
            week = int(week_part)
            start_date = datetime.fromisocalendar(year, week, 1).date()
            end_date = datetime.fromisocalendar(year, week, 7).date()
        except (ValueError, AttributeError):
            return week_label

        start_text = f"{start_date.day}/{start_date.month}"
        end_text = f"{end_date.day}/{end_date.month}"
        return f"{week_label} ({start_text}~{end_text})"


class MultiSelectFilter(QtWidgets.QWidget):
    selection_changed = QtCore.pyqtSignal(list)

    def __init__(self, label: str, placeholder: str = "All", parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(parent)
        self._placeholder = placeholder
        self._selected: List[str] = []
        self._all_entry = "All"
        self._search_entry = "All (Search Results)"
        self._option_items: Dict[str, QtWidgets.QListWidgetItem] = {}
        self._all_item: Optional[QtWidgets.QListWidgetItem] = None
        self._search_item: Optional[QtWidgets.QListWidgetItem] = None

        layout = QtWidgets.QHBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 0)
        layout.setSpacing(6)

        self.label = QtWidgets.QLabel(label)
        layout.addWidget(self.label)

        self.button = QtWidgets.QToolButton()
        self.button.setPopupMode(QtWidgets.QToolButton.ToolButtonPopupMode.InstantPopup)
        self.button.setText(self._placeholder)
        self.button.setMinimumWidth(180)
        layout.addWidget(self.button, 1)

        self.clear_button = QtWidgets.QToolButton()
        self.clear_button.setText("Clear")
        self.clear_button.setEnabled(False)
        self.clear_button.clicked.connect(self._clear_clicked)
        layout.addWidget(self.clear_button)

        self.menu = QtWidgets.QMenu(self)
        self.button.setMenu(self.menu)
        self._suppress_emit = False
        self._pending_emit = False
        self.menu.aboutToShow.connect(self._on_menu_about_to_show)
        self.menu.aboutToHide.connect(self._on_menu_about_to_hide)

        self._list_action = QtWidgets.QWidgetAction(self.menu)
        container = QtWidgets.QWidget(self.menu)
        container_layout = QtWidgets.QVBoxLayout(container)
        container_layout.setContentsMargins(4, 4, 4, 4)
        container_layout.setSpacing(4)

        self._search_input = QtWidgets.QLineEdit(container)
        self._search_input.setPlaceholderText("Search…")
        self._search_input.textChanged.connect(self._on_search_text_changed)
        container_layout.addWidget(self._search_input)

        self._list_widget = QtWidgets.QListWidget(container)
        self._list_widget.setSelectionMode(QtWidgets.QAbstractItemView.SelectionMode.NoSelection)
        self._list_widget.setVerticalScrollMode(QtWidgets.QAbstractItemView.ScrollMode.ScrollPerPixel)
        self._list_widget.itemChanged.connect(self._on_item_changed)
        self._list_widget.itemClicked.connect(self._on_item_clicked)
        container_layout.addWidget(self._list_widget)

        close_layout = QtWidgets.QHBoxLayout()
        close_layout.setContentsMargins(0, 0, 0, 0)
        close_layout.setSpacing(4)
        close_layout.addStretch(1)
        close_button = QtWidgets.QPushButton("Close", container)
        close_button.clicked.connect(self.menu.hide)
        close_layout.addWidget(close_button)
        container_layout.addLayout(close_layout)

        self._list_action.setDefaultWidget(container)
        self.menu.addAction(self._list_action)

    def set_options(self, options: Iterable[str], *, maintain: bool = False) -> None:
        options_list = list(dict.fromkeys(options))
        if self._all_entry in options_list:
            options_list.remove(self._all_entry)
        previous = set(self._selected) if maintain else set()

        self._suppress_emit = True
        self._list_widget.blockSignals(True)
        self._list_widget.clear()
        self._option_items.clear()
        self._all_item = None
        self._search_item = None

        self._all_item = QtWidgets.QListWidgetItem(self._all_entry)
        self._all_item.setFlags(self._all_item.flags() | QtCore.Qt.ItemFlag.ItemIsUserCheckable)
        self._all_item.setCheckState(QtCore.Qt.CheckState.Checked)
        self._list_widget.addItem(self._all_item)

        self._search_item = QtWidgets.QListWidgetItem(self._search_entry)
        self._search_item.setFlags(self._search_item.flags() | QtCore.Qt.ItemFlag.ItemIsUserCheckable)
        self._search_item.setCheckState(QtCore.Qt.CheckState.Unchecked)
        self._search_item.setHidden(True)
        self._list_widget.addItem(self._search_item)

        for option in options_list:
            item = QtWidgets.QListWidgetItem(option)
            item.setFlags(item.flags() | QtCore.Qt.ItemFlag.ItemIsUserCheckable)
            item.setCheckState(QtCore.Qt.CheckState.Unchecked)
            self._list_widget.addItem(item)
            self._option_items[option] = item

        self._list_widget.blockSignals(False)
        self._suppress_emit = False

        if maintain and previous:
            self.set_selections([value for value in previous if value in options_list])
        else:
            self.set_selections(options_list)

        self._reset_search()

    def selections(self) -> List[str]:
        values = [value for value in self._selected if value != self._all_entry]
        return values

    def set_selections(self, values: Iterable[str]) -> None:
        cleaned = [value for value in values if value in self._option_items]
        self._suppress_emit = True
        self._list_widget.blockSignals(True)
        total_options = len(self._option_items)
        for option, item in self._option_items.items():
            item_state = QtCore.Qt.CheckState.Checked if option in cleaned else QtCore.Qt.CheckState.Unchecked
            item.setCheckState(item_state)
        if self._all_item is not None:
            if cleaned and len(cleaned) == total_options:
                self._set_all_item_state(QtCore.Qt.CheckState.Checked)
            elif cleaned:
                self._set_all_item_state(QtCore.Qt.CheckState.Unchecked)
            else:
                self._set_all_item_state(QtCore.Qt.CheckState.Unchecked)
        if self._search_item is not None:
            self._search_item.setCheckState(QtCore.Qt.CheckState.Unchecked)
        self._list_widget.blockSignals(False)
        self._suppress_emit = False
        self._update_selection_from_items(emit=False)
        self._update_search_item_state()

    def _on_menu_about_to_hide(self) -> None:
        if self._pending_emit and not self._suppress_emit:
            self._emit_selection()
        self._pending_emit = False

    def _request_emit(self) -> None:
        if self.menu.isVisible():
            self._pending_emit = True
        else:
            self._emit_selection()

    def _emit_selection(self) -> None:
        self.selection_changed.emit(self.selections())
        self._pending_emit = False

    def clear(self) -> None:
        self.set_selections([])

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------
    def _on_item_changed(self, item: QtWidgets.QListWidgetItem) -> None:
        checked = item.checkState() == QtCore.Qt.CheckState.Checked

        if item is self._all_item:
            self._list_widget.blockSignals(True)
            for list_item in self._option_items.values():
                list_item.setCheckState(QtCore.Qt.CheckState.Checked if checked else QtCore.Qt.CheckState.Unchecked)
            if self._search_item is not None:
                self._search_item.setCheckState(QtCore.Qt.CheckState.Unchecked)
            self._list_widget.blockSignals(False)
            self._update_selection_from_items()
            return
        elif item is self._search_item:
            targets = [it for it in self._option_items.values() if not it.isHidden()]
            if not targets:
                self._list_widget.blockSignals(True)
                self._search_item.setCheckState(QtCore.Qt.CheckState.Unchecked)
                self._list_widget.blockSignals(False)
            else:
                self._list_widget.blockSignals(True)
                for list_item in targets:
                    list_item.setCheckState(QtCore.Qt.CheckState.Checked if checked else QtCore.Qt.CheckState.Unchecked)
                if checked and self._all_item is not None:
                    self._all_item.setCheckState(QtCore.Qt.CheckState.Unchecked)
                self._list_widget.blockSignals(False)
        else:
            if checked and self._all_item is not None and self._all_item.checkState() == QtCore.Qt.CheckState.Checked:
                self._set_all_item_state(QtCore.Qt.CheckState.Unchecked)
            elif not checked and not any(
                itm.checkState() == QtCore.Qt.CheckState.Checked for itm in self._option_items.values()
            ):
                if self._all_item is not None:
                    self._set_all_item_state(QtCore.Qt.CheckState.Unchecked)

        self._update_selection_from_items()
        self._update_search_item_state()

    def _update_button(self) -> None:
        total_options = len(self._option_items)
        if not self._selected:
            self.button.setText(self._placeholder)
        elif total_options and len(self._selected) == total_options:
            self.button.setText("All")
        else:
            summary = ", ".join(self._selected[:3])
            if len(self._selected) > 3:
                summary += " …"
            self.button.setText(summary)
        self.clear_button.setEnabled(bool(self._selected))

    def _update_selection_from_items(self, *, emit: bool = True) -> None:
        previous = list(self._selected)
        selections = [name for name, item in self._option_items.items() if item.checkState() == QtCore.Qt.CheckState.Checked]
        total_options = len(self._option_items)

        if selections:
            self._selected = selections
            if total_options and len(selections) == total_options:
                self._set_all_item_state(QtCore.Qt.CheckState.Checked)
            else:
                self._set_all_item_state(QtCore.Qt.CheckState.Unchecked)
        else:
            self._selected = []
            self._set_all_item_state(QtCore.Qt.CheckState.Unchecked)

        if emit and previous != self._selected and not self._suppress_emit:
            self._request_emit()
        self._update_button()
        self.clear_button.setEnabled(bool(self._selected))
        self._update_search_item_state()

    def _set_all_item_state(self, state: QtCore.Qt.CheckState) -> None:
        if self._all_item is None:
            return
        if self._all_item.checkState() == state:
            return
        self._list_widget.blockSignals(True)
        self._all_item.setCheckState(state)
        self._list_widget.blockSignals(False)

    def _on_item_clicked(self, item: QtWidgets.QListWidgetItem) -> None:
        current_state = item.checkState()
        new_state = QtCore.Qt.CheckState.Unchecked if current_state == QtCore.Qt.CheckState.Checked else QtCore.Qt.CheckState.Checked
        self._list_widget.blockSignals(True)
        item.setCheckState(new_state)
        self._list_widget.blockSignals(False)
        self._on_item_changed(item)

    def _on_menu_about_to_show(self) -> None:
        min_width = max(self.button.width(), 260)
        self._list_widget.setMinimumWidth(min_width)
        self._reset_search()

    def _clear_clicked(self) -> None:
        if not self._selected:
            return
        self.clear()
        self._emit_selection()

    @QtCore.pyqtSlot(str)
    def _on_search_text_changed(self, text: str) -> None:
        text = text.strip().lower()
        any_visible = False
        for option, item in self._option_items.items():
            match = not text or text in option.lower()
            item.setHidden(not match)
            any_visible = any_visible or match

        if self._search_item is not None:
            self._list_widget.blockSignals(True)
            if not text or not any_visible:
                self._search_item.setHidden(True)
                self._search_item.setCheckState(QtCore.Qt.CheckState.Unchecked)
            else:
                flags = self._search_item.flags() | QtCore.Qt.ItemFlag.ItemIsUserCheckable | QtCore.Qt.ItemFlag.ItemIsEnabled
                self._search_item.setFlags(flags)
                self._search_item.setHidden(False)
            self._list_widget.blockSignals(False)

        self._update_search_item_state()

    def _visible_option_items(self) -> List[QtWidgets.QListWidgetItem]:
        return [item for item in self._option_items.values() if not item.isHidden()]

    def _update_search_item_state(self) -> None:
        if self._search_item is None or self._search_item.isHidden():
            return

        visible_items = self._visible_option_items()
        if not visible_items:
            state = QtCore.Qt.CheckState.Unchecked
        else:
            all_checked = all(item.checkState() == QtCore.Qt.CheckState.Checked for item in visible_items)
            state = QtCore.Qt.CheckState.Checked if all_checked else QtCore.Qt.CheckState.Unchecked

        self._list_widget.blockSignals(True)
        self._search_item.setCheckState(state)
        self._list_widget.blockSignals(False)

    def _reset_search(self) -> None:
        if self._search_input is not None:
            self._search_input.blockSignals(True)
            self._search_input.clear()
            self._search_input.blockSignals(False)
        for item in self._option_items.values():
            item.setHidden(False)
        if self._search_item is not None:
            self._list_widget.blockSignals(True)
            self._search_item.setHidden(True)
            self._search_item.setCheckState(QtCore.Qt.CheckState.Unchecked)
            self._list_widget.blockSignals(False)


class WeekdaySelector(QtWidgets.QWidget):
    selection_changed = QtCore.pyqtSignal(list)

    WEEKDAY_LABELS = [
        (0, "Mon"),
        (1, "Tue"),
        (2, "Wed"),
        (3, "Thu"),
        (4, "Fri"),
        (5, "Sat"),
        (6, "Sun"),
    ]

    def __init__(self, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(parent)
        layout = QtWidgets.QHBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 0)
        layout.setSpacing(6)

        self._updating = False
        self.all_button = PillToggleButton("Mon-Sun", self)
        self.all_button.toggled.connect(self._on_all_toggled)
        layout.addWidget(self.all_button)

        self._buttons: Dict[int, PillToggleButton] = {}
        for value, label in self.WEEKDAY_LABELS:
            button = PillToggleButton(label, self)
            button.toggled.connect(partial(self._on_day_toggled, value))  # type: ignore[arg-type]
            self._buttons[value] = button
            layout.addWidget(button)

        layout.addStretch(1)

    def selected_weekdays(self) -> List[int]:
        return sorted(value for value, button in self._buttons.items() if button.isChecked())

    def set_selected_weekdays(self, weekdays: Iterable[int]) -> None:
        normalized = set(int(day) for day in weekdays)
        self._updating = True
        try:
            for value, button in self._buttons.items():
                button.setChecked(value in normalized)
            self.all_button.setChecked(len(normalized) == len(self._buttons))
        finally:
            self._updating = False
        self.selection_changed.emit(self.selected_weekdays())

    def clear(self) -> None:
        self.set_selected_weekdays([])

    def _on_all_toggled(self, checked: bool) -> None:
        if self._updating:
            return
        self._updating = True
        try:
            for button in self._buttons.values():
                button.setChecked(checked)
        finally:
            self._updating = False
        self.selection_changed.emit(self.selected_weekdays())

    def _on_day_toggled(self, value: int, checked: bool) -> None:
        del checked
        if self._updating:
            return
        self._updating = True
        try:
            all_selected = all(button.isChecked() for button in self._buttons.values())
            self.all_button.setChecked(all_selected)
        finally:
            self._updating = False
        self.selection_changed.emit(self.selected_weekdays())


class PillToggleButton(QtWidgets.QToolButton):
    def __init__(self, text: str, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(parent)
        self.setText(text)
        self.setCheckable(True)
        self.setCursor(QtCore.Qt.CursorShape.PointingHandCursor)
        self.setFocusPolicy(QtCore.Qt.FocusPolicy.StrongFocus)
        self.setSizePolicy(QtWidgets.QSizePolicy.Policy.Fixed, QtWidgets.QSizePolicy.Policy.Fixed)
        self._apply_styles()

    def _apply_styles(self) -> None:
        self.setStyleSheet(
            """
QToolButton {
    border: 2px solid #3b74ff;
    border-radius: 18px;
    padding: 6px 20px;
    background-color: #101a33;
    color: #a9bff1;
    font-weight: 500;
}
QToolButton:hover {
    border: 2px solid #4d85ff;
    background-color: #162347;
    color: #c2d3ff;
}
QToolButton:checked {
    border: 2px solid #8ab8ff;
    background-color: #3b74ff;
    color: #f2f6ff;
}
QToolButton:checked:hover {
    border: 2px solid #b3ceff;
    background-color: #4b82ff;
}
QToolButton:disabled {
    border: 2px solid #3c4563;
    background-color: #18233a;
    color: #3c4563;
}
            """
        )


class DateRangePopup(QtWidgets.QDialog):
    range_selected = QtCore.pyqtSignal(object, object)
    cleared = QtCore.pyqtSignal()

    def __init__(
        self,
        parent: Optional[QtWidgets.QWidget] = None,
        *,
        minimum: Optional[date] = None,
        maximum: Optional[date] = None,
    ) -> None:
        super().__init__(parent)
        self.setWindowFlags(
            QtCore.Qt.WindowType.Popup
            | QtCore.Qt.WindowType.FramelessWindowHint
            | QtCore.Qt.WindowType.NoDropShadowWindowHint
        )
        self.setModal(False)

        self._minimum = minimum
        self._maximum = maximum
        self._start_date: Optional[date] = None
        self._end_date: Optional[date] = None

        layout = QtWidgets.QVBoxLayout(self)
        layout.setContentsMargins(14, 14, 14, 14)
        layout.setSpacing(10)

        self.summary_label = QtWidgets.QLabel("Select date range")
        layout.addWidget(self.summary_label)

        calendars = QtWidgets.QHBoxLayout()
        calendars.setSpacing(12)
        layout.addLayout(calendars)

        self.start_calendar = QtWidgets.QCalendarWidget()
        self.end_calendar = QtWidgets.QCalendarWidget()
        for calendar_widget in (self.start_calendar, self.end_calendar):
            calendar_widget.setVerticalHeaderFormat(QtWidgets.QCalendarWidget.VerticalHeaderFormat.NoVerticalHeader)
            calendar_widget.setGridVisible(True)
            calendar_widget.clicked.connect(self._on_date_clicked)
            if minimum is not None:
                calendar_widget.setMinimumDate(QtCore.QDate(minimum))
            if maximum is not None:
                calendar_widget.setMaximumDate(QtCore.QDate(maximum))
        calendars.addWidget(self.start_calendar, 1)
        calendars.addWidget(self.end_calendar, 1)

        button_grid = QtWidgets.QGridLayout()
        button_grid.setSpacing(6)
        quick_actions = [
            ("Today", self._select_today),
            ("Yesterday", self._select_yesterday),
            ("Last 7 Days", partial(self._select_last_n, 7)),
            ("Last 30 Days", partial(self._select_last_n, 30)),
            ("This Month", self._select_this_month),
            ("Last Month", self._select_last_month),
            ("This Year", self._select_this_year),
            ("Last Year", self._select_last_year),
        ]
        for index, (label, handler) in enumerate(quick_actions):
            button = QtWidgets.QPushButton(label)
            button.setCursor(QtCore.Qt.CursorShape.PointingHandCursor)
            button.clicked.connect(handler)
            button_grid.addWidget(button, index // 4, index % 4)
        layout.addLayout(button_grid)

        action_row = QtWidgets.QHBoxLayout()
        action_row.addStretch(1)

        clear_button = QtWidgets.QPushButton("Clear")
        clear_button.clicked.connect(self._on_clear)
        action_row.addWidget(clear_button)

        cancel_button = QtWidgets.QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        action_row.addWidget(cancel_button)

        apply_button = QtWidgets.QPushButton("Apply")
        apply_button.setDefault(True)
        apply_button.clicked.connect(self._on_apply)
        action_row.addWidget(apply_button)

        layout.addLayout(action_row)

    def set_range(self, start: Optional[date], end: Optional[date]) -> None:
        if start and end and end < start:
            start, end = end, start
        self._start_date = self._clamp(start)
        self._end_date = self._clamp(end)
        self._refresh_selection()
        self._update_summary()

    def set_bounds(self, minimum: Optional[date], maximum: Optional[date]) -> None:
        self._minimum = minimum
        self._maximum = maximum
        for calendar_widget in (self.start_calendar, self.end_calendar):
            if minimum is not None:
                calendar_widget.setMinimumDate(QtCore.QDate(minimum))
            else:
                calendar_widget.setMinimumDate(QtCore.QDate(1752, 9, 14))
            if maximum is not None:
                calendar_widget.setMaximumDate(QtCore.QDate(maximum))
            else:
                calendar_widget.setMaximumDate(QtCore.QDate(7999, 12, 31))
        self.set_range(self._start_date, self._end_date)

    def _clamp(self, value: Optional[date]) -> Optional[date]:
        if value is None:
            return None
        if self._minimum and value < self._minimum:
            return self._minimum
        if self._maximum and value > self._maximum:
            return self._maximum
        return value

    def _on_date_clicked(self, qdate: QtCore.QDate) -> None:
        clicked = qdate.toPyDate()
        if self._start_date is None or (self._start_date is not None and self._end_date is not None):
            self._start_date = clicked
            self._end_date = None
        else:
            if clicked < self._start_date:
                self._end_date = self._start_date
                self._start_date = clicked
            else:
                self._end_date = clicked
        self._start_date = self._clamp(self._start_date)
        self._end_date = self._clamp(self._end_date)
        self._refresh_selection()
        self._update_summary()

    def _refresh_selection(self) -> None:
        today = date.today()
        start_display = self._start_date or today
        end_display = self._end_date or self._start_date or today

        self.start_calendar.blockSignals(True)
        self.start_calendar.setSelectedDate(QtCore.QDate(start_display))
        self.start_calendar.setCurrentPage(start_display.year, start_display.month)
        self.start_calendar.blockSignals(False)

        self.end_calendar.blockSignals(True)
        self.end_calendar.setSelectedDate(QtCore.QDate(end_display))
        self.end_calendar.setCurrentPage(end_display.year, end_display.month)
        self.end_calendar.blockSignals(False)

    def _update_summary(self) -> None:
        if self._start_date and self._end_date:
            self.summary_label.setText(
                f"Selected {self._start_date.strftime('%d/%m/%Y')} - {self._end_date.strftime('%d/%m/%Y')}"
            )
        elif self._start_date:
            self.summary_label.setText(
                f"Selected start {self._start_date.strftime('%d/%m/%Y')} — choose end date"
            )
        else:
            self.summary_label.setText("Select date range")

    def _select_today(self) -> None:
        today = date.today()
        self.set_range(today, today)

    def _select_yesterday(self) -> None:
        today = date.today()
        self.set_range(today - timedelta(days=1), today - timedelta(days=1))

    def _select_last_n(self, days: int) -> None:
        today = date.today()
        start = today - timedelta(days=days - 1)
        self.set_range(start, today)

    def _select_this_month(self) -> None:
        today = date.today()
        start = today.replace(day=1)
        end = today.replace(day=calendar.monthrange(today.year, today.month)[1])
        self.set_range(start, end)

    def _select_last_month(self) -> None:
        today = date.today()
        year = today.year
        month = today.month - 1
        if month == 0:
            year -= 1
            month = 12
        start = date(year, month, 1)
        end = date(year, month, calendar.monthrange(year, month)[1])
        self.set_range(start, end)

    def _select_this_year(self) -> None:
        today = date.today()
        self.set_range(date(today.year, 1, 1), date(today.year, 12, 31))

    def _select_last_year(self) -> None:
        today = date.today()
        year = today.year - 1
        self.set_range(date(year, 1, 1), date(year, 12, 31))

    def _on_apply(self) -> None:
        if self._start_date is None:
            self.range_selected.emit(None, None)
        else:
            end_value = self._end_date or self._start_date
            self.range_selected.emit(self._start_date, end_value)
        self.accept()

    def _on_clear(self) -> None:
        self._start_date = None
        self._end_date = None
        self._refresh_selection()
        self._update_summary()
        self.cleared.emit()
        self.accept()


class DateRangePicker(QtWidgets.QWidget):
    range_changed = QtCore.pyqtSignal(object)

    def __init__(
        self,
        parent: Optional[QtWidgets.QWidget] = None,
        *,
        minimum: Optional[date] = None,
        maximum: Optional[date] = None,
    ) -> None:
        super().__init__(parent)
        self._minimum = minimum
        self._maximum = maximum
        self._start: Optional[date] = None
        self._end: Optional[date] = None

        layout = QtWidgets.QHBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 0)
        layout.setSpacing(0)

        self._display = QtWidgets.QLineEdit()
        self._display.setReadOnly(True)
        self._display.setPlaceholderText("Select date range")
        self._display.setCursor(QtCore.Qt.CursorShape.PointingHandCursor)
        self._display.installEventFilter(self)
        layout.addWidget(self._display, 1)

        self._popup: Optional[DateRangePopup] = None

    def set_bounds(self, minimum: Optional[date], maximum: Optional[date]) -> None:
        self._minimum = minimum
        self._maximum = maximum
        if self._popup is not None:
            self._popup.set_bounds(minimum, maximum)

    def set_range(self, start: Optional[date], end: Optional[date], *, notify: bool = False) -> None:
        if start and end and end < start:
            start, end = end, start
        self._start = start
        self._end = end
        self._update_display()
        if notify:
            self.range_changed.emit(self.current_range())
        if self._popup is not None:
            self._popup.set_range(start, end)

    def current_range(self) -> Tuple[Optional[date], Optional[date]]:
        return self._start, self._end

    def _show_popup(self) -> None:
        if self._popup is None:
            self._popup = DateRangePopup(self, minimum=self._minimum, maximum=self._maximum)
            self._popup.range_selected.connect(self._on_popup_selected)
            self._popup.cleared.connect(self._on_popup_cleared)
            self._popup.set_range(self._start, self._end)
        if self._minimum or self._maximum:
            self._popup.set_bounds(self._minimum, self._maximum)
        self._popup.set_range(self._start, self._end)
        popup_pos = self.mapToGlobal(QtCore.QPoint(0, self.height()))
        self._popup.move(popup_pos)
        self._popup.show()
        self._popup.raise_()
        self._popup.activateWindow()

    def eventFilter(self, source: QtCore.QObject, event: QtCore.QEvent) -> bool:  # type: ignore[override]
        if source is self._display and event.type() in {
            QtCore.QEvent.Type.MouseButtonPress,
            QtCore.QEvent.Type.MouseButtonRelease,
            QtCore.QEvent.Type.MouseButtonDblClick,
        }:
            if event.type() == QtCore.QEvent.Type.MouseButtonPress:
                self._show_popup()
            return True
        return super().eventFilter(source, event)

    def _on_popup_selected(self, start: Optional[date], end: Optional[date]) -> None:
        self._start = start
        self._end = end
        self._update_display()
        self.range_changed.emit(self.current_range())

    def _on_popup_cleared(self) -> None:
        self._start = None
        self._end = None
        self._update_display()
        self.range_changed.emit(self.current_range())

    def _update_display(self) -> None:
        if self._start and self._end:
            self._display.setText(
                f"{self._start.strftime('%d/%m/%Y')} - {self._end.strftime('%d/%m/%Y')}"
            )
        elif self._start:
            self._display.setText(self._start.strftime("%d/%m/%Y"))
        else:
            self._display.clear()


class TaskSignals(QtCore.QObject):
    finished = QtCore.pyqtSignal(object)
    failed = QtCore.pyqtSignal(Exception)

    def __init__(self, parent: Optional[QtCore.QObject] = None) -> None:
        super().__init__(parent)


class BackgroundTask(QtCore.QRunnable):
    def __init__(self, fn, *args, parent: Optional[QtCore.QObject] = None, **kwargs) -> None:
        super().__init__()
        self._fn = fn
        self._args = args
        self._kwargs = kwargs
        self._parent = parent
        self.signals = TaskSignals(parent)

    def run(self) -> None:
        try:
            result = self._fn(*self._args, **self._kwargs)
        except Exception as exc:  # pragma: no cover - defensive log
            self.signals.failed.emit(exc)
        else:
            self.signals.finished.emit(result)


class PandasTableModel(QtCore.QAbstractTableModel):
    def __init__(self, df: Optional[pd.DataFrame] = None, parent: Optional[QtCore.QObject] = None) -> None:
        super().__init__(parent)
        self._df = df if df is not None else pd.DataFrame()
        self._currency_columns = {"Sales", "Discount Sales", "Nett Sales", "Payment Sales", "Bill Sales"}
        self._header_overrides: Dict[str, str] = {}

    def set_frame(self, df: pd.DataFrame) -> None:
        self.beginResetModel()
        self._df = df
        self._header_overrides = {}
        self.endResetModel()

    def set_header_overrides(self, overrides: Dict[str, str]) -> None:
        self._header_overrides = overrides
        if not self._df.empty:
            self.headerDataChanged.emit(
                QtCore.Qt.Orientation.Horizontal,
                0,
                len(self._df.columns) - 1,
            )

    def rowCount(self, parent: QtCore.QModelIndex = QtCore.QModelIndex()) -> int:  # type: ignore[override]
        return 0 if parent.isValid() else len(self._df.index)

    def columnCount(self, parent: QtCore.QModelIndex = QtCore.QModelIndex()) -> int:  # type: ignore[override]
        return 0 if parent.isValid() else len(self._df.columns)

    def headerData(
        self,
        section: int,
        orientation: QtCore.Qt.Orientation,
        role: int = QtCore.Qt.ItemDataRole.DisplayRole,
    ) -> Optional[str]:  # type: ignore[override]
        if role != QtCore.Qt.ItemDataRole.DisplayRole:
            return None
        if orientation == QtCore.Qt.Orientation.Horizontal:
            if 0 <= section < len(self._df.columns):
                column_name = str(self._df.columns[section])
                return self._header_overrides.get(column_name, column_name)
        else:
            return str(self._df.index[section])
        return None

    def data(
        self,
        index: QtCore.QModelIndex,
        role: int = QtCore.Qt.ItemDataRole.DisplayRole,
    ) -> Optional[str]:  # type: ignore[override]
        if not index.isValid():
            return None

        value = self._df.iat[index.row(), index.column()]

        if role == QtCore.Qt.ItemDataRole.UserRole:
            if isinstance(value, str):
                cleaned = value.replace("$", "").replace(",", "").strip()
                try:
                    return float(cleaned)
                except ValueError:
                    return cleaned.lower()
            if isinstance(value, (datetime, date)):
                return datetime.combine(value, datetime.min.time()) if isinstance(value, date) and not isinstance(value, datetime) else value
            if pd.isna(value):
                return float("nan")
            return value

        if role not in (
            QtCore.Qt.ItemDataRole.DisplayRole,
            QtCore.Qt.ItemDataRole.ToolTipRole,
        ):
            return None

        column_name = self._df.columns[index.column()] if index.column() < len(self._df.columns) else ""
        if column_name in self._currency_columns:
            numeric = pd.to_numeric(value, errors="coerce")
            if pd.notna(numeric):
                return f"$ {numeric:,.1f}"
        if pd.isna(value):
            return ""
        return str(value)


class SalesTransactionView(QtWidgets.QWidget):
    def __init__(self, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(parent)
        layout = QtWidgets.QVBoxLayout(self)
        layout.setContentsMargins(12, 12, 12, 12)
        layout.setSpacing(8)

        self.summary_label = QtWidgets.QLabel("No data loaded")
        self.summary_label.setStyleSheet("color: #94a3b8;")
        layout.addWidget(self.summary_label)

        self.table = QtWidgets.QTableView()
        self.table.setAlternatingRowColors(True)
        self.table.setSortingEnabled(False)
        header = self.table.horizontalHeader()
        header.setStretchLastSection(True)
        header.setSectionResizeMode(QtWidgets.QHeaderView.ResizeMode.Stretch)
        header.setSortIndicatorShown(True)
        header.sectionClicked.connect(self._on_header_clicked)
        self.table.setSelectionBehavior(QtWidgets.QAbstractItemView.SelectionBehavior.SelectRows)
        self.table.setSelectionMode(QtWidgets.QAbstractItemView.SelectionMode.ExtendedSelection)
        layout.addWidget(self.table, 1)

        self._model = PandasTableModel()
        self._detail_frame = pd.DataFrame()
        self.proxy = SalesSearchProxy(self._model, self)
        self.table.setModel(self.proxy)
        self._selection_model: Optional[QtCore.QItemSelectionModel] = None
        self._connect_selection()
        self._current_sort_section: Optional[int] = None
        self._current_sort_order = QtCore.Qt.SortOrder.AscendingOrder

    def set_status(self, message: str) -> None:
        self.summary_label.setText(message)

    def update_data(self, df: pd.DataFrame) -> None:
        self._detail_frame = df.copy()
        self._model.set_frame(df)
        self.proxy.refresh()
        self._connect_selection()
        self._current_sort_section = None
        self._current_sort_order = QtCore.Qt.SortOrder.AscendingOrder
        header = self.table.horizontalHeader()
        header.setSortIndicatorShown(False)
        self._update_summary()
        self._update_header_summaries()

    def set_search_text(self, text: str) -> None:
        self.proxy.set_search_text(text)
        self._update_summary()
        self._update_header_summaries()

    def _on_header_clicked(self, section: int) -> None:
        columns = list(self._model._df.columns)
        if not columns or section >= len(columns):
            return

        column_name = columns[section]
        if self._detail_frame.empty:
            return

        if self._current_sort_section == section:
            ascending = self._current_sort_order == QtCore.Qt.SortOrder.DescendingOrder
            next_order = QtCore.Qt.SortOrder.AscendingOrder if ascending else QtCore.Qt.SortOrder.DescendingOrder
        else:
            ascending = True
            next_order = QtCore.Qt.SortOrder.AscendingOrder

        try:
            sorted_frame = (
                self._detail_frame.sort_values(column_name, ascending=ascending, kind="mergesort")
                .reset_index(drop=True)
            )
        except Exception:
            return

        self._detail_frame = sorted_frame
        self._model.set_frame(sorted_frame)
        self.proxy.refresh()
        self._connect_selection()
        self._update_summary()
        self._update_header_summaries()

        header = self.table.horizontalHeader()
        header.setSortIndicator(section, next_order)
        header.setSortIndicatorShown(True)
        self._current_sort_section = section
        self._current_sort_order = next_order

    def _update_summary(self) -> None:
        frame = self.proxy.current_frame()
        if frame.empty:
            self.summary_label.setText("No data found.")
            return

        rows = len(frame.index)
        if not frame.empty:
            summary_source = self._detail_frame[["Outlet", "Bill (Sales No)", "Date", "Payment"]].drop_duplicates()
            mask = ~summary_source["Payment"].str.contains(r"\bWASTAGE\b|\bSTAFF MEAL\b", case=False, na=False)
            unique_receipts = summary_source[mask][["Outlet", "Bill (Sales No)", "Date"]].drop_duplicates().shape[0]
        else:
            unique_receipts = 0
        net_total = pd.to_numeric(frame["Nett Sales"], errors="coerce").fillna(0.0).sum()
        self.summary_label.setText(
            f"Rows: {rows:,} | Receipts: {unique_receipts:,} | Nett Sales: $ {net_total:,.1f}"
        )
        self.table.resizeColumnsToContents()
        self._update_header_summaries()

    def _connect_selection(self) -> None:
        selection_model = self.table.selectionModel()
        if selection_model is self._selection_model:
            return
        if self._selection_model is not None:
            try:
                self._selection_model.selectionChanged.disconnect(self._on_selection_changed)
            except TypeError:
                pass
        self._selection_model = selection_model
        if selection_model is not None:
            selection_model.selectionChanged.connect(self._on_selection_changed)  # type: ignore[arg-type]

    def _on_selection_changed(self, *_: object) -> None:
        self._update_header_summaries()

    def _update_header_summaries(self) -> None:
        frame = self.proxy.current_frame().reset_index(drop=True)
        selection_model = self.table.selectionModel()
        selected_indexes = selection_model.selectedRows() if selection_model else []
        rows = sorted({index.row() for index in selected_indexes}) if selected_indexes else []

        if rows:
            frame = frame.iloc[rows].copy()

        columns = list(self._model._df.columns)
        if frame.empty or not columns:
            self._model.set_header_overrides({})
            return

        headers: Dict[str, str] = {}
        row_count = len(rows) if rows else len(self.proxy.current_frame())

        if columns:
            first_col = columns[0]
            headers[first_col] = f"{first_col}\nSUMMARY ({row_count} rows)"

        currency_columns = self._model._currency_columns

        for col in columns:
            if col not in frame.columns:
                continue
            if col == first_col:
                continue

            series = frame[col]
            if series.dtype == object:
                cleaned = series.astype(str).str.replace(",", "", regex=False).str.strip()
                numeric = pd.to_numeric(cleaned.str.replace("%", "", regex=False), errors="coerce")
            else:
                numeric = pd.to_numeric(series, errors="coerce")

            if not numeric.notna().any():
                continue

            total = numeric.sum()
            is_ratio = "percent" in col.lower() or "ratio" in col.lower() or "%" in col
            if is_ratio:
                value_text = f"{total:.2f}%"
            elif col in currency_columns:
                value_text = f"$ {total:,.1f}"
            elif col.lower() in {"receipt", "qty", "quantity"}:
                value_text = f"{int(round(total)):,}"
            else:
                value_text = f"{total:,.1f}" if isinstance(total, (int, float)) else str(total)

            headers[col] = f"{col}\n{value_text}"

        self._model.set_header_overrides(headers)


class SalesTransactionReportTab(QtWidgets.QWidget):
    def __init__(self, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(parent)
        layout = QtWidgets.QVBoxLayout(self)
        layout.setContentsMargins(4, 4, 4, 4)
        layout.setSpacing(4)

        self.tab_widget = QtWidgets.QTabWidget()
        self.details_view = SalesTransactionView()
        self.tab_widget.addTab(self.details_view, "Details Raw Data")

        self.payment_model = PandasTableModel()
        self.payment_proxy = SalesSearchProxy(self.payment_model, self)
        payment_page = QtWidgets.QWidget()
        payment_layout = QtWidgets.QVBoxLayout(payment_page)
        payment_layout.setContentsMargins(0, 0, 0, 0)
        payment_layout.setSpacing(2)

        self.payment_view = QtWidgets.QTableView()
        self.payment_view.setModel(self.payment_proxy)
        self.payment_view.setAlternatingRowColors(True)
        self.payment_view.setSortingEnabled(True)
        self.payment_view.horizontalHeader().setSectionResizeMode(QtWidgets.QHeaderView.ResizeMode.Stretch)
        self.payment_view.setSelectionBehavior(QtWidgets.QAbstractItemView.SelectionBehavior.SelectRows)
        self.payment_view.setSelectionMode(QtWidgets.QAbstractItemView.SelectionMode.ExtendedSelection)
        payment_layout.addWidget(self.payment_view, 1)

        self.tab_widget.addTab(payment_page, "Payment Analysis")

        discount_page = QtWidgets.QWidget()
        discount_layout = QtWidgets.QVBoxLayout(discount_page)
        discount_layout.setContentsMargins(0, 0, 0, 0)
        discount_layout.setSpacing(4)

        self.discount_summary_label = QtWidgets.QLabel("No discount data loaded")
        self.discount_summary_label.setStyleSheet("color: #94a3b8;")
        discount_layout.addWidget(self.discount_summary_label)

        self.discount_model = PandasTableModel()
        self.discount_proxy = SalesSearchProxy(self.discount_model, self)
        self.discount_view = QtWidgets.QTableView()
        self.discount_view.setModel(self.discount_proxy)
        self.discount_view.setAlternatingRowColors(True)
        self.discount_view.setSortingEnabled(True)
        self.discount_view.horizontalHeader().setSectionResizeMode(QtWidgets.QHeaderView.ResizeMode.Stretch)
        self.discount_view.setSelectionBehavior(QtWidgets.QAbstractItemView.SelectionBehavior.SelectRows)
        self.discount_view.setSelectionMode(QtWidgets.QAbstractItemView.SelectionMode.ExtendedSelection)
        discount_layout.addWidget(self.discount_view, 1)

        self.tab_widget.addTab(discount_page, "Discount Analysis")

        layout.addWidget(self.tab_widget)

        self._payment_selection_model: Optional[QtCore.QItemSelectionModel] = None
        self._connect_payment_selection()
        self._discount_selection_model: Optional[QtCore.QItemSelectionModel] = None
        self._connect_discount_selection()

    def update_payment_analysis(self, df: pd.DataFrame) -> None:
        self.payment_model.set_frame(df)
        self.payment_proxy.refresh()
        self._connect_payment_selection()
        if df.empty:
            self.payment_view.verticalHeader().setVisible(False)
        else:
            self.payment_view.verticalHeader().setVisible(True)
        self._update_payment_summary()

    def set_search_text(self, text: str) -> None:
        self.details_view.set_search_text(text)
        self.payment_proxy.set_search_text(text)
        self._update_payment_summary()
        self.discount_proxy.set_search_text(text)
        self._update_discount_summary()

    def _connect_payment_selection(self) -> None:
        selection_model = self.payment_view.selectionModel()
        if selection_model is self._payment_selection_model:
            return
        if self._payment_selection_model is not None:
            try:
                self._payment_selection_model.selectionChanged.disconnect(self._on_payment_selection_changed)
            except TypeError:
                pass
        self._payment_selection_model = selection_model
        if selection_model is not None:
            selection_model.selectionChanged.connect(self._on_payment_selection_changed)  # type: ignore[arg-type]

    def _on_payment_selection_changed(self, *_: object) -> None:
        self._update_payment_summary()

    def _update_payment_summary(self) -> None:
        selection_model = self.payment_view.selectionModel()
        selected_indexes = selection_model.selectedRows() if selection_model else []
        rows: List[int] = []
        base_frame = self.payment_proxy.current_frame().reset_index(drop=True)
        if selected_indexes:
            rows = sorted({index.row() for index in selected_indexes})
            frame = base_frame.iloc[rows].copy()
        else:
            frame = base_frame
        columns = list(self.payment_model._df.columns)
        if frame.empty or not columns:
            self.payment_model.set_header_overrides({})
            return

        headers: Dict[str, str] = {}
        row_count = len(rows) if rows else len(base_frame)

        if "Payment Type" in columns:
            headers["Payment Type"] = f"Payment Type\nSUMMARY ({row_count} rows)"
        else:
            first_col = columns[0]
            headers[first_col] = f"{first_col}\nSUMMARY ({row_count} rows)"

        currency_columns = self.payment_model._currency_columns

        for col in columns:
            if col not in frame.columns:
                continue

            series = frame[col]
            if series.dtype == object:
                cleaned = series.astype(str).str.replace(",", "", regex=False).str.strip()
                numeric = pd.to_numeric(cleaned.str.replace("%", "", regex=False), errors="coerce")
            else:
                numeric = pd.to_numeric(series, errors="coerce")

            if not numeric.notna().any():
                continue

            total = numeric.sum()
            is_ratio = "percent" in col.lower() or "ratio" in col.lower() or "%" in col
            if is_ratio:
                value_text = f"{total:.2f}%"
            elif col in currency_columns:
                value_text = f"$ {total:,.1f}"
            elif col.lower() == "receipt":
                value_text = f"{int(round(total)):,}"
            else:
                value_text = f"{total:,.1f}" if isinstance(total, (int, float)) else str(total)

            headers[col] = f"{col}\n{value_text}"

        headers["Bill Sales"] = f"Bill Sales\n$ {pd.to_numeric(frame.get('Bill Sales'), errors='coerce').fillna(0.0).sum():,.1f}"

        self.payment_model.set_header_overrides(headers)

        self.payment_view.resizeColumnsToContents()

    def update_discount_analysis(self, df: pd.DataFrame) -> None:
        self.discount_model.set_frame(df)
        self.discount_proxy.refresh()
        self._connect_discount_selection()
        if df.empty:
            self.discount_summary_label.setText("No discount data loaded")
            self.discount_model.set_header_overrides({})
            return
        self._update_discount_summary()

    def _connect_discount_selection(self) -> None:
        selection_model = self.discount_view.selectionModel()
        if selection_model is self._discount_selection_model:
            return
        if self._discount_selection_model is not None:
            try:
                self._discount_selection_model.selectionChanged.disconnect(self._on_discount_selection_changed)
            except TypeError:
                pass
        self._discount_selection_model = selection_model
        if selection_model is not None:
            selection_model.selectionChanged.connect(self._on_discount_selection_changed)  # type: ignore[arg-type]

    def _on_discount_selection_changed(self, *_: object) -> None:
        self._update_discount_summary()

    def _update_discount_summary(self) -> None:
        base_frame = self.discount_proxy.current_frame().reset_index(drop=True)
        selection_model = self.discount_view.selectionModel()
        selected_indexes = selection_model.selectedRows() if selection_model else []
        rows = sorted({index.row() for index in selected_indexes}) if selected_indexes else []

        if rows:
            frame = base_frame.iloc[rows].copy()
        else:
            frame = base_frame

        if frame.empty:
            if base_frame.empty:
                self.discount_summary_label.setText("No discount data loaded")
            else:
                self.discount_summary_label.setText("No discount rows available.")
            self.discount_model.set_header_overrides({})
            return

        row_count = len(frame)

        def _sum_numeric(series: Optional[pd.Series]) -> float:
            if series is None:
                return 0.0
            return float(pd.to_numeric(series, errors="coerce").fillna(0.0).sum())

        discount_total = _sum_numeric(frame.get("Discount Sales"))
        bill_sales_total = _sum_numeric(frame.get("Bill Sales"))
        quantity_total = _sum_numeric(frame.get("Quantity"))
        transaction_total = _sum_numeric(frame.get("Transaction"))

        self.discount_summary_label.setText(
            (
                "Rows: {rows:,} | Discount Sales: $ {sales:,.1f} | Bill Sales: $ {bill:,.1f} | "
                "Quantity: {qty:,.0f} | Transactions: {txn:,.0f}"
            ).format(
                rows=row_count,
                sales=discount_total,
                bill=bill_sales_total,
                qty=quantity_total,
                txn=transaction_total,
            )
        )

        headers: Dict[str, str] = {}
        columns = list(self.discount_model._df.columns)
        if columns:
            first_col = columns[0]
            if first_col in frame.columns:
                headers[first_col] = f"{first_col}\nSUMMARY ({row_count} rows)"

        currency_columns = {"Discount Sales", "Bill Sales"}

        for col in columns:
            if col not in frame.columns:
                continue
            if col in {columns[0] if columns else ""}:
                continue

            series = frame[col]
            if series.empty:
                headers[col] = col
                continue

            if col in {"Month", "Outlet", "Discount Name"}:
                headers[col] = col
                continue

            cleaned = series.astype(str).str.replace(",", "", regex=False).str.strip()
            numeric = pd.to_numeric(cleaned.str.replace("%", "", regex=False), errors="coerce")
            if not numeric.notna().any():
                headers[col] = col
                continue

            total = numeric.sum()
            if "ratio" in col.lower() or "%" in col:
                headers[col] = f"{col}\n{total:.2f}%"
            elif col in currency_columns:
                headers[col] = f"{col}\n$ {total:,.1f}"
            else:
                headers[col] = f"{col}\n{total:,.1f}"

        self.discount_model.set_header_overrides(headers)
        self.discount_view.resizeColumnsToContents()


class PromotionAnalysisTab(QtWidgets.QWidget):
    def __init__(self, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(parent)
        layout = QtWidgets.QVBoxLayout(self)
        layout.setContentsMargins(4, 4, 4, 4)
        layout.setSpacing(4)

        self.promotion_name_label = QtWidgets.QLabel("Promotion Name: (current filters)")
        header_font = QtGui.QFont()
        header_font.setPointSize(12)
        header_font.setBold(True)
        self.promotion_name_label.setFont(header_font)
        layout.addWidget(self.promotion_name_label)

        self.summary_label = QtWidgets.QLabel("No promotion data loaded")
        self.summary_label.setStyleSheet("color: #94a3b8;")
        layout.addWidget(self.summary_label)

        self._model = PandasTableModel()
        self._proxy = SalesSearchProxy(self._model, self)
        self.view = QtWidgets.QTableView()
        self.view.setModel(self._proxy)
        self.view.setAlternatingRowColors(True)
        self.view.setSortingEnabled(True)
        self.view.horizontalHeader().setSectionResizeMode(QtWidgets.QHeaderView.ResizeMode.Stretch)
        self.view.setSelectionBehavior(QtWidgets.QAbstractItemView.SelectionBehavior.SelectRows)
        self.view.setSelectionMode(QtWidgets.QAbstractItemView.SelectionMode.ExtendedSelection)
        layout.addWidget(self.view, 1)

        self._selection_model: Optional[QtCore.QItemSelectionModel] = None
        self._connect_selection()

    def update_report(self, df: pd.DataFrame) -> None:
        self._model.set_frame(df)
        self._proxy.refresh()
        self._connect_selection()

        if df.empty:
            self.summary_label.setText("No promotion data loaded")
            self._model.set_header_overrides({})
            self.view.verticalHeader().setVisible(False)
            return

        self.view.verticalHeader().setVisible(True)
        self._update_summary()

    def set_search_text(self, text: str) -> None:
        self._proxy.set_search_text(text)
        self._update_summary()

    def set_promotion_name(self, name: Optional[str]) -> None:
        if name:
            self.promotion_name_label.setText(f"Promotion Name: {name}")
        else:
            self.promotion_name_label.setText("Promotion Name: (current filters)")

    def _connect_selection(self) -> None:
        selection_model = self.view.selectionModel()
        if selection_model is self._selection_model:
            return
        if self._selection_model is not None:
            try:
                self._selection_model.selectionChanged.disconnect(self._on_selection_changed)
            except TypeError:
                pass
        self._selection_model = selection_model
        if selection_model is not None:
            selection_model.selectionChanged.connect(self._on_selection_changed)  # type: ignore[arg-type]

    def _on_selection_changed(self, *_: object) -> None:
        self._update_header_summaries()

    def _update_summary(self) -> None:
        frame = self._proxy.current_frame().reset_index(drop=True)
        if frame.empty:
            self.summary_label.setText("No promotion data loaded")
            self._model.set_header_overrides({})
            return

        rows = len(frame.index)

        def _sum(column: str) -> float:
            return float(pd.to_numeric(frame.get(column), errors="coerce").fillna(0.0).sum())

        sales_total = _sum("Sales")
        txn_total = _sum("Transaction")
        qty_total = _sum("Quantity")

        def _ratio_sum(column: str) -> Optional[float]:
            if column not in frame.columns:
                return None
            numeric = pd.to_numeric(frame[column].astype(str).str.rstrip("%"), errors="coerce").fillna(0.0)
            if numeric.empty:
                return None
            return float(numeric.sum())

        sales_ratio = _ratio_sum("Sales Ratio %")
        txn_ratio = _ratio_sum("Transaction Ratio %")
        qty_ratio = _ratio_sum("Quantity Ratio %")

        summary_parts = [
            f"Rows: {rows:,}",
            f"Sales: $ {sales_total:,.1f}",
            f"Transaction: {int(round(txn_total)):,.0f}",
            f"Quantity: {qty_total:,.1f}",
        ]
        ratio_pairs = (
            ("Sales Ratio %", sales_ratio),
            ("Transaction Ratio %", txn_ratio),
            ("Quantity Ratio %", qty_ratio),
        )
        for label, value in ratio_pairs:
            if value is not None:
                summary_parts.append(f"{label} Σ: {value:.2f}%")

        self.summary_label.setText(" | ".join(summary_parts))
        self._update_header_summaries()

    def _update_header_summaries(self) -> None:
        frame = self._proxy.current_frame().reset_index(drop=True)
        selection_model = self.view.selectionModel()
        selected_indexes = selection_model.selectedRows() if selection_model else []
        rows = sorted({index.row() for index in selected_indexes}) if selected_indexes else []

        if rows:
            frame = frame.iloc[rows].copy()

        columns = list(self._model._df.columns)
        if frame.empty or not columns:
            self._model.set_header_overrides({})
            return

        headers: Dict[str, str] = {}
        row_count = len(rows) if rows else len(self._proxy.current_frame())

        first_col = columns[0]
        headers[first_col] = f"{first_col}\nSUMMARY ({row_count} rows)"

        currency_columns = {"Sales"}
        integer_columns = {"Transaction"}
        quantity_columns = {"Quantity"}

        for col in columns:
            if col not in frame.columns or col == first_col:
                continue

            lower = col.lower()
            is_ratio = "ratio" in lower or "%" in lower
            numeric = pd.to_numeric(frame[col].astype(str).str.rstrip("%"), errors="coerce").fillna(0.0)
            if not numeric.notna().any():
                continue

            total = numeric.sum()
            if is_ratio:
                value_text = f"{total:.2f}%"
            elif col in currency_columns:
                value_text = f"$ {total:,.1f}"
            elif col in integer_columns:
                value_text = f"{int(round(total)):,}"
            elif col in quantity_columns:
                value_text = f"{total:,.1f}"
            else:
                value_text = f"{total:,.1f}"

            headers[col] = f"{col}\n{value_text}"

        self._model.set_header_overrides(headers)
        self.view.resizeColumnsToContents()


class SalesAnalysisReportStack(QtWidgets.QWidget):
    def __init__(self, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(parent)
        layout = QtWidgets.QVBoxLayout(self)
        layout.setContentsMargins(4, 4, 4, 4)
        layout.setSpacing(4)

        self.tab_widget = QtWidgets.QTabWidget()
        layout.addWidget(self.tab_widget, 1)

        self.promotion_tab = PromotionAnalysisTab()
        self.tab_widget.addTab(self.promotion_tab, "Promotion Analytics")

        self.product_tab = ProductDataReportTab()
        self.tab_widget.addTab(self.product_tab, "Product Analytics")

    def update_report(self, df: pd.DataFrame) -> None:
        self.promotion_tab.update_report(df)

    def update_promotion_analysis(self, df: pd.DataFrame) -> None:
        self.promotion_tab.update_report(df)

    def update_product_analysis(self, df: pd.DataFrame) -> None:
        self.product_tab.update_product_analysis(df)

    def set_search_text(self, text: str) -> None:
        self.promotion_tab.set_search_text(text)
        self.product_tab.set_search_text(text)

    def set_promotion_name(self, name: Optional[str]) -> None:
        self.promotion_tab.set_promotion_name(name)

class ProductDataReportTab(QtWidgets.QWidget):
    def __init__(self, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(parent)
        layout = QtWidgets.QVBoxLayout(self)
        layout.setContentsMargins(4, 4, 4, 4)
        layout.setSpacing(4)

        self.summary_label = QtWidgets.QLabel("No product data loaded")
        self.summary_label.setStyleSheet("color: #94a3b8;")
        layout.addWidget(self.summary_label)

        self.product_model = PandasTableModel()
        self.product_proxy = SalesSearchProxy(self.product_model, self)
        self.product_view = QtWidgets.QTableView()
        self.product_view.setModel(self.product_proxy)
        self.product_view.setAlternatingRowColors(True)
        self.product_view.setSortingEnabled(True)
        self.product_view.horizontalHeader().setSectionResizeMode(QtWidgets.QHeaderView.ResizeMode.Stretch)
        self.product_view.setSelectionBehavior(QtWidgets.QAbstractItemView.SelectionBehavior.SelectRows)
        self.product_view.setSelectionMode(QtWidgets.QAbstractItemView.SelectionMode.ExtendedSelection)
        layout.addWidget(self.product_view, 1)

        self._selection_model: Optional[QtCore.QItemSelectionModel] = None
        self._connect_selection()

    def update_product_analysis(self, df: pd.DataFrame) -> None:
        self.product_model.set_frame(df)
        self.product_proxy.refresh()
        self._connect_selection()

        if df.empty:
            self.summary_label.setText("No product data loaded")
            self.product_model.set_header_overrides({})
            self.product_view.verticalHeader().setVisible(False)
            return

        self.product_view.verticalHeader().setVisible(True)
        self._update_summary()

    def set_search_text(self, text: str) -> None:
        self.product_proxy.set_search_text(text)
        self._update_summary()

    def _connect_selection(self) -> None:
        selection_model = self.product_view.selectionModel()
        if selection_model is self._selection_model:
            return
        if self._selection_model is not None:
            try:
                self._selection_model.selectionChanged.disconnect(self._on_selection_changed)
            except TypeError:
                pass
        self._selection_model = selection_model
        if selection_model is not None:
            selection_model.selectionChanged.connect(self._on_selection_changed)  # type: ignore[arg-type]

    def _on_selection_changed(self, *_: object) -> None:
        self._update_header_summaries()

    def _update_summary(self) -> None:
        frame = self.product_proxy.current_frame().reset_index(drop=True)
        if frame.empty:
            if self.product_model._df.empty:
                self.summary_label.setText("No product data loaded")
            else:
                self.summary_label.setText("No product rows available.")
            self.product_model.set_header_overrides({})
            return

        rows = len(frame.index)

        def _sum(column: str) -> float:
            return float(pd.to_numeric(frame.get(column), errors="coerce").fillna(0.0).sum())

        sales_total = _sum("Sales")
        txn_total = _sum("Transaction")
        qty_total = _sum("Quantity")
        waste_total = _sum("Wastage")
        bill_total = _sum("Bill Sales")

        def _ratio_sum(column: str) -> Optional[float]:
            if column not in frame.columns:
                return None
            numeric = pd.to_numeric(frame[column].astype(str).str.rstrip("%"), errors="coerce").fillna(0.0)
            if numeric.empty:
                return None
            return float(numeric.sum())

        sales_ratio_total = _ratio_sum("Sales Ratio %")
        qty_ratio_total = _ratio_sum("Quantity Ratio %")
        waste_ratio_total = _ratio_sum("Wastage Ratio %")
        bill_ratio_total = _ratio_sum("Bill Sales Ratio %")

        summary_parts = [
            f"Rows: {rows:,}",
            f"Sales: $ {sales_total:,.1f}",
            f"Transaction: {int(round(txn_total)):,.0f}",
            f"Quantity: {qty_total:,.1f}",
            f"Wastage: {waste_total:,.1f}",
            f"Bill Sales: $ {bill_total:,.1f}",
        ]

        ratio_mappings = (
            ("Sales Ratio %", sales_ratio_total),
            ("Quantity Ratio %", qty_ratio_total),
            ("Wastage Ratio %", waste_ratio_total),
            ("Bill Sales Ratio %", bill_ratio_total),
        )

        for label, value in ratio_mappings:
            if value is not None:
                summary_parts.append(f"{label} Σ: {value:.2f}%")

        self.summary_label.setText(" | ".join(summary_parts))
        self._update_header_summaries()

    def _update_header_summaries(self) -> None:
        frame = self.product_proxy.current_frame().reset_index(drop=True)
        selection_model = self.product_view.selectionModel()
        selected_indexes = selection_model.selectedRows() if selection_model else []
        rows = sorted({index.row() for index in selected_indexes}) if selected_indexes else []

        if rows:
            frame = frame.iloc[rows].copy()

        columns = list(self.product_model._df.columns)
        if frame.empty or not columns:
            self.product_model.set_header_overrides({})
            return

        headers: Dict[str, str] = {}
        row_count = len(rows) if rows else len(self.product_proxy.current_frame())

        first_col = columns[0]
        headers[first_col] = f"{first_col}\nSUMMARY ({row_count} rows)"

        currency_columns = {"Sales", "Bill Sales"}
        quantity_columns = {"Quantity", "Wastage"}
        integer_columns = {"Transaction"}

        for col in columns:
            if col not in frame.columns or col == first_col:
                continue

            lower = col.lower()
            if "ratio" in lower:
                numeric = pd.to_numeric(frame[col].astype(str).str.rstrip("%"), errors="coerce").fillna(0.0)
                if not numeric.notna().any():
                    continue
                total = numeric.sum()
                headers[col] = f"{col}\n{total:.2f}%"
                continue

            numeric = pd.to_numeric(frame[col], errors="coerce").fillna(0.0)
            if not numeric.notna().any():
                continue

            total = numeric.sum()
            if col in currency_columns:
                value_text = f"$ {total:,.1f}"
            elif col in quantity_columns:
                value_text = f"{total:,.1f}"
            elif col in integer_columns:
                value_text = f"{total:,.0f}"
            else:
                value_text = f"{total:,.1f}"

            headers[col] = f"{col}\n{value_text}"

        self.product_model.set_header_overrides(headers)
        self.product_view.resizeColumnsToContents()


class ActivityRecordTableModel(QtCore.QAbstractTableModel):
    HEADERS = [
        "Promotion Name",
        "Date Range",
        "Weekdays",
        "Outlets",
        "Brands",
        "Categories",
        "Items",
        "Discounts",
        "Promotion Type",
        "Created",
        "Details",
    ]

    WEEKDAY_LABELS = WeekdaySelector.WEEKDAY_LABELS

    def __init__(self, parent: Optional[QtCore.QObject] = None) -> None:
        super().__init__(parent)
        self._records: List[ActivityRecord] = []

    def rowCount(self, parent: QtCore.QModelIndex = QtCore.QModelIndex()) -> int:  # type: ignore[override]
        if parent.isValid():
            return 0
        return len(self._records)

    def columnCount(self, parent: QtCore.QModelIndex = QtCore.QModelIndex()) -> int:  # type: ignore[override]
        if parent.isValid():
            return 0
        return len(self.HEADERS)

    def data(self, index: QtCore.QModelIndex, role: int = QtCore.Qt.ItemDataRole.DisplayRole) -> Optional[str]:  # type: ignore[override]
        if not index.isValid() or not (0 <= index.row() < len(self._records)):
            return None
        record = self._records[index.row()]
        column = index.column()

        if role == QtCore.Qt.ItemDataRole.DisplayRole:
            if column == 0:
                return record.name
            if column == 1:
                if record.date_from and record.date_to:
                    if record.date_from == record.date_to:
                        return record.date_from.isoformat()
                    return f"{record.date_from.isoformat()} ~ {record.date_to.isoformat()}"
                if record.date_from:
                    return f"{record.date_from.isoformat()} ~"
                if record.date_to:
                    return f"~ {record.date_to.isoformat()}"
                return "All"
            if column == 2:
                if not record.weekdays:
                    return "All"
                label_map = {value: label for value, label in self.WEEKDAY_LABELS}
                return ", ".join(label_map.get(day, str(day)) for day in record.weekdays)
            if column == 3:
                return ", ".join(record.outlets) if record.outlets else "All"
            if column == 4:
                return ", ".join(record.brands) if record.brands else "All"
            if column == 5:
                return ", ".join(record.categories) if record.categories else "All"
            if column == 6:
                return ", ".join(record.products) if record.products else "All"
            if column == 7:
                return ", ".join(record.discounts) if record.discounts else "All"
            if column == 8:
                return ", ".join(record.promotion_types) if record.promotion_types else "-"
            if column == 9:
                return record.created_at.strftime("%Y-%m-%d %H:%M")
            if column == 10:
                return record.details
        return None

    def headerData(self, section: int, orientation: QtCore.Qt.Orientation, role: int = QtCore.Qt.ItemDataRole.DisplayRole):  # type: ignore[override]
        if role != QtCore.Qt.ItemDataRole.DisplayRole:
            return None
        if orientation == QtCore.Qt.Orientation.Horizontal:
            if 0 <= section < len(self.HEADERS):
                return self.HEADERS[section]
        return super().headerData(section, orientation, role)

    def flags(self, index: QtCore.QModelIndex) -> QtCore.Qt.ItemFlag:  # type: ignore[override]
        base = super().flags(index)
        if not index.isValid():
            return base
        return base | QtCore.Qt.ItemFlag.ItemIsSelectable | QtCore.Qt.ItemFlag.ItemIsEnabled

    def set_records(self, records: Sequence[ActivityRecord]) -> None:
        self.beginResetModel()
        self._records = list(records)
        self.endResetModel()

    def record_at(self, row: int) -> Optional[ActivityRecord]:
        if 0 <= row < len(self._records):
            return self._records[row]
        return None


class FilterPanel(QtWidgets.QGroupBox):
    filters_changed = QtCore.pyqtSignal(FilterState)
    payment_options_changed = QtCore.pyqtSignal(bool, bool, bool, str)

    def __init__(self, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__("Filters", parent)
        self.setLayout(QtWidgets.QVBoxLayout())
        self.layout().setContentsMargins(8, 8, 8, 8)
        self.layout().setSpacing(8)

        toggles_widget = QtWidgets.QWidget()
        toggles_layout = QtWidgets.QHBoxLayout(toggles_widget)
        toggles_layout.setContentsMargins(0, 0, 0, 0)
        toggles_layout.setSpacing(12)

        toggles_layout.addWidget(QtWidgets.QLabel("Payment View:"))

        self.show_total_checkbox = PillToggleButton("Show Total")
        self.daily_average_checkbox = PillToggleButton("Daily Average")
        self.outlet_average_checkbox = PillToggleButton("Outlet Average")

        self.brand_filter = MultiSelectFilter("Brand")

        self.period_mode_combo = QtWidgets.QComboBox()
        self.period_mode_combo.addItems(list(PERIOD_OPTIONS))
        self.period_mode_combo.setCurrentText("Monthly")
        self.period_mode_combo.currentTextChanged.connect(self._emit_payment_options)

        for button in (
            self.show_total_checkbox,
            self.daily_average_checkbox,
            self.outlet_average_checkbox,
        ):
            toggles_layout.addWidget(button)
            button.toggled.connect(self._emit_payment_options)

        toggles_layout.addWidget(self.brand_filter)
        self.brand_filter.selection_changed.connect(self._on_filter_modified)

        toggles_layout.addWidget(QtWidgets.QLabel("Breakdown"))
        toggles_layout.addWidget(self.period_mode_combo)

        self.apply_button = QtWidgets.QPushButton("Filters auto apply")
        self.apply_button.setCursor(QtCore.Qt.CursorShape.ArrowCursor)
        self.apply_button.setFocusPolicy(QtCore.Qt.FocusPolicy.StrongFocus)
        self.apply_button.setFixedHeight(36)
        self.apply_button.setToolTip("Filters update automatically when selections change.")
        self.apply_button.setEnabled(False)
        self.apply_button.clicked.connect(self._apply_filters)
        toggles_layout.addWidget(self.apply_button)

        toggles_layout.addStretch(1)
        self.layout().addWidget(toggles_widget)

        date_widget = QtWidgets.QWidget()
        date_layout = QtWidgets.QHBoxLayout(date_widget)
        date_layout.setContentsMargins(0, 0, 0, 0)
        date_layout.setSpacing(6)

        today = QtCore.QDate.currentDate()
        first_of_month = QtCore.QDate(today.year(), today.month(), 1)
        self.date_range = DateRangePicker(minimum=date(1900, 1, 1))
        self.date_range.set_range(first_of_month.toPyDate(), today.toPyDate())
        self.date_range.range_changed.connect(self._on_filter_modified)

        date_layout.addWidget(QtWidgets.QLabel("Date Range"))
        date_layout.addWidget(self.date_range, 1)
        self.layout().addWidget(date_widget)

        weekday_container = QtWidgets.QWidget()
        weekday_layout = QtWidgets.QHBoxLayout(weekday_container)
        weekday_layout.setContentsMargins(0, 0, 0, 0)
        weekday_layout.setSpacing(6)

        weekday_layout.addWidget(QtWidgets.QLabel("Weekdays"))
        self.weekday_selector = WeekdaySelector()
        self.weekday_selector.selection_changed.connect(self._on_weekday_changed)
        weekday_layout.addWidget(self.weekday_selector, 1)
        self.layout().addWidget(weekday_container)

        grid_widget = QtWidgets.QWidget()
        grid_layout = QtWidgets.QGridLayout(grid_widget)
        grid_layout.setContentsMargins(0, 0, 0, 0)
        grid_layout.setHorizontalSpacing(12)
        grid_layout.setVerticalSpacing(6)

        self.outlet_filter = MultiSelectFilter("Outlet")
        self.month_filter = MultiSelectFilter("Month")
        self.week_filter = MultiSelectFilter("Week")
        self.payment_filter = MultiSelectFilter("Payment Method")
        self.category_filter = MultiSelectFilter("Category")
        self.product_filter = MultiSelectFilter("Product")
        self.discount_filter = MultiSelectFilter("Discount")

        filters = [
            self.outlet_filter,
            self.month_filter,
            self.week_filter,
            self.payment_filter,
            self.category_filter,
            self.product_filter,
            self.discount_filter,
        ]

        for index, widget in enumerate(filters):
            row = index // 3
            column = index % 3
            grid_layout.addWidget(widget, row, column)
            widget.selection_changed.connect(self._on_filter_modified)

        self.layout().addWidget(grid_widget)

        self._state = FilterState()
        self._filters_dirty = False
        self._emit_payment_options()

    def populate(self, options: Dict[str, List[str]], *, emit: bool = False) -> None:
        self.outlet_filter.set_options(options.get("outlets", []), maintain=True)
        self.month_filter.set_options(options.get("months", []), maintain=True)
        self.week_filter.set_options(options.get("weeks", []), maintain=True)
        self.payment_filter.set_options(options.get("payments", []), maintain=True)
        self.brand_filter.set_options(options.get("brands", []), maintain=True)
        self.category_filter.set_options(options.get("categories", []), maintain=True)
        self.product_filter.set_options(options.get("products", []), maintain=True)
        self.discount_filter.set_options(options.get("discounts", []), maintain=True)

        self._state = self._gather_state()
        self._filters_dirty = False
        self.apply_button.setEnabled(False)
        if emit:
            self.filters_changed.emit(self._state)
        self._emit_payment_options()

    def _gather_state(self) -> FilterState:
        date_from, date_to = self.date_range.current_range()
        return FilterState(
            date_from=date_from,
            date_to=date_to,
            outlets=self.outlet_filter.selections(),
            months=self.month_filter.selections(),
            weeks=self.week_filter.selections(),
            payments=self.payment_filter.selections(),
            categories=self.category_filter.selections(),
            products=self.product_filter.selections(),
            brands=self.brand_filter.selections(),
            discounts=self.discount_filter.selections(),
            weekdays=self.weekday_selector.selected_weekdays(),
        )

    def _on_filter_modified(self, *_: object) -> None:
        self._emit_changes()

    def _on_weekday_changed(self, _values: List[int]) -> None:
        del _values
        self._state = self._gather_state()
        self._filters_dirty = False
        self.apply_button.setEnabled(False)
        self.filters_changed.emit(self._state)

    def current_state(self) -> FilterState:
        return self._state

    def refresh_state(self) -> FilterState:
        self._emit_changes()
        return self._state

    def _apply_filters(self) -> None:
        self._emit_changes()

    def _emit_changes(self) -> None:
        self._state = self._gather_state()
        self.filters_changed.emit(self._state)
        self._filters_dirty = False
        self.apply_button.setEnabled(False)

    def set_filter_controls_enabled(self, enabled: bool) -> None:
        self.date_range.setEnabled(enabled)
        self.weekday_selector.setEnabled(enabled)
        for widget in (
            self.outlet_filter,
            self.month_filter,
            self.week_filter,
            self.payment_filter,
            self.category_filter,
            self.product_filter,
            self.discount_filter,
            self.brand_filter,
        ):
            widget.setEnabled(enabled)

    def apply_state(self, state: FilterState) -> None:
        self.date_range.set_range(state.date_from, state.date_to)
        self.outlet_filter.set_selections(state.outlets)
        self.month_filter.set_selections(state.months)
        self.week_filter.set_selections(state.weeks)
        self.payment_filter.set_selections(state.payments)
        self.category_filter.set_selections(state.categories)
        self.product_filter.set_selections(state.products)
        self.discount_filter.set_selections(state.discounts)
        self.brand_filter.set_selections(state.brands)
        self.weekday_selector.set_selected_weekdays(state.weekdays)
        self._emit_changes()

    def current_payment_options(self) -> PaymentDisplayOptions:
        return PaymentDisplayOptions(
            show_total=self.show_total_checkbox.isChecked(),
            daily_average=self.daily_average_checkbox.isChecked(),
            outlet_average=self.outlet_average_checkbox.isChecked(),
            period_mode=str(self.period_mode_combo.currentText()),
        )

    def _emit_payment_options(self) -> None:
        opts = self.current_payment_options()
        self.payment_options_changed.emit(
            opts.show_total,
            opts.daily_average,
            opts.outlet_average,
            opts.period_mode,
        )


class ActivityLogTab(QtWidgets.QWidget):
    record_add_requested = QtCore.pyqtSignal(object)
    record_apply_requested = QtCore.pyqtSignal(object)
    record_delete_requested = QtCore.pyqtSignal(str)
    promotion_filters_changed = QtCore.pyqtSignal(FilterState)

    def __init__(self, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(parent)
        self._records: List[ActivityRecord] = []
        self._current_record: Optional[ActivityRecord] = None

        layout = QtWidgets.QVBoxLayout(self)
        layout.setContentsMargins(8, 8, 8, 8)
        layout.setSpacing(10)

        form_group = QtWidgets.QGroupBox("Promotion Filters")
        form_layout = QtWidgets.QGridLayout(form_group)
        form_layout.setHorizontalSpacing(10)
        form_layout.setVerticalSpacing(8)

        self.promotion_name_input = QtWidgets.QLineEdit()
        self.promotion_details_input = QtWidgets.QTextEdit()
        self.promotion_details_input.setFixedHeight(80)

        form_layout.addWidget(QtWidgets.QLabel("Promotion Name"), 0, 0)
        form_layout.addWidget(self.promotion_name_input, 0, 1, 1, 3)
        form_layout.addWidget(QtWidgets.QLabel("Promotion Details"), 1, 0)
        form_layout.addWidget(self.promotion_details_input, 1, 1, 1, 3)

        self.date_range = DateRangePicker(minimum=date(1900, 1, 1))
        self.date_range.range_changed.connect(self._on_form_modified)
        self._set_default_dates()

        date_range_widget = QtWidgets.QWidget()
        date_layout = QtWidgets.QHBoxLayout(date_range_widget)
        date_layout.setContentsMargins(0, 0, 0, 0)
        date_layout.setSpacing(6)
        date_layout.addWidget(QtWidgets.QLabel("Date Range"))
        date_layout.addWidget(self.date_range, 1)

        form_layout.addWidget(date_range_widget, 2, 0, 1, 4)

        self.weekday_selector = WeekdaySelector()
        self.weekday_selector.selection_changed.connect(self._on_form_modified)

        self.brand_filter = MultiSelectFilter("Brand", placeholder="Select", parent=self)

        weekday_brand_container = QtWidgets.QWidget()
        weekday_brand_layout = QtWidgets.QHBoxLayout(weekday_brand_container)
        weekday_brand_layout.setContentsMargins(0, 0, 0, 0)
        weekday_brand_layout.setSpacing(12)
        weekday_brand_layout.addWidget(QtWidgets.QLabel("Weekdays"))
        weekday_brand_layout.addWidget(self.weekday_selector, 1)
        weekday_brand_layout.addWidget(self.brand_filter)
        weekday_brand_layout.addStretch(1)
        form_layout.addWidget(weekday_brand_container, 3, 0, 1, 4)

        self.outlet_filter = MultiSelectFilter("Outlet", parent=self)
        self.category_filter = MultiSelectFilter("Category", parent=self)
        self.product_filter = MultiSelectFilter("Item", parent=self)
        self.discount_filter = MultiSelectFilter("Discount", parent=self)

        self.promotion_type_filter = MultiSelectFilter("Promotion Type", parent=self)
        self.promotion_type_filter.set_options(PROMOTION_TYPES)

        filter_grid = QtWidgets.QGridLayout()
        filter_grid.setContentsMargins(0, 0, 0, 0)
        filter_grid.setHorizontalSpacing(10)
        filter_grid.setVerticalSpacing(10)
        filter_grid.addWidget(self.outlet_filter, 0, 0)
        filter_grid.addWidget(self.category_filter, 0, 1)
        filter_grid.addWidget(self.product_filter, 0, 2)
        filter_grid.addWidget(self.discount_filter, 1, 0)
        filter_grid.addWidget(self.promotion_type_filter, 1, 1)
        filter_grid.addItem(
            QtWidgets.QSpacerItem(
                20,
                20,
                QtWidgets.QSizePolicy.Policy.Expanding,
                QtWidgets.QSizePolicy.Policy.Minimum,
            ),
            1,
            2,
        )
        filter_grid.setColumnStretch(0, 1)
        filter_grid.setColumnStretch(1, 1)
        filter_grid.setColumnStretch(2, 1)

        filter_container = QtWidgets.QWidget()
        filter_container.setLayout(filter_grid)
        form_layout.addWidget(filter_container, 4, 0, 1, 4)

        button_layout = QtWidgets.QHBoxLayout()
        self.save_button = QtWidgets.QPushButton("Save Record")
        self.apply_button = QtWidgets.QPushButton("Apply to Filters")
        self.delete_button = QtWidgets.QPushButton("Delete Record")
        self.clear_button = QtWidgets.QPushButton("Clear")
        self.apply_button.setEnabled(False)
        self.delete_button.setEnabled(False)

        for button in (self.save_button, self.apply_button, self.delete_button, self.clear_button):
            button_layout.addWidget(button)
        button_layout.addStretch(1)

        form_layout.addLayout(button_layout, 5, 0, 1, 4)

        layout.addWidget(form_group)

        self.records_model = ActivityRecordTableModel(self)
        self.records_view = QtWidgets.QTableView()
        self.records_view.setModel(self.records_model)
        self.records_view.setSelectionBehavior(QtWidgets.QAbstractItemView.SelectionBehavior.SelectRows)
        self.records_view.setSelectionMode(QtWidgets.QAbstractItemView.SelectionMode.SingleSelection)
        self.records_view.horizontalHeader().setSectionResizeMode(QtWidgets.QHeaderView.ResizeMode.Stretch)
        self.records_view.verticalHeader().setVisible(False)

        layout.addWidget(self.records_view, 1)

        self._selection_model: Optional[QtCore.QItemSelectionModel] = None

        self.save_button.clicked.connect(self._on_save_clicked)
        self.apply_button.clicked.connect(self._on_apply_clicked)
        self.delete_button.clicked.connect(self._on_delete_clicked)
        self.clear_button.clicked.connect(self.clear_form)

        self.outlet_filter.selection_changed.connect(self._on_form_modified)
        self.brand_filter.selection_changed.connect(self._on_form_modified)
        self.category_filter.selection_changed.connect(self._on_form_modified)
        self.product_filter.selection_changed.connect(self._on_form_modified)
        self.discount_filter.selection_changed.connect(self._on_form_modified)
        self.promotion_type_filter.selection_changed.connect(self._on_form_modified)

        self._filter_controls: List[QtWidgets.QWidget] = [
            self.brand_filter,
            self.outlet_filter,
            self.category_filter,
            self.product_filter,
            self.discount_filter,
            self.promotion_type_filter,
        ]
        self.promotion_name_input.textChanged.connect(self._on_form_modified)
        self.promotion_details_input.textChanged.connect(self._on_form_modified)
        self._current_filter_state: FilterState = self._gather_filter_state()

    # ------------------------------------------------------------------
    # Form helpers
    # ------------------------------------------------------------------
    def _default_date_range(self) -> Tuple[QtCore.QDate, QtCore.QDate]:
        today = QtCore.QDate.currentDate()
        start = QtCore.QDate(today.year(), today.month(), 1)
        return start, today

    def _set_default_dates(self) -> None:
        start_qdate, end_qdate = self._default_date_range()
        self.date_range.set_range(start_qdate.toPyDate(), end_qdate.toPyDate())

    def update_filter_options(self, options: Dict[str, List[str]]) -> None:
        self.outlet_filter.set_options(options.get("outlets", []), maintain=True)
        self.brand_filter.set_options(options.get("brands", []), maintain=True)
        self.category_filter.set_options(options.get("categories", []), maintain=True)
        self.product_filter.set_options(options.get("products", []), maintain=True)
        self.discount_filter.set_options(options.get("discounts", []), maintain=True)
        self.promotion_type_filter.set_options(PROMOTION_TYPES, maintain=True)
        self._current_filter_state = self._gather_filter_state()

    def current_filter_state(self) -> FilterState:
        return self._current_filter_state

    def set_filter_controls_enabled(self, enabled: bool) -> None:
        self.date_range.setEnabled(enabled)
        self.weekday_selector.setEnabled(enabled)
        for widget in self._filter_controls:
            widget.setEnabled(enabled)

    def _gather_filter_state(self) -> FilterState:
        date_from, date_to = self.date_range.current_range()
        return FilterState(
            date_from=date_from,
            date_to=date_to,
            outlets=self.outlet_filter.selections(),
            months=[],
            weeks=[],
            payments=[],
            categories=self.category_filter.selections(),
            products=self.product_filter.selections(),
            brands=self.brand_filter.selections(),
            discounts=self.discount_filter.selections(),
            weekdays=self.weekday_selector.selected_weekdays(),
            promotion_name=self.promotion_name_input.text().strip() or None,
            promotion_details=self.promotion_details_input.toPlainText().strip() or None,
            promotion_types=self.promotion_type_filter.selections(),
        )

    def _schedule_filters_changed(self) -> None:
        state = self._gather_filter_state()
        if state == self._current_filter_state:
            return
        self._current_filter_state = state
        self.promotion_filters_changed.emit(state)

    def set_records(self, records: Sequence[ActivityRecord]) -> None:
        self._records = list(records)
        self.records_model.set_records(records)
        self._sync_selection_model()

    def select_record(self, record_id: str) -> None:
        for row, record in enumerate(self._records):
            if record.id == record_id:
                index = self.records_model.index(row, 0)
                self.records_view.selectionModel().select(
                    index, QtCore.QItemSelectionModel.SelectionFlag.ClearAndSelect | QtCore.QItemSelectionModel.SelectionFlag.Rows
                )
                self.records_view.scrollTo(index)
                self._load_record(record)
                return

    def clear_form(self) -> None:
        self._current_record = None
        self.promotion_name_input.clear()
        self.promotion_details_input.clear()
        self._set_default_dates()
        self.weekday_selector.clear()
        self.outlet_filter.clear()
        self.brand_filter.clear()
        self.category_filter.clear()
        self.product_filter.clear()
        self.discount_filter.clear()
        self.promotion_type_filter.clear()
        if self.records_view.selectionModel() is not None:
            self.records_view.selectionModel().clearSelection()
        self.apply_button.setEnabled(False)
        self.delete_button.setEnabled(False)

    # ------------------------------------------------------------------
    # Event handlers
    # ------------------------------------------------------------------
    def _sync_selection_model(self) -> None:
        selection_model = self.records_view.selectionModel()
        if selection_model is None:
            selection_model = QtCore.QItemSelectionModel(self.records_model)
            self.records_view.setSelectionModel(selection_model)
        if selection_model is self._selection_model:
            return
        if self._selection_model is not None:
            try:
                self._selection_model.selectionChanged.disconnect(self._on_selection_changed)
            except TypeError:
                pass
        self._selection_model = selection_model
        if selection_model is not None:
            selection_model.selectionChanged.connect(self._on_selection_changed)  # type: ignore[arg-type]

    def _on_form_modified(self, *_: object) -> None:
        self._schedule_filters_changed()

    def _on_selection_changed(self, *_: object) -> None:
        selection_model = self.records_view.selectionModel()
        if selection_model is None or not selection_model.hasSelection():
            self.apply_button.setEnabled(False)
            self.delete_button.setEnabled(False)
            return
        selected_rows = selection_model.selectedRows()
        if not selected_rows:
            self.apply_button.setEnabled(False)
            self.delete_button.setEnabled(False)
            return
        row = selected_rows[0].row()
        record = self.records_model.record_at(row)
        if record is None:
            self.apply_button.setEnabled(False)
            self.delete_button.setEnabled(False)
            return
        self.apply_button.setEnabled(True)
        self.delete_button.setEnabled(True)
        self._load_record(record)

    def _load_record(self, record: ActivityRecord) -> None:
        self._current_record = record
        self.promotion_name_input.setText(record.name)
        self.promotion_details_input.setPlainText(record.details)

        self.date_range.set_range(record.date_from, record.date_to)

        self.weekday_selector.set_selected_weekdays(record.weekdays)
        self.outlet_filter.set_selections(record.outlets)
        self.brand_filter.set_selections(record.brands)
        self.category_filter.set_selections(record.categories)
        self.product_filter.set_selections(record.products)
        self.discount_filter.set_selections(record.discounts)
        self.promotion_type_filter.set_selections(record.promotion_types)

    def _on_save_clicked(self) -> None:
        name = self.promotion_name_input.text().strip()
        if not name:
            QtWidgets.QMessageBox.warning(self, "Missing name", "Please provide a promotion name before saving.")
            return

        date_from, date_to = self.date_range.current_range()

        if date_from and date_to and date_from > date_to:
            QtWidgets.QMessageBox.warning(self, "Invalid date range", "The 'Date From' value must be earlier than 'Date To'.")
            return

        brands = self.brand_filter.selections()
        if not brands:
            QtWidgets.QMessageBox.warning(self, "Missing brand", "Please select at least one brand before saving.")
            return

        record_id = self._current_record.id if self._current_record else str(uuid.uuid4())
        created_at = (
            self._current_record.created_at if self._current_record else datetime.now(timezone.utc)
        )

        promotion_types = self.promotion_type_filter.selections()

        record = ActivityRecord(
            id=record_id,
            name=name,
            details=self.promotion_details_input.toPlainText().strip(),
            date_from=date_from,
            date_to=date_to,
            weekdays=self.weekday_selector.selected_weekdays(),
            outlets=self.outlet_filter.selections(),
            brands=brands,
            categories=self.category_filter.selections(),
            products=self.product_filter.selections(),
            discounts=self.discount_filter.selections(),
            promotion_types=promotion_types,
            created_at=created_at,
        )

        self.record_add_requested.emit(record)

    def _on_apply_clicked(self) -> None:
        record = self._current_record
        if record is None:
            QtWidgets.QMessageBox.information(self, "No record selected", "Select an activity record to apply.")
            return
        self.record_apply_requested.emit(record)

    def _on_delete_clicked(self) -> None:
        record = self._current_record
        if record is None:
            return
        confirm = QtWidgets.QMessageBox.question(
            self,
            "Delete activity record",
            f"Are you sure you want to delete '{record.name}'?",
            QtWidgets.QMessageBox.StandardButton.Yes | QtWidgets.QMessageBox.StandardButton.No,
        )
        if confirm != QtWidgets.QMessageBox.StandardButton.Yes:
            return
        self.record_delete_requested.emit(record.id)
        self.clear_form()

    def apply_external_state(self, state: FilterState) -> None:
        self.date_range.set_range(state.date_from, state.date_to)

        self.outlet_filter.set_selections(state.outlets)
        self.brand_filter.set_selections(state.brands)
        self.category_filter.set_selections(state.categories)
        self.product_filter.set_selections(state.products)
        self.discount_filter.set_selections(state.discounts)
        self.promotion_type_filter.set_selections(state.promotion_types)
        self.weekday_selector.set_selected_weekdays(state.weekdays)

        self._state = self._gather_state()
        self._emit_changes()

    def apply_state(self, state: FilterState) -> None:
        self.apply_external_state(state)


class ActivityDock(QtWidgets.QDockWidget):
    def __init__(self, title: str, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(title, parent)
        self.setAllowedAreas(
            QtCore.Qt.DockWidgetArea.LeftDockWidgetArea
            | QtCore.Qt.DockWidgetArea.RightDockWidgetArea
            | QtCore.Qt.DockWidgetArea.BottomDockWidgetArea
        )
        self.setFeatures(
            QtWidgets.QDockWidget.DockWidgetFeature.DockWidgetMovable
            | QtWidgets.QDockWidget.DockWidgetFeature.DockWidgetFloatable
        )

        container = QtWidgets.QWidget(self)
        layout = QtWidgets.QVBoxLayout(container)
        layout.setContentsMargins(6, 6, 6, 6)
        layout.setSpacing(6)

        self.notes_edit = QtWidgets.QPlainTextEdit(container)
        self.notes_edit.setPlaceholderText("Enter activity notes…")
        self.notes_edit.setMinimumWidth(240)
        layout.addWidget(self.notes_edit)

        self.setWidget(container)


class LogConsole(QtWidgets.QPlainTextEdit):
    def __init__(self, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(parent)
        self.setReadOnly(True)
        self.setMaximumBlockCount(2000)
        self.setObjectName("LogConsole")
        self.setStyleSheet(
            "QPlainTextEdit {"
            " background-color: #0f172a;"
            " color: #e2e8f0;"
            " border: 1px solid #1e293b;"
            " border-radius: 8px;"
            " font-family: Consolas, 'Courier New', monospace;"
            " font-size: 9pt;"
            " padding: 8px;"
            "}"
        )

    def append_log(self, message: str) -> None:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.appendPlainText(f"[{timestamp}] {message}")
        self.verticalScrollBar().setValue(self.verticalScrollBar().maximum())


class ReportTabs(QtWidgets.QTabWidget):
    def __init__(self, parent: Optional[QtWidgets.QWidget] = None) -> None:
        super().__init__(parent)
        self.setTabPosition(QtWidgets.QTabWidget.TabPosition.North)
        self.setDocumentMode(True)

        self.sales_transaction_report = SalesTransactionReportTab()
        self.sales_transaction_view = self.sales_transaction_report.details_view
        self.addTab(self.sales_transaction_report, "Sales Transaction Report")

        self.sales_analysis_report = SalesAnalysisReportStack()
        self.other_page = self._create_placeholder_page(
            "Other Analysis",
            "Staging area for experiments (e.g., cancellation impact, trend overlays).",
        )

        self.activity_log_tab = ActivityLogTab()

        self.addTab(self.sales_analysis_report, "Sales Analysis Report")
        self.addTab(self.activity_log_tab, "Activity Log")
        self.addTab(self.other_page, "Other Analysis")

    def update_activity_records(self, records: Sequence[ActivityRecord]) -> None:
        self.activity_log_tab.set_records(records)

    def update_activity_filter_options(self, options: Dict[str, List[str]]) -> None:
        self.activity_log_tab.update_filter_options(options)

    def on_activity_record_add(self, handler: Callable[[ActivityRecord], None]) -> None:
        self.activity_log_tab.record_add_requested.connect(handler)  # type: ignore[arg-type]

    def on_activity_record_apply(self, handler: Callable[[ActivityRecord], None]) -> None:
        self.activity_log_tab.record_apply_requested.connect(handler)  # type: ignore[arg-type]

    def on_activity_record_delete(self, handler: Callable[[str], None]) -> None:
        self.activity_log_tab.record_delete_requested.connect(handler)  # type: ignore[arg-type]

    def select_activity_record(self, record_id: str) -> None:
        self.activity_log_tab.select_record(record_id)

    @staticmethod
    def _create_placeholder_page(title: str, description: str) -> QtWidgets.QWidget:
        widget = QtWidgets.QWidget()
        layout = QtWidgets.QVBoxLayout(widget)
        layout.setAlignment(QtCore.Qt.AlignmentFlag.AlignCenter)

        title_label = QtWidgets.QLabel(title)
        title_label.setAlignment(QtCore.Qt.AlignmentFlag.AlignCenter)
        title_font = QtGui.QFont()
        title_font.setPointSize(18)
        title_font.setBold(True)
        title_label.setFont(title_font)

        description_label = QtWidgets.QLabel(description)
        description_label.setWordWrap(True)
        description_label.setAlignment(QtCore.Qt.AlignmentFlag.AlignCenter)
        description_label.setMaximumWidth(480)
        description_label.setStyleSheet("color: #4b5563;")

        layout.addWidget(title_label)
        layout.addWidget(description_label)
        layout.addStretch(1)
        return widget


class MainWindow(QtWidgets.QMainWindow):
    def __init__(self) -> None:
        super().__init__()
        self.setWindowTitle("POS Analysis Tool v1 (PyQt6 Shell)")
        self.resize(1320, 820)

        self.repository = DataRepository()
        self._cached_filter_options: Dict[str, List[str]] = {}
        self.repository.log_message.connect(self._log)
        self.repository.filters_ready.connect(self._on_filters_loaded)
        self.repository.filters_failed.connect(self._on_filters_failed)
        self.repository.repair_completed.connect(self._on_repair_completed)

        self._thread_pool = QtCore.QThreadPool.globalInstance()
        self._sync_in_progress = False
        self._startup_sync_requested = False
        self._active_fetch_generation = 0

        self._latest_details_df = pd.DataFrame()
        self._latest_payment_df: Dict[str, pd.DataFrame] = {mode: pd.DataFrame() for mode in PERIOD_OPTIONS}
        self._latest_discount_df: Dict[str, pd.DataFrame] = {mode: pd.DataFrame() for mode in PERIOD_OPTIONS}
        self._latest_product_df: Dict[str, pd.DataFrame] = {mode: pd.DataFrame() for mode in PERIOD_OPTIONS}
        self._latest_promotion_df: Dict[str, pd.DataFrame] = {
            mode: pd.DataFrame(columns=PROMOTION_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS
        }
        self._latest_store_brand_map = pd.DataFrame()
        self._latest_active_store_counts: Dict[str, int] = {}
        self._base_details_df = pd.DataFrame()
        self._base_payments_df = pd.DataFrame()
        self._base_filter_state = FilterState()

        self._current_filter_state: Optional[FilterState] = None
        self._current_promotion_state: Optional[FilterState] = None
        self._payment_options = PaymentDisplayOptions()
        self._search_text: str = ""
        self._options_refresh_pending = False
        self._pending_state_for_data: Optional[FilterState] = None

        self._activity_options_refresh_pending = False
        self._activity_request_state: Optional[FilterState] = None
        self._queued_activity_filter_state: Optional[FilterState] = None

        self._current_theme_key = "express_deep_blue"

        self._promotion_name_override: Optional[str] = None
        self._applying_activity_state = False

        self._search_debounce = QtCore.QTimer(self)
        self._search_debounce.setSingleShot(True)
        self._search_debounce.setInterval(250)
        self._search_debounce.timeout.connect(self._apply_search_text)

        self._init_ui()
        if HAS_FLUENT and Theme is not None:
            self._apply_theme_scheme(self._current_theme_key)
        self._load_filters()
        QtCore.QTimer.singleShot(0, self._trigger_startup_sync)

    # ------------------------------------------------------------------
    # UI setup
    # ------------------------------------------------------------------
    def _init_ui(self) -> None:
        self._create_actions()
        self._create_menus()
        self._create_toolbars()

        central = QtWidgets.QWidget()
        central_layout = QtWidgets.QVBoxLayout(central)
        central_layout.setContentsMargins(8, 8, 8, 8)
        central_layout.setSpacing(8)

        self.filter_panel = FilterPanel()
        self.filter_panel.filters_changed.connect(self._on_filters_changed)
        self.filter_panel.payment_options_changed.connect(self._on_payment_options_changed)
        central_layout.addWidget(self.filter_panel)

        self._payment_options = self.filter_panel.current_payment_options()

        self.search_card = QtWidgets.QFrame()
        self.search_card.setObjectName("SearchCard")
        search_layout = QtWidgets.QHBoxLayout(self.search_card)
        search_layout.setContentsMargins(12, 10, 12, 10)
        search_layout.setSpacing(10)

        search_layout.addWidget(QtWidgets.QLabel("Search"))
        self.search_box = LineEdit()
        self.search_box.setPlaceholderText("Search keywords…")
        try:
            self.search_box.setClearButtonEnabled(True)  # type: ignore[attr-defined]
        except AttributeError:
            pass
        search_layout.addWidget(self.search_box, 1)
        self.search_box.textChanged.connect(self._on_search_changed)
        central_layout.addWidget(self.search_card)

        splitter = QtWidgets.QSplitter(QtCore.Qt.Orientation.Vertical)
        self.report_tabs = ReportTabs()
        self.report_tabs.sales_transaction_report.details_view.set_status("Ready. Select filters to load data.")
        splitter.addWidget(self.report_tabs)

        self.log_console = LogConsole()
        self.log_console.setMinimumHeight(120)
        splitter.addWidget(self.log_console)
        splitter.setStretchFactor(0, 3)
        splitter.setStretchFactor(1, 1)
        central_layout.addWidget(splitter, 1)

        central.setObjectName("CentralWidget")
        self.setCentralWidget(central)

        self.activity_dock = ActivityDock("活動提醒 / Activity Notes", self)
        self.addDockWidget(QtCore.Qt.DockWidgetArea.RightDockWidgetArea, self.activity_dock)

        self.report_tabs.on_activity_record_add(self._handle_activity_record_added)
        self.report_tabs.on_activity_record_apply(self._handle_activity_record_applied)
        self.report_tabs.on_activity_record_delete(self._handle_activity_record_deleted)
        self.report_tabs.activity_log_tab.promotion_filters_changed.connect(self._on_activity_filters_changed)

        self._activity_records: List[ActivityRecord] = []
        self._refresh_activity_records()

    @staticmethod
    def _state_equal_except_weekdays(
        prior: Optional[FilterState], current: FilterState
    ) -> bool:
        if prior is None:
            return False

        def _normalize(values: Sequence[str]) -> Tuple[str, ...]:
            return tuple(values)

        return (
            prior.date_from == current.date_from
            and prior.date_to == current.date_to
            and _normalize(prior.outlets) == _normalize(current.outlets)
            and _normalize(prior.months) == _normalize(current.months)
            and _normalize(prior.weeks) == _normalize(current.weeks)
            and _normalize(prior.payments) == _normalize(current.payments)
            and _normalize(prior.categories) == _normalize(current.categories)
            and _normalize(prior.products) == _normalize(current.products)
            and _normalize(prior.brands) == _normalize(current.brands)
            and _normalize(prior.discounts) == _normalize(current.discounts)
        )

    def _apply_theme_scheme(self, scheme_key: str) -> None:
        if scheme_key not in THEME_SCHEMES:
            scheme_key = "classic_dark"

        cfg = THEME_SCHEMES[scheme_key]
        self._current_theme_key = scheme_key

        if HAS_FLUENT and Theme is not None:
            setTheme(Theme.DARK if cfg["qtheme"] == "dark" else Theme.LIGHT)
            setThemeColor(QtGui.QColor(cfg["accent"]))

        app = QtWidgets.QApplication.instance()
        if app is not None:
            palette = app.palette()
            palette.setColor(QtGui.QPalette.ColorRole.Window, QtGui.QColor(cfg["window"]))
            palette.setColor(QtGui.QPalette.ColorRole.Base, QtGui.QColor(cfg["base"]))
            palette.setColor(QtGui.QPalette.ColorRole.Button, QtGui.QColor(cfg["button"]))
            palette.setColor(QtGui.QPalette.ColorRole.ButtonText, QtGui.QColor(cfg["button_text"]))
            palette.setColor(QtGui.QPalette.ColorRole.WindowText, QtGui.QColor(cfg["text"]))
            palette.setColor(QtGui.QPalette.ColorRole.Text, QtGui.QColor(cfg["text"]))
            palette.setColor(QtGui.QPalette.ColorRole.Highlight, QtGui.QColor(cfg["accent"]))
            highlight_text = cfg.get("highlight_text", cfg.get("accent_text", cfg["text"]))
            palette.setColor(QtGui.QPalette.ColorRole.HighlightedText, QtGui.QColor(highlight_text))
            app.setPalette(palette)

    def _create_actions(self) -> None:
        self.sync_action = QtGui.QAction("Sync Remote Data", self)
        self.sync_action.triggered.connect(self._sync_remote)

        self.refresh_filters_action = QtGui.QAction("Reload Filters", self)
        self.refresh_filters_action.triggered.connect(self._load_filters)

        self.export_excel_action = QtGui.QAction("Export Current Report…", self)
        self.export_excel_action.triggered.connect(self._export_to_excel)

        self.exit_action = QtGui.QAction("Exit", self)
        self.exit_action.triggered.connect(QtWidgets.QApplication.instance().quit)

    def _create_menus(self) -> None:
        file_menu = self.menuBar().addMenu("File")
        file_menu.addAction(self.sync_action)
        file_menu.addSeparator()
        file_menu.addAction(self.export_excel_action)
        file_menu.addSeparator()
        file_menu.addAction(self.exit_action)

        view_menu = self.menuBar().addMenu("View")
        view_menu.addAction(self.refresh_filters_action)

        if HAS_FLUENT and Theme is not None:
            theme_menu = self.menuBar().addMenu("Theme")
            for key, cfg in THEME_SCHEMES.items():
                action = theme_menu.addAction(cfg["name"])

                def handler(checked: bool, theme_key=key) -> None:  # type: ignore[override]
                    del checked
                    self._apply_theme_scheme(theme_key)

                action.triggered.connect(handler)

    def _create_toolbars(self) -> None:
        toolbar = self.addToolBar("Main")
        toolbar.addAction(self.sync_action)
        toolbar.addAction(self.refresh_filters_action)
        toolbar.addAction(self.export_excel_action)

        if HAS_FLUENT:
            toolbar.setIconSize(QtCore.QSize(20, 20))
            toolbar.setToolButtonStyle(QtCore.Qt.ToolButtonStyle.ToolButtonTextBesideIcon)

    # ------------------------------------------------------------------
    # Data & logging
    # ------------------------------------------------------------------
    def _load_filters(self) -> None:
        if self._cached_filter_options:
            self.filter_panel.populate(self._cached_filter_options, emit=False)
        if self._options_refresh_pending:
            return
        self._options_refresh_pending = True
        self.filter_panel.setEnabled(False)
        self.repository.load_filter_options_async(FilterState())
        self._log("Filter options loading…")

    def _trigger_startup_sync(self) -> None:
        if self._startup_sync_requested:
            return
        self._startup_sync_requested = True
        self._log("Startup sync initiated.")
        self._sync_remote()

    def _sync_remote(self) -> None:
        if self._sync_in_progress:
            self._log("[SYNC] Request ignored; synchronization already running.")
            return

        state = self.filter_panel.current_state()
        start_date = state.date_from
        end_date = state.date_to

        single_day: Optional[date] = None
        if start_date and end_date and start_date == end_date:
            single_day = start_date

        if single_day:
            self._log(f"Triggering single-day sync for {single_day.isoformat()}.")
            start_date = single_day
            end_date = single_day
        elif start_date or end_date:
            start_label = start_date.isoformat() if start_date else "-∞"
            end_label = end_date.isoformat() if end_date else "+∞"
            self._log(f"Triggering remote sync for range {start_label} ~ {end_label}.")
        else:
            self._log("Triggering remote incremental sync (full range).")
        self.report_tabs.sales_transaction_view.set_status("Sync in progress…")
        self._sync_in_progress = True

        task = BackgroundTask(
            self.repository.sync_remote_tables,
            single_date=single_day,
            start_date=start_date if single_day is None else single_day,
            end_date=end_date if single_day is None else single_day,
        )
        task.signals.finished.connect(partial(self._handle_sync_finished, generation=None))
        task.signals.failed.connect(self._handle_sync_failed)
        self._thread_pool.start(task)

    def _on_filters_changed(self, state: FilterState) -> None:
        if self._state_equal_except_weekdays(self._current_filter_state, state):
            self._refresh_sales_transactions(state)
            return

        if self._current_filter_state is not None:
            prior = self._current_filter_state
            if (
                prior.date_from == state.date_from
                and prior.date_to == state.date_to
                and tuple(prior.brands) == tuple(state.brands)
            ):
                self._log("[FILTER] Quick refresh with cached data (date/brand unchanged).")
                self._refresh_sales_transactions(state)
                return

        cached_options = self.repository.get_cached_filter_options(state)
        if cached_options is not None:
            self._log("[FILTER] Using cached filter options for requested brands.")
            self.filter_panel.populate(cached_options, emit=False)
            self.filter_panel.apply_button.setEnabled(False)
            self._cached_filter_options = cached_options
            self._pending_state_for_data = None
            self._refresh_sales_transactions(state)
            return

        self._pending_state_for_data = state
        self.filter_panel.setEnabled(False)
        self.repository.load_filter_options_async(state)

    def _log(self, message: str) -> None:
        self.log_console.append_log(message)

    @QtCore.pyqtSlot(FilterState, dict)
    def _on_filters_loaded(self, state: FilterState, options: Dict[str, List[str]]) -> None:
        # Prevent double processing of the same filter state
        if hasattr(self, '_is_loading_filters') and self._is_loading_filters:
            return
            
        self._is_loading_filters = True
        try:
            if (
                self._activity_options_refresh_pending
                and self._activity_request_state is not None
                and state == self._activity_request_state
            ):
                self._activity_options_refresh_pending = False
                self._activity_request_state = None
                self.report_tabs.activity_log_tab.update_filter_options(options)
                self.report_tabs.activity_log_tab.set_filter_controls_enabled(True)
                queued = self._queued_activity_filter_state
                self._queued_activity_filter_state = None
                if queued is not None and queued != state:
                    self._start_activity_filter_refresh(queued)
                return

            self._options_refresh_pending = False
            prior_state = self.filter_panel.current_state()
            self.filter_panel.populate(options, emit=False)
            self.filter_panel.setEnabled(True)
            refreshed_state = self.filter_panel.current_state()
            self._log("Filters updated")
            self.filter_panel.apply_button.setEnabled(False)
            self._cached_filter_options = options
            self.report_tabs.update_activity_filter_options(options)
            target_state = self._pending_state_for_data
            if target_state is not None:
                self._pending_state_for_data = None
            elif self._current_filter_state is None:
                target_state = refreshed_state
            if target_state is not None:
                self._refresh_sales_transactions(target_state)
        finally:
            self._is_loading_filters = False

    @QtCore.pyqtSlot(object, object)
    def _on_filters_failed(self, state: FilterState, exc: Exception) -> None:
        if (
            self._activity_options_refresh_pending
            and self._activity_request_state is not None
            and state == self._activity_request_state
        ):
            self._activity_options_refresh_pending = False
            self._activity_request_state = None
            self.report_tabs.activity_log_tab.set_filter_controls_enabled(True)
            self._queued_activity_filter_state = None
            self._log(f"[FILTER] Activity filter load failed: {exc}")
            return

        del state
        self._options_refresh_pending = False
        self._pending_state_for_data = None
        self.filter_panel.setEnabled(True)
        self.report_tabs.sales_transaction_view.set_status("Filter load failed. Check logs.")
        self._log(f"[FILTER] Load failed: {exc}")

    @QtCore.pyqtSlot(str)
    def _on_repair_completed(self, db_name: str) -> None:
        self._log(f"[REPAIR] {db_name}: parquet repair completed. Reloading filters.")
        self._load_filters()

    def _on_activity_filters_changed(self, state: FilterState) -> None:
        self._current_promotion_state = state
        self._promotion_name_override = state.promotion_name
        self.report_tabs.sales_analysis_report.set_promotion_name(self._promotion_name_override)

        if self._activity_options_refresh_pending:
            self._queued_activity_filter_state = state
            return

        self._start_activity_filter_refresh(state)

    def _start_activity_filter_refresh(self, state: FilterState) -> None:
        self._activity_options_refresh_pending = True
        self._activity_request_state = state
        self._queued_activity_filter_state = None
        self.report_tabs.activity_log_tab.set_filter_controls_enabled(False)
        self.repository.load_filter_options_async(state)

    def closeEvent(self, event: QtGui.QCloseEvent) -> None:  # noqa: N802
        self.repository.close()
        super().closeEvent(event)

    # ------------------------------------------------------------------
    # Background orchestration
    # ------------------------------------------------------------------
    def _handle_sync_finished(self, _result: object, generation: Optional[int] = None) -> None:
        del generation  # unused placeholder for partial binding
        self._log("Remote sync completed.")
        self._sync_in_progress = False
        self.report_tabs.sales_transaction_view.set_status("Sync completed. Refreshing data…")
        self.repository.invalidate_caches()
        # Refresh filters asynchronously to avoid blocking the UI.
        QtCore.QTimer.singleShot(0, self._load_filters)
        if self._current_filter_state is not None:
            self._refresh_sales_transactions(self._current_filter_state)
        self._refresh_activity_records()

    def _handle_sync_failed(self, exc: Exception) -> None:
        self.report_tabs.sales_transaction_view.set_status("Sync failed.")
        self._log(f"[SYNC] Synchronization failed: {exc}")
        self._sync_in_progress = False

    def _refresh_sales_transactions(self, state: Optional[FilterState] = None) -> None:
        base_state = state or self.filter_panel.refresh_state()
        current_state = self._merge_promotion_filters(base_state)

        self.report_tabs.sales_transaction_view.set_status("Loading data…")
        self._current_filter_state = current_state

        if not self._base_cache_covers(current_state):
            self._active_fetch_generation += 1
            generation = self._active_fetch_generation
            self._log(f"Starting data refresh (generation {generation})")

            task = BackgroundTask(self.repository.fetch_sales_transactions, current_state)
            task.signals.finished.connect(
                partial(self._handle_sales_data, generation=generation)
            )
            task.signals.failed.connect(
                partial(self._handle_sales_error, generation=generation)
            )
            self._thread_pool.start(task)
            return

        self._log("[FILTER] Reusing cached base data for non-date filter update.")
        self._refresh_from_cached_base(current_state)

    def _base_cache_covers(self, state: FilterState) -> bool:
        if self._base_details_df.empty:
            return False

        base_state = self._base_filter_state
        if base_state.date_from != state.date_from or base_state.date_to != state.date_to:
            return False

        requested_brands = tuple(state.brands)
        cached_brands = tuple(base_state.brands)

        if not requested_brands:
            return not cached_brands  # require full-brand cache

        if not cached_brands:
            return True  # cached covers all brands

        cached_set = set(cached_brands)
        return set(requested_brands).issubset(cached_set)

    def _handle_sales_data(self, result: SalesReportFrames, generation: int) -> None:
        if generation != self._active_fetch_generation:
            self._log("[FETCH] Ignoring stale sales data.")
            return

        formatted_details = self._format_sales_dataframe(result.details)
        self.report_tabs.sales_transaction_report.details_view.update_data(formatted_details)
        if formatted_details.empty:
            self.report_tabs.sales_transaction_report.details_view.set_status("No data found for current filters.")
            self._log("[FETCH] Completed with no detail rows after formatting.")
        else:
            self.report_tabs.sales_transaction_view.set_status(
                f"Loaded {len(formatted_details):,} detail rows."
            )
            self._log(
                f"[FETCH] Completed data refresh: {len(formatted_details):,} detail rows, "
                f"{sum(len(df.index) for df in result.payment_analysis.values()):,} payment rows, "
                f"{sum(len(df.index) for df in result.discount_analysis.values()):,} discount rows."
            )

        self._latest_details_df = formatted_details.copy()
        self._latest_payment_df = {mode: df.copy() for mode, df in result.payment_analysis.items()}
        self._latest_discount_df = {mode: df.copy() for mode, df in result.discount_analysis.items()}
        self._latest_product_df = {mode: df.copy() for mode, df in result.product_analysis.items()}
        self._latest_promotion_df = {mode: df.copy() for mode, df in result.promotion_analysis.items()}
        self._latest_store_brand_map = result.store_brand_map.copy(deep=True)
        self._latest_active_store_counts = dict(result.active_store_counts)
        self._base_details_df = result.base_details.copy()
        self._base_payments_df = result.base_payments.copy()
        self._base_filter_state = result.base_state

        self._update_payment_analysis_display()
        self._update_discount_analysis_display()
        self._update_product_analysis_display()
        self._update_promotion_analysis_display()
        self._log("Payment analysis updated.")
        self._apply_search_text()

    def _refresh_from_cached_base(self, state: FilterState) -> None:
        if self._base_details_df.empty:
            self._log("[FILTER] No base cache available; triggering fetch instead.")
            self._refresh_sales_transactions(state)
            return

        filtered_detail, filtered_payments = DataRepository._filter_sales_frames(
            self._base_details_df, self._base_payments_df, state
        )

        if filtered_detail.empty or filtered_payments.empty:
            self._log("[FILTER] Cached base data produced no rows; updating UI with empty frames.")
            empty_payment = {mode: pd.DataFrame(columns=self._payment_columns_for_mode(mode)) for mode in PERIOD_OPTIONS}
            empty_discount = {mode: pd.DataFrame(columns=DISCOUNT_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}
            empty_product = {mode: pd.DataFrame(columns=PRODUCT_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}
            self._latest_details_df = filtered_detail.copy()
            self._latest_payment_df = empty_payment
            self._latest_discount_df = empty_discount
            self._latest_product_df = empty_product
            self._latest_promotion_df = {mode: pd.DataFrame(columns=PROMOTION_ANALYSIS_COLUMNS[mode]) for mode in PERIOD_OPTIONS}
            self._update_payment_analysis_display()
            self._update_discount_analysis_display()
            self._update_product_analysis_display()
            self._update_promotion_analysis_display()
            self.report_tabs.sales_transaction_report.details_view.update_data(filtered_detail)
            self.report_tabs.sales_transaction_report.details_view.set_status("No data found for current filters.")
            self.report_tabs.sales_transaction_view.set_status("Loaded 0 detail rows.")
            self._apply_search_text()
            return

        result = self.repository._assemble_sales_report(
            filtered_detail,
            filtered_payments,
            base_details=self._base_details_df.copy(),
            base_payments=self._base_payments_df.copy(),
            base_state=self._base_filter_state,
            state=state,
        )

        formatted_details = self._format_sales_dataframe(result.details)
        self.report_tabs.sales_transaction_report.details_view.update_data(formatted_details)
        if formatted_details.empty:
            self.report_tabs.sales_transaction_report.details_view.set_status("No data found for current filters.")
        else:
            self.report_tabs.sales_transaction_view.set_status(
                f"Loaded {len(formatted_details):,} detail rows."
            )

        self._latest_details_df = formatted_details.copy()
        self._latest_payment_df = {mode: df.copy() for mode, df in result.payment_analysis.items()}
        self._latest_discount_df = {mode: df.copy() for mode, df in result.discount_analysis.items()}
        self._latest_product_df = {mode: df.copy() for mode, df in result.product_analysis.items()}
        self._latest_promotion_df = {mode: df.copy() for mode, df in result.promotion_analysis.items()}
        self._latest_store_brand_map = result.store_brand_map.copy(deep=True)
        self._latest_active_store_counts = dict(result.active_store_counts)

        self._update_payment_analysis_display()
        self._update_discount_analysis_display()
        self._update_product_analysis_display()
        self._update_promotion_analysis_display()
        self._apply_search_text()

    def _merge_promotion_filters(self, base_state: FilterState) -> FilterState:
        promo_state = self._current_promotion_state
        if promo_state is None:
            return base_state

        return FilterState(
            date_from=promo_state.date_from or base_state.date_from,
            date_to=promo_state.date_to or base_state.date_to,
            outlets=promo_state.outlets or base_state.outlets,
            months=base_state.months,
            weeks=base_state.weeks,
            payments=base_state.payments,
            categories=promo_state.categories or base_state.categories,
            products=promo_state.products or base_state.products,
            brands=base_state.brands,
            discounts=promo_state.discounts or base_state.discounts,
            weekdays=promo_state.weekdays or base_state.weekdays,
            promotion_name=promo_state.promotion_name,
            promotion_details=promo_state.promotion_details,
            promotion_types=promo_state.promotion_types,
        )

    def _handle_activity_record_added(self, record: ActivityRecord) -> None:
        saved = self.repository.add_activity_record(record)
        self._log(f"[ACTIVITY] Saved record '{saved.name}'.")
        self._refresh_activity_records(select_record_id=saved.id)

    def _handle_activity_record_deleted(self, record_id: str) -> None:
        if self.repository.delete_activity_record(record_id):
            self._log(f"[ACTIVITY] Deleted record {record_id}.")
            self._refresh_activity_records()
        else:
            self._log(f"[ACTIVITY] Record {record_id} not found.")

    def _handle_activity_record_applied(self, record: ActivityRecord) -> None:
        state = FilterState(
            date_from=record.date_from,
            date_to=record.date_to,
            outlets=record.outlets,
            months=[],
            weeks=[],
            payments=[],
            categories=record.categories,
            products=record.products,
            brands=record.brands,
            discounts=record.discounts,
            weekdays=record.weekdays,
        )
        self.filter_panel.apply_state(state)
        self._log(f"[ACTIVITY] Applied record '{record.name}'.")

    def _refresh_activity_records(self, select_record_id: Optional[str] = None) -> None:
        try:
            records = self.repository.list_activity_records()
        except Exception as exc:
            self._log(f"[ACTIVITY] Failed to load records: {exc}")
            return
        self._activity_records = records
        self.report_tabs.update_activity_records(records)
        if select_record_id:
            self.report_tabs.select_activity_record(select_record_id)

    def _export_to_excel(self) -> None:
        try:
            if (
                self._latest_details_df.empty
                and self._display_payment_df.empty
                and self._display_discount_df.empty
                and self._display_product_df.empty
            ):
                QtWidgets.QMessageBox.information(
                    self,
                    "Export to Excel",
                    "No report data available. Please load a report first.",
                )
                return

            suggested = QtCore.QDateTime.currentDateTime().toString("yyyyMMdd_HHmm")
            default_name = f"POS_Report_{suggested}.xlsx"
            path, _ = QtWidgets.QFileDialog.getSaveFileName(
                self,
                "Save Report as Excel",
                str(Path.home() / default_name),
                "Excel Files (*.xlsx)",
            )
            if not path:
                return
            if not path.lower().endswith(".xlsx"):
                path += ".xlsx"

            details_df = self._latest_details_df.copy()
            payment_df = self._display_payment_df.copy()
            discount_df = self._display_discount_df.copy()
            product_df = self._display_product_df.copy()

            try:
                import xlsxwriter  # type: ignore  # noqa: F401
                excel_engine = "xlsxwriter"
                use_openpyxl = False
            except ImportError:
                excel_engine = "openpyxl"
                try:
                    import openpyxl  # type: ignore  # noqa: F401
                except ImportError as exc:
                    QtWidgets.QMessageBox.critical(
                        self,
                        "Export failed",
                        "Could not export report to Excel.\n\nPlease install either 'xlsxwriter' or 'openpyxl'.",
                    )
                    self._log(f"[EXPORT] Missing Excel engine ({exc})")
                    return
                use_openpyxl = True

            try:
                # Process payment data
                percent_payment = [col for col in ("Sales Ratio %", "TC Ratio %") if col in payment_df.columns]
                payment_excel = payment_df.copy()
                for col in percent_payment:
                    payment_excel[col] = (
                        payment_excel[col]
                        .astype(str)
                        .str.replace("%", "", regex=False)
                        .replace("", pd.NA)
                    )
                    payment_excel[col] = pd.to_numeric(payment_excel[col], errors="coerce") / 100.0

                # Process discount data
                percent_discount = [
                    col
                    for col in ("Discount Ratio %", "Transaction Ratio %", "Quantity Ratio %")
                    if col in discount_df.columns
                ]
                discount_excel = discount_df.copy()
                for col in percent_discount:
                    discount_excel[col] = (
                        discount_excel[col]
                        .astype(str)
                        .str.replace("%", "", regex=False)
                        .replace("", pd.NA)
                    )
                    discount_excel[col] = pd.to_numeric(discount_excel[col], errors="coerce") / 100.0

                # Process product data
                percent_product = [
                    col
                    for col in (
                        "Sales Ratio %",
                        "Quantity Ratio %",
                        "Wastage Ratio %",
                        "Bill Sales Ratio %",
                    )
                    if col in product_df.columns
                ]
                product_excel = product_df.copy()
                for col in percent_product:
                    product_excel[col] = (
                        product_excel[col]
                        .astype(str)
                        .str.replace("%", "", regex=False)
                        .replace("", pd.NA)
                    )
                    product_excel[col] = pd.to_numeric(product_excel[col], errors="coerce") / 100.0

                # Define currency and quantity columns for formatting
                currency_details = {"Sales", "Discount Sales", "Nett Sales"}
                quantity_details = {"QTY"}
                currency_payment = {"Payment Sales", "Bill Sales"}
                currency_discount = {"Discount Sales", "Bill Sales"}
                quantity_discount = {"Quantity"}
                currency_product = {"Sales", "Bill Sales"}
                quantity_product = {"Quantity", "Wastage"}

                # Write to Excel
                with pd.ExcelWriter(path, engine=excel_engine) as writer:
                    try:
                        if not details_df.empty:
                            details_df.to_excel(writer, sheet_name="Details Raw Data", index=False)
                        if not payment_df.empty:
                            payment_excel.to_excel(writer, sheet_name="Payment Analysis", index=False)
                        if discount_df.columns.tolist():
                            discount_excel.to_excel(writer, sheet_name="Discount Analysis", index=False)
                        if product_df.columns.tolist():
                            product_excel.to_excel(writer, sheet_name="Product Analysis", index=False)
                        
                        # Apply formatting based on the Excel engine
                        if use_openpyxl:
                            self._style_openpyxl(
                                writer,
                                details_df,
                                payment_df,
                                payment_excel,
                                discount_df,
                                discount_excel,
                                product_df,
                                product_excel,
                                currency_details,
                                quantity_details,
                                currency_payment,
                                currency_discount,
                                quantity_discount,
                                currency_product,
                                quantity_product,
                                percent_payment,
                                percent_discount,
                                percent_product,
                            )
                        else:
                            self._style_xlsxwriter(
                                writer,
                                details_df,
                                payment_df,
                                discount_df,
                                product_df,
                                currency_details,
                                quantity_details,
                                currency_payment,
                                currency_discount,
                                quantity_discount,
                                currency_product,
                                quantity_product,
                                percent_payment,
                                percent_discount,
                                percent_product,
                            )
                        
                        QtWidgets.QMessageBox.information(
                            self,
                            "Export Successful",
                            f"Report successfully exported to:\n{path}",
                        )
                        
                    except Exception as e:
                        QtWidgets.QMessageBox.critical(
                            self,
                            "Export Failed",
                            f"Failed to write Excel file. Error: {str(e)}",
                        )
                        self._log(f"[EXPORT] Error writing Excel file: {str(e)}")
                        
            except Exception as e:
                QtWidgets.QMessageBox.critical(
                    self,
                    "Export Failed",
                    f"Failed to process data for export. Error: {str(e)}",
                )
                self._log(f"[EXPORT] Error processing data: {str(e)}")
                
        except Exception as e:
            QtWidgets.QMessageBox.critical(
                self,
                "Export Failed",
                f"An unexpected error occurred. Error: {str(e)}",
            )
            self._log(f"[EXPORT] Unexpected error: {str(e)}")

    def _load_epoint_raw_frames(
        self,
        db_name: str,
        date_from: Optional[date],
        date_to: Optional[date],
    ) -> Optional[BrandCacheEntry]:
        """Load raw sales and payment data from Epoint DuckDB files.
        
        Args:
            db_name: Name of the database (should be 'sushi_epoint_pos_live')
            date_from: Start date for filtering data (inclusive)
            date_to: End date for filtering data (inclusive)
            
        Returns:
            BrandCacheEntry containing the loaded data, or None if no data was found
        """
        cache_paths = self.cache_paths[db_name]
        cache_key = (db_name, date_from, date_to)

        # Check if we have this data cached in memory
        with self._brand_cache_lock:
            if cache_key in self._brand_raw_cache:
                entry = self._brand_raw_cache[cache_key]
                if entry.date_from == date_from and entry.date_to == date_to:
                    return entry

        try:
            # Connect to the main Epoint database
            db_path = cache_paths.duckdb_path
            if not os.path.exists(db_path):
                self.log_message.emit(f"Epoint database not found at {db_path}")
                return None

            conn = duckdb.connect(str(db_path), read_only=True)
            
            # Build date filter
            date_conditions = []
            params: Dict[str, object] = {}
            if date_from:
                date_conditions.append("c_date >= %(date_from)s")
                params["date_from"] = date_from.isoformat()
                
            if date_to:
                date_conditions.append("c_date <= %(date_to)s")
                params["date_to"] = date_to.isoformat()
                
            date_filter = " AND ".join(date_conditions) if date_conditions else "1=1"

            # Load details data - using item_name as item_no for compatibility
            details_query = f"""
                SELECT 
                    c_date,
                    store_name,
                    sales_no,
                    item_name AS item_no,  -- Map item_name to item_no for compatibility
                    item_name,
                    '' AS category_code,   -- Epoint may not have categories
                    qty,
                    sub_total,
                    disc_name,
                    disc_amt,
                    pro_disc_amt,
                    svc_amt,
                    tax_amt,
                    '' AS take_away_item,  -- Epoint may not have this field
                    item_sub_total,
                    payment_methods,
                    '{db_name}' AS source_database
                FROM raw_details
                WHERE {date_filter}
            """
            details = conn.execute(details_query, params).fetchdf()
            
            # Load payments data
            payments_query = f"""
                SELECT DISTINCT
                    c_date,
                    store_name,
                    sales_no,
                    '{db_name}' AS source_database,
                    payment_name,
                    tender_amt AS tender_amount
                FROM raw_payments
                WHERE {date_filter}
            """
            payments = conn.execute(payments_query, params).fetchdf()
            
            conn.close()
            
            if details.empty or payments.empty:
                self.log_message.emit("No data found for the selected date range")
                return None
                
            # Create cache entry
            entry = BrandCacheEntry(
                detail=details,
                payments=payments,
                date_from=date_from,
                date_to=date_to,
            )

            # Update cache
            with self._brand_cache_lock:
                self._brand_raw_cache[cache_key] = entry
                
            return entry
            
        except Exception as e:
            self.log_message.emit(f"Error loading Epoint data: {str(e)}")
            import traceback
            self.log_message.emit(traceback.format_exc())
            return None

    def _load_sql_raw_frames(
        self,
        db_name: str,
        date_from: Optional[date],
        date_to: Optional[date],
    ) -> Optional[BrandCacheEntry]:
        """Load raw sales and payment data from SQL database.
        """
        cache_paths = self.cache_paths[db_name]
        cache_key = (db_name, date_from, date_to)

        # Check if we have this data cached in memory
        if cache_key in self._brand_raw_cache:
            entry = self._brand_raw_cache[cache_key]
            if entry.date_from == date_from and entry.date_to == date_to:
                return entry

        try:
            with self.duckdb_connection(db_name) as conn:
                # Register the parquet files as views
                storage_duckdb.register_parquet_views(conn, db_name)

                # Build date filter
                date_conditions = []
                params: Dict[str, object] = {}
                if date_from:
                    date_conditions.append("c_date >= %(date_from)s")
                    params["date_from"] = date_from.isoformat()
                if date_to:
                    date_conditions.append("c_date <= %(date_to)s")
                    params["date_to"] = date_to.isoformat()

                date_filter = " AND ".join(date_conditions) if date_conditions else "1=1"

                # Load details
                details_query = f"""
                    SELECT * FROM vw_clean_details
                    WHERE {date_filter}
                """
                details = conn.execute(details_query, params).fetchdf()

                # Load payments
                payments_query = f"""
                    SELECT * FROM vw_clean_payments
                    WHERE sales_no IN (SELECT DISTINCT sales_no FROM vw_clean_details WHERE {date_filter})
                """
                payments = conn.execute(payments_query, params).fetchdf()

                if details.empty or payments.empty:
                    return None

                # Create cache entry
                entry = BrandCacheEntry(
                    detail=details,
                    payments=payments,
                    date_from=date_from,
                    date_to=date_to,
                )

                # Update cache
                self._brand_raw_cache[cache_key] = entry
                return entry

        except Exception as e:
            self.log_message.emit(f"Error loading {db_name} data: {e}")
            return None
            
    def _load_brand_raw_frames(
        self,
        db_name: str,
        date_from: Optional[date],
        date_to: Optional[date],
    ) -> Optional[BrandCacheEntry]:
        """Load raw sales and payment data for a specific brand.

        This method routes to the appropriate loader based on the database type.
        """
        if db_name == "sushi_epoint_pos_live":
            return self._load_epoint_raw_frames(db_name, date_from, date_to)
        else:
            return self._load_sql_raw_frames(db_name, date_from, date_to)

    def _style_xlsxwriter(
        self,
        writer: pd.ExcelWriter,
        details_df: pd.DataFrame,
        payment_df: pd.DataFrame,
        discount_df: pd.DataFrame,
        product_df: pd.DataFrame,
        currency_details: set[str],
        quantity_details: set[str],
        currency_payment: set[str],
        currency_discount: set[str],
        quantity_discount: set[str],
        currency_product: set[str],
        quantity_product: set[str],
        percent_payment: list[str],
        percent_discount: list[str],
        percent_product: list[str],
    ) -> None:
        workbook = writer.book
        currency_format = workbook.add_format({"num_format": "$ #,##0.0"})
        quantity_format = workbook.add_format({"num_format": "0.0"})
        percent_format = workbook.add_format({"num_format": "0.00%"})
        header_format = workbook.add_format(
            {
                "bold": True,
                "bg_color": "#1f2937",
                "font_color": "#ffffff",
                "border": 0,
            }
        )

        if not details_df.empty:
            sheet = writer.sheets["Details Raw Data"]
            sheet.freeze_panes(1, 0)
            sheet.autofilter(0, 0, len(details_df.index), len(details_df.columns) - 1)
            for col_idx, column in enumerate(details_df.columns):
                values = details_df[column]
                width = max(len(str(column)), *(len(str(v)) for v in values.head(500))) + 2
                cell_format = None
                if column in currency_details:
                    cell_format = currency_format
                elif column in quantity_details:
                    cell_format = quantity_format
                sheet.set_column(col_idx, col_idx, min(width, 40), cell_format)
                sheet.write(0, col_idx, column, header_format)

        if not payment_df.empty:
            sheet = writer.sheets["Payment Analysis"]
            sheet.freeze_panes(1, 0)
            sheet.autofilter(0, 0, len(payment_df.index), len(payment_df.columns) - 1)
            for col_idx, column in enumerate(payment_df.columns):
                values = payment_df[column]
                width = max(len(str(column)), *(len(str(v)) for v in values.head(500))) + 2
                cell_format = None
                if column in currency_payment:
                    cell_format = currency_format
                elif column in percent_payment:
                    cell_format = percent_format
                sheet.set_column(col_idx, col_idx, min(width, 40), cell_format)
                sheet.write(0, col_idx, column, header_format)

        if "Discount Analysis" in writer.sheets:
            sheet = writer.sheets["Discount Analysis"]
            row_count = len(discount_df.index)
            sheet.freeze_panes(1, 0)
            sheet.autofilter(0, 0, row_count, max(len(discount_df.columns) - 1, 0))
            for col_idx, column in enumerate(discount_df.columns):
                values = discount_df[column] if column in discount_df.columns else pd.Series(dtype=object)
                width = max(len(str(column)), *(len(str(v)) for v in values.head(500))) + 2
                cell_format = None
                if column in currency_discount:
                    cell_format = currency_format
                elif column in quantity_discount:
                    cell_format = quantity_format
                elif column in percent_discount:
                    cell_format = percent_format
                sheet.set_column(col_idx, col_idx, min(width, 40), cell_format)
                sheet.write(0, col_idx, column, header_format)

        if "Product Analysis" in writer.sheets:
            sheet = writer.sheets["Product Analysis"]
            row_count = len(product_df.index)
            sheet.freeze_panes(1, 0)
            sheet.autofilter(0, 0, row_count, max(len(product_df.columns) - 1, 0))
            for col_idx, column in enumerate(product_df.columns):
                values = product_df[column] if column in product_df.columns else pd.Series(dtype=object)
                width = max(len(str(column)), *(len(str(v)) for v in values.head(500))) + 2
                cell_format = None
                if column in currency_product:
                    cell_format = currency_format
                elif column in quantity_product:
                    cell_format = quantity_format
                elif column in percent_product:
                    cell_format = percent_format
                sheet.set_column(col_idx, col_idx, min(width, 40), cell_format)
                sheet.write(0, col_idx, column, header_format)

    def _style_openpyxl(
        self,
        writer: pd.ExcelWriter,
        details_df: pd.DataFrame,
        payment_df: pd.DataFrame,
        payment_excel: pd.DataFrame,
        discount_df: pd.DataFrame,
        discount_excel: pd.DataFrame,
        product_df: pd.DataFrame,
        product_excel: pd.DataFrame,
        currency_details: set[str],
        quantity_details: set[str],
        currency_payment: set[str],
        currency_discount: set[str],
        quantity_discount: set[str],
        currency_product: set[str],
        quantity_product: set[str],
        percent_payment: list[str],
        percent_discount: list[str],
        percent_product: list[str],
    ) -> None:
        from openpyxl.styles import Font, PatternFill
        from openpyxl.utils import get_column_letter

        workbook = writer.book
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(fill_type="solid", fgColor="1F2937")

        if not details_df.empty:
            sheet = workbook["Details Raw Data"]
            sheet.freeze_panes = "A2"
            last_column_letter = get_column_letter(len(details_df.columns))
            last_row = len(details_df.index) + 1
            sheet.auto_filter.ref = f"A1:{last_column_letter}{last_row}"
            for idx, column in enumerate(details_df.columns, start=1):
                letter = get_column_letter(idx)
                values = details_df[column]
                width = max(len(str(column)), *(len(str(v)) for v in values.head(500))) + 2
                sheet.column_dimensions[letter].width = min(width, 40)
                header_cell = sheet[f"{letter}1"]
                header_cell.font = header_font
                header_cell.fill = header_fill
                if column in currency_details:
                    number_format = "$ #,##0.0"
                elif column in quantity_details:
                    number_format = "0.0"
                else:
                    number_format = None
                if number_format:
                    for row_idx in range(2, last_row + 1):
                        sheet[f"{letter}{row_idx}"].number_format = number_format

        if not payment_df.empty:
            sheet = workbook["Payment Analysis"]
            sheet.freeze_panes = "A2"
            last_column_letter = get_column_letter(len(payment_df.columns))
            last_row = len(payment_excel.index) + 1
            sheet.auto_filter.ref = f"A1:{last_column_letter}{last_row}"
            for idx, column in enumerate(payment_df.columns, start=1):
                letter = get_column_letter(idx)
                values = payment_df[column]
                width = max(len(str(column)), *(len(str(v)) for v in values.head(500))) + 2
                sheet.column_dimensions[letter].width = min(width, 40)
                header_cell = sheet[f"{letter}1"]
                header_cell.font = header_font
                header_cell.fill = header_fill
                if column in currency_payment:
                    number_format = "$ #,##0.0"
                elif column in percent_payment:
                    number_format = "0.00%"
                else:
                    number_format = None
                if number_format:
                    for row_idx in range(2, last_row + 1):
                        sheet[f"{letter}{row_idx}"].number_format = number_format

        if "Discount Analysis" in workbook.sheetnames:
            sheet = workbook["Discount Analysis"]
            sheet.freeze_panes = "A2"
            last_column_letter = get_column_letter(len(discount_df.columns)) if discount_df.columns.size else "A"
            last_row = len(discount_excel.index) + 1
            sheet.auto_filter.ref = f"A1:{last_column_letter}{last_row}"
            for idx, column in enumerate(discount_df.columns, start=1):
                letter = get_column_letter(idx)
                values = discount_df[column]
                width = max(len(str(column)), *(len(str(v)) for v in values.head(500))) + 2
                sheet.column_dimensions[letter].width = min(width, 40)
                header_cell = sheet[f"{letter}1"]
                header_cell.font = header_font
                header_cell.fill = header_fill
                if column in currency_discount:
                    number_format = "$ #,##0.0"
                elif column in quantity_discount:
                    number_format = "0.0"
                elif column in percent_discount:
                    number_format = "0.00%"
                else:
                    number_format = None
                if number_format:
                    for row_idx in range(2, last_row + 1):
                        sheet[f"{letter}{row_idx}"].number_format = number_format

        if "Product Analysis" in workbook.sheetnames:
            sheet = workbook["Product Analysis"]
            sheet.freeze_panes = "A2"
            last_column_letter = get_column_letter(len(product_df.columns)) if product_df.columns.size else "A"
            last_row = len(product_excel.index) + 1
            sheet.auto_filter.ref = f"A1:{last_column_letter}{last_row}"
            for idx, column in enumerate(product_df.columns, start=1):
                letter = get_column_letter(idx)
                values = product_df[column]
                width = max(len(str(column)), *(len(str(v)) for v in values.head(500))) + 2
                sheet.column_dimensions[letter].width = min(width, 40)
                header_cell = sheet[f"{letter}1"]
                header_cell.font = header_font
                header_cell.fill = header_fill
                if column in currency_product:
                    number_format = "$ #,##0.0"
                elif column in quantity_product:
                    number_format = "0.0"
                elif column in percent_product:
                    number_format = "0.00%"
                else:
                    number_format = None
                if number_format:
                    for row_idx in range(2, last_row + 1):
                        sheet[f"{letter}{row_idx}"].number_format = number_format

    def _handle_sales_error(self, exc: Exception, generation: int) -> None:
        if generation != self._active_fetch_generation:
            return
        self.report_tabs.sales_transaction_view.set_status("Failed to load data.")
        self._log(f"[REPORT] Failed to load data ({exc}).")

        formatted_tb = "\n".join(traceback.format_exception(type(exc), exc, exc.__traceback__))
        self._log("[REPORT] Traceback:\n" + formatted_tb)

        if hasattr(self, "_latest_promotion_df"):
            details: list[str] = []
            for mode, df in self._latest_promotion_df.items():
                columns = list(df.columns)
                details.append(f"  - {mode}: shape={df.shape}, columns={columns}")
            self._log("[PROMOTION] Cached frames:\n" + "\n".join(details))

    def _on_search_changed(self, text: str) -> None:
        self._search_text = text
        self._search_debounce.start()

    def _apply_search_text(self) -> None:
        if self._search_debounce.isActive():
            self._search_debounce.stop()
        self.report_tabs.sales_transaction_report.set_search_text(self._search_text)
        self.report_tabs.sales_analysis_report.set_search_text(self._search_text)

    def _on_payment_options_changed(
        self,
        show_total: bool,
        daily_avg: bool,
        outlet_avg: bool,
        period_mode: str,
    ) -> None:
        self._payment_options = PaymentDisplayOptions(
            show_total=show_total,
            daily_average=daily_avg,
            outlet_average=outlet_avg,
            period_mode=period_mode,
        )
        self._update_payment_analysis_display()
        self._update_discount_analysis_display()
        self._update_product_analysis_display()

    def _selected_day_count(self) -> int:
        if self._current_filter_state and self._current_filter_state.date_from and self._current_filter_state.date_to:
            return (self._current_filter_state.date_to - self._current_filter_state.date_from).days + 1
        if not self._latest_details_df.empty:
            unique_dates = pd.to_datetime(self._latest_details_df["Date"], errors="coerce").dt.normalize().nunique()
            return int(unique_dates) if unique_dates else 1
        return 1

    def _selected_outlet_count(self, outlet_label: Optional[str] = None) -> int:
        if not self._latest_active_store_counts:
            return 1

        if outlet_label is None:
            candidates = ["__overall__"]
        else:
            normalized = str(outlet_label).strip()
            if not normalized:
                candidates = ["__overall__"]
            else:
                lower = normalized.lower()
                if lower == "all":
                    candidates = ["__overall__"]
                elif lower.endswith(" all"):
                    base = normalized[:-4].strip()
                    candidates = [base, base.upper(), base.title(), "__overall__"]
                else:
                    candidates = [normalized, normalized.upper(), normalized.title(), "__overall__"]

        for key in candidates:
            if key in self._latest_active_store_counts:
                return max(1, int(self._latest_active_store_counts[key]))

        return max(1, int(self._latest_active_store_counts.get("__overall__", 1)))

    def _update_payment_analysis_display(self) -> None:
        current_mode = self._payment_options.period_mode
        base = self._latest_payment_df.get(current_mode, pd.DataFrame())
        if base.empty:
            self._display_payment_df = base.copy()
            self.report_tabs.sales_transaction_report.update_payment_analysis(base)
            return

        display = base.copy()
        if self._payment_options.show_total:
            mask = pd.Series(False, index=display.index)
            if "Payment Type" in display.columns:
                mask |= display["Payment Type"].eq("TOTAL")
            if "Outlet" in display.columns:
                mask |= display["Outlet"].fillna("").str.contains(r"(?:^All$| All$)", regex=True)
            display = display[mask].copy()

        if self._payment_options.daily_average:
            day_count = max(self._selected_day_count(), 1)
            if day_count > 1:
                numeric_columns = [col for col in ("Payment Sales", "Bill Sales", "Receipt") if col in display.columns]
                for col in numeric_columns:
                    values = pd.to_numeric(display[col], errors="coerce").fillna(0.0)
                    precision = 2 if col == "Receipt" else 1
                    display[col] = (values / day_count).round(precision)

        if self._payment_options.outlet_average and not display.empty and "Outlet" in display.columns:
            total_mask = display["Outlet"].fillna("").str.contains(r"(?:^All$| All$)", regex=True)
            if total_mask.any():
                counts = (
                    display.loc[total_mask, "Outlet"].map(lambda label: max(self._selected_outlet_count(label), 1)).astype(float)
                )
                for col in ("Payment Sales", "Bill Sales", "Receipt"):
                    if col in display.columns:
                        values = pd.to_numeric(display.loc[total_mask, col], errors="coerce").fillna(0.0)
                        precision = 2 if col == "Receipt" else 1
                        display.loc[total_mask, col] = (values / counts).round(precision)

        display.reset_index(drop=True, inplace=True)
        self._display_payment_df = display
        self.report_tabs.sales_transaction_report.update_payment_analysis(display)

    def _update_discount_analysis_display(self) -> None:
        current_mode = self._payment_options.period_mode
        frame = self._latest_discount_df.get(current_mode, pd.DataFrame()).copy()

        if self._payment_options.show_total and "Outlet" in frame.columns:
            outlet_series = frame["Outlet"].fillna("")
            filtered = frame[outlet_series.str.contains(r"(?:^All$| All$)", regex=True)].copy()
            if not filtered.empty:
                frame = filtered

        if (
            self._payment_options.daily_average
            and not frame.empty
            and current_mode in {"Weekly", "Monthly", "Period"}
        ):
            day_count = max(self._selected_day_count(), 1)
            if day_count > 1:
                for column in ("Discount Sales", "Quantity", "Transaction"):
                    if column in frame.columns:
                        numeric = pd.to_numeric(frame[column], errors="coerce").fillna(0.0)
                        frame[column] = numeric.div(day_count).round(1)

        if self._payment_options.outlet_average and not frame.empty and "Outlet" in frame.columns:
            total_mask = frame["Outlet"].fillna("").str.contains(r"(?:^All$| All$)", regex=True)
            if total_mask.any():
                counts = (
                    frame.loc[total_mask, "Outlet"].map(lambda label: max(self._selected_outlet_count(label), 1)).astype(float)
                )
                for column, precision in (("Discount Sales", 1), ("Quantity", 1), ("Transaction", 1)):
                    if column in frame.columns:
                        values = pd.to_numeric(frame.loc[total_mask, column], errors="coerce").fillna(0.0)
                        frame.loc[total_mask, column] = (values / counts).round(precision)

        frame = frame.reset_index(drop=True)
        self._display_discount_df = frame
        self.report_tabs.sales_transaction_report.update_discount_analysis(frame)

    def _update_product_analysis_display(self) -> None:
        current_mode = self._payment_options.period_mode
        frame = self._latest_product_df.get(current_mode, pd.DataFrame()).copy()

        if self._payment_options.show_total and "Outlet" in frame.columns:
            outlet_series = frame["Outlet"].fillna("")
            total_rows = frame[outlet_series.str.contains(r"(?:^All$| All$)", regex=True)]
            if not total_rows.empty:
                frame = total_rows.copy()

        if self._payment_options.daily_average and not frame.empty:
            day_count = max(self._selected_day_count(), 1)
            if day_count > 1:
                for column in ("Sales", "Transaction", "Quantity", "Wastage", "Bill Sales"):
                    if column in frame.columns:
                        numeric = pd.to_numeric(frame[column], errors="coerce").fillna(0.0)
                        frame[column] = numeric.div(day_count).round(1)

        if self._payment_options.outlet_average and not frame.empty and "Outlet" in frame.columns:
            brand_total_mask = frame["Outlet"].fillna("").str.contains(r"(?:^All$| All$)", regex=True)
            if brand_total_mask.any():
                counts = (
                    frame.loc[brand_total_mask, "Outlet"].map(lambda label: max(self._selected_outlet_count(label), 1)).astype(float)
                )
                divide_targets = {
                    "Sales": ("Sales", 1),
                    "Transaction": ("Transaction", 1),
                    "Quantity": ("Quantity", 1),
                    "Wastage": ("Wastage", 1),
                    "Bill Sales": ("Bill Sales", 1),
                }
                for column, (target_col, precision) in divide_targets.items():
                    if target_col in frame.columns:
                        values = pd.to_numeric(frame.loc[brand_total_mask, target_col], errors="coerce").fillna(0.0)
                        frame.loc[brand_total_mask, target_col] = (values / counts).round(precision)

        frame = frame.reset_index(drop=True)
        self._display_product_df = frame
        self.report_tabs.sales_analysis_report.update_product_analysis(frame)

    def _update_promotion_analysis_display(self) -> None:
        current_mode = self._payment_options.period_mode
        required = PROMOTION_ANALYSIS_COLUMNS.get(current_mode, [])

        frame = self._latest_promotion_df.get(current_mode)
        if frame is None or frame.empty:
            fallback = self._latest_promotion_df.get("Period")
            frame = fallback if fallback is not None and not fallback.empty else pd.DataFrame(columns=required)

        frame = frame.copy()
        missing = [column for column in required if column not in frame.columns]
        if missing:
            self._log(
                f"[PROMOTION] Missing columns {missing} for mode '{current_mode}'. Falling back to Period output."
            )
            frame = self._latest_promotion_df.get("Period", pd.DataFrame(columns=required)).copy()
            for column in required:
                if column not in frame.columns:
                    frame[column] = "" if frame.empty else ""

        for column in required:
            if column not in frame.columns:
                frame[column] = "" if column not in {"Sales", "Transaction", "Quantity"} else 0

        frame = frame.reindex(columns=required)
        self.report_tabs.sales_analysis_report.update_promotion_analysis(frame)

    def _apply_component_styles(self, cfg: Dict[str, str]) -> None:
        button_stylesheet = FLUENT_BUTTON_STYLES_TEMPLATE.format(
            base=cfg["button"],
            hover=cfg["hover"],
            pressed=cfg["pressed"],
            border=cfg["border"],
            text=cfg["button_text"],
            accent=cfg["accent"],
            accent_text=cfg["accent_text"],
        )

        extra_styles = f"""
QGroupBox {{
    background-color: {cfg["panel_bg"]};
    border: 1px solid {cfg["border"]};
    border-radius: 14px;
    margin-top: 14px;
    padding: 16px;
}}
QGroupBox::title {{
    color: {cfg["text"]};
    padding: 0 0 8px 0;
    font-weight: 600;
}}
QLineEdit, QComboBox, QDateEdit {{
    background-color: {cfg["input_bg"]};
    border: 1px solid {cfg["border"]};
    border-radius: 10px;
    padding: 6px 10px;
    color: {cfg["text"]};
}}
QLineEdit:hover, QComboBox:hover, QDateEdit:hover {{
    background-color: {cfg["input_hover"]};
}}
QLineEdit:focus, QComboBox:focus, QDateEdit:focus {{
    border: 1px solid {cfg["accent"]};
    background-color: {cfg["base"]};
}}
QLineEdit::placeholder {{
    color: {cfg["placeholder"]};
}}
QTextEdit, QPlainTextEdit {{
    background-color: {cfg["card_bg"]};
    border: 1px solid {cfg["border"]};
    border-radius: 12px;
    color: {cfg["text"]};
}}
QTabWidget::pane {{
    background-color: {cfg["panel_bg"]};
    border: 1px solid {cfg["border"]};
    border-radius: 12px;
}}
QTabBar::tab {{
    background-color: transparent;
    color: {cfg["text"]};
    padding: 8px 18px;
    border: 1px solid transparent;
    border-top-left-radius: 10px;
    border-top-right-radius: 10px;
}}
QTabBar::tab:selected {{
    background-color: {cfg["button"]};
    color: {cfg["button_text"]};
    border-color: {cfg["border"]};
}}
QTableView {{
    background-color: {cfg["card_bg"]};
    alternate-background-color: {cfg["panel_bg"]};
    color: {cfg["text"]};
    gridline-color: {cfg["border"]};
}}
QHeaderView::section {{
    background-color: {cfg["panel_bg"]};
    color: {cfg["text"]};
    border: 1px solid {cfg["border"]};
    padding: 6px 8px;
}}
QScrollBar:vertical {{
    background: transparent;
    width: 12px;
    margin: 4px;
    border-radius: 6px;
}}
QScrollBar::handle:vertical {{
    background: {cfg["hover"]};
    border-radius: 6px;
}}
QScrollBar:horizontal {{
    background: transparent;
    height: 12px;
    margin: 4px;
    border-radius: 6px;
}}
QScrollBar::handle:horizontal {{
    background: {cfg["hover"]};
    border-radius: 6px;
}}
"""

        self.setStyleSheet(button_stylesheet + extra_styles)

    def _apply_layer_shadows(self, cfg: Dict[str, str]) -> None:
        shadow_color = QtGui.QColor(cfg.get("shadow", "rgba(0, 0, 0, 120)"))
        targets: List[Optional[QtWidgets.QWidget]] = [
            getattr(self, "filter_panel", None),
            getattr(self, "search_card", None),
            getattr(self, "report_tabs", None),
            getattr(self, "log_console", None),
        ]

        for target in targets:
            if target is None:
                continue
            effect = QtWidgets.QGraphicsDropShadowEffect(target)
            effect.setBlurRadius(28.0)
            effect.setOffset(0.0, 14.0)
            effect.setColor(shadow_color)
            target.setGraphicsEffect(effect)

    @staticmethod
    def _format_sales_dataframe(df: pd.DataFrame) -> pd.DataFrame:
        columns = [
            "Date",
            "Outlet",
            "Bill (Sales No)",
            "Payment",
            "Item Name",
            "Category",
            "QTY",
            "Sales",
            "Discount Name",
            "Discount Sales",
            "Nett Sales",
        ]

        if df.empty:
            return pd.DataFrame(columns=columns)

        frame = df.copy()
        frame["Date"] = pd.to_datetime(frame["c_date"], errors="coerce").dt.date
        frame["Outlet"] = frame["store_name"].fillna("")
        frame["Bill (Sales No)"] = frame["sales_no"].fillna("")
        frame["Payment"] = frame["payment_methods"].fillna("")
        frame["Item Name"] = frame["item_name"].fillna("")
        frame["Category"] = frame.get("category_code", "").fillna("")
        frame["QTY"] = pd.to_numeric(frame["qty"], errors="coerce").fillna(0.0)
        frame["Sales"] = pd.to_numeric(frame["sub_total"], errors="coerce").fillna(0.0)
        frame["Discount Name"] = frame["disc_name"].fillna("")
        disc_amt = pd.to_numeric(frame.get("disc_amt"), errors="coerce").fillna(0.0)
        promo_disc = pd.to_numeric(frame.get("pro_disc_amt"), errors="coerce").fillna(0.0)
        frame["Discount Sales"] = disc_amt + promo_disc
        svc_amt = pd.to_numeric(frame.get("svc_amt"), errors="coerce").fillna(0.0)
        tax_amt = pd.to_numeric(frame.get("tax_amt"), errors="coerce").fillna(0.0)
        if "source_database" in frame:
            source_db_fmt = frame["source_database"].astype(str)
        else:
            source_db_fmt = pd.Series("", index=frame.index, dtype="object")

        if "take_away_item" in frame:
            takeaway_flag_fmt = frame["take_away_item"].astype(str).str.upper()
        else:
            takeaway_flag_fmt = pd.Series("", index=frame.index, dtype="object")
        express_mask_fmt = source_db_fmt.eq("sushi_express_pos_live")
        takeaway_mask_fmt = takeaway_flag_fmt.eq("Y")
        tax_deduction_fmt = np.where(express_mask_fmt & ~takeaway_mask_fmt, 0.0, tax_amt)
        frame["Nett Sales"] = frame["Sales"] - frame["Discount Sales"] - tax_deduction_fmt + svc_amt
        frame[["Sales", "Discount Sales", "Nett Sales"]] = frame[["Sales", "Discount Sales", "Nett Sales"]].round(1)

        display = frame[columns].copy()
        display.sort_values(["Date", "Outlet", "Bill (Sales No)", "Item Name"], inplace=True)
        display.reset_index(drop=True, inplace=True)
        return display


class SalesSearchProxy(QtCore.QSortFilterProxyModel):
    def __init__(self, model: PandasTableModel, parent: Optional[QtCore.QObject] = None) -> None:
        super().__init__(parent)
        self._model = model
        self._search_text: str = ""
        self._search_tokens: list[str] = []
        self._cached_frame = pd.DataFrame()
        self._normalized_rows: Optional[pd.Series] = None
        self._mask_cache: Optional[pd.Series] = None
        self.setSourceModel(model)
        self.setSortRole(QtCore.Qt.ItemDataRole.UserRole)

    def set_search_text(self, text: str) -> None:
        cleaned = text.strip().lower()
        self._search_text = cleaned
        self._search_tokens = [token for token in cleaned.split() if token]
        self._mask_cache = None
        self.invalidateFilter()

    def refresh(self) -> None:
        self._normalized_rows = None
        self._mask_cache = None
        self.invalidateFilter()

    def filterAcceptsRow(self, source_row: int, source_parent: QtCore.QModelIndex) -> bool:  # type: ignore[override]
        del source_parent
        if not self._search_text:
            return True
        df = self._model._df
        if source_row >= len(df.index):
            return False
        normalized = self._get_normalized_rows()
        if source_row >= len(normalized.index):
            return False
        row_text = normalized.iat[source_row]
        for token in self._search_tokens:
            if token not in row_text:
                return False
        return True

    def current_frame(self) -> pd.DataFrame:
        df = self._model._df
        if df.empty:
            self._cached_frame = df
            self._normalized_rows = pd.Series(dtype=str)
            return df
        if not self._search_text:
            self._cached_frame = df
            return df
        mask = self._get_mask()
        self._cached_frame = df[mask]
        return self._cached_frame

    def _get_normalized_rows(self) -> pd.Series:
        df = self._model._df
        if self._normalized_rows is not None and len(self._normalized_rows.index) == len(df.index):
            return self._normalized_rows
        if df.empty:
            self._normalized_rows = pd.Series(dtype=str)
            return self._normalized_rows
        normalized = (
            df.fillna("")
            .astype(str)
            .agg(" ".join, axis=1)
            .str.lower()
        )
        self._normalized_rows = normalized
        return normalized

    def _get_mask(self) -> pd.Series:
        if self._mask_cache is not None:
            return self._mask_cache
        normalized = self._get_normalized_rows()
        if not self._search_text:
            mask = pd.Series(True, index=self._model._df.index)
        else:
            mask = pd.Series(True, index=self._model._df.index)
            for token in self._search_tokens:
                mask &= normalized.str.contains(token, na=False)
        self._mask_cache = mask
        return mask



def main() -> None:
    app = QtWidgets.QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec())


if __name__ == "__main__":
    main()
